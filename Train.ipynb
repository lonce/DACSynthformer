{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9bb5a36d-0fea-4c17-b799-f7bae8b0db61",
   "metadata": {},
   "source": [
    "### chaptGPT specs   \n",
    "\n",
    "A decoder-only transformer in pytorch to predict 'next output' at each time step. \n",
    "\n",
    "Each time step t is represented by a vector of n=4 tokens from the Descript DAC encoder. \n",
    "The length of the sequence (context window) is Ti=86 for inference, and Tt=8*Ti for training. That is, the context window for training is 8 times the length of the context window for inference. \n",
    "The attention is \"causal\", looking only back in time, and the maximum look-back time for the attention blocks is Ti (even when the sequence is longer during training). That is, the masking matrix is *banded* - triangular to be causal, and limited in lookback which results in a diagonal band). This prevents much of the training on shortened context that happens when tokens are near the beginning of traning examples. \n",
    "\n",
    "The size of the vocabulary (the number of descrete values in each codebook) for each of the n tokens is V=1024. \n",
    "\n",
    "The dataloader will as is usual, supply batches in triplets  (input, target, conditioning info) where the size of each input and output is Tt*n (the sequence length times the number of tokens at each time step). The tokens are indexes for the vocabulary in the range of (0, V-1). The targets are shifted relative to the input sequence by 1 as is typical for networks the learn to predict the output for the next time step. \n",
    "\n",
    "The first layer in the architecture will be a learnable \"multiembedding\" layer that embeds each of the 4 tokens at each time step as an m-dimensional vector. The n m-dimensional vectors are concatenated to provide the n*m dimensional input embeddings for the transformer blocks at each time step. \n",
    "\n",
    "A positional code is is added to the K and Q matricies in each Transformer block using Rotary Position Embedding (RoPE).\n",
    "\n",
    "We use a stack of b transformer blocks that are standard (using layer norms, a relu for activation, and a forward expansion factor of 4 form the linear layer). Each transformer block consumes and produces a context window length sequence of m*n dimensional vectors. \n",
    "\n",
    "After the last transformer block, there is a linear layer that maps the m*n dimensional vectors to the output size which is V*n (the vocabulary size time the number of tokens stacked at each time step). These are the logits that will be fed to the softmax functions (one for each of the n to kens) that provide the probability distribtion across the vocabulary set. We use the criterion nn.CrossEntropyLoss() for computing the loss using the targets provided by the dataloader, and Adam for the optimizer.\n",
    "\n",
    "Again, at inference time, the fixed-length context window is shorter than the training sequence window length, and equal to the maximum look-back time of the attention blocks. The inference process takes the output produced at each time step (a stack of n tokens), and shift them in to a sliding window that is used for input for the next time step. The length of the sequences generated during inference is arbitrary and should be settable with a parameter. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8db8df-da27-4eb1-91c5-1d4945ff4161",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; height: 20px; background-color: black;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce614c-47d9-4e16-bee8-3fbcc556b08a",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad58d43c-b453-496f-8a43-f0a1722b8fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paramfile = \"private/params_lala-mini.yaml\" # 'params.yaml' #\n",
    "#paramfile = \"private/params_nsynth64.76.yaml\" # 'params.yaml' #\n",
    "paramfile = \"private/params_lala-mini-mel.yaml\"\n",
    "#paramfile = \"paramls/params_mini.yaml\"\n",
    "DEVICE='cuda' ##''cuda'\n",
    "start_epoch=0 # to start from a previous training checkpoint, otherwise must be 0\n",
    "verboselevel=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9760e14-8c2f-4a14-be94-f1ef300296ce",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; height: 20px; background-color: black;\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d67b59e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import yaml\n",
    "import shutil\n",
    "\n",
    "# and for creating a custom dataset and loader:\n",
    "sys.path.insert(0, \"/home/lonce/working_local/DACSynthformer\")\n",
    "from sfutils.utils import generate_mask, save_model, load_model, writeDACFile, interpolate_vectors\n",
    "from DACTransformer.RopeCondDACTransformer import RopeCondDACTransformer\n",
    "\n",
    "from dataloader.dataset import CustomDACDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76dcc87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953b85ef",
   "metadata": {},
   "source": [
    "### <font color='blue'> Derived parameters </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "638ee684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validatador data dir is None\n",
      "Dataset has for conditioning 8 classes and 0 parameters.\n",
      "class names are ['do', 'do2', 'fa', 'la', 'mi', 're', 'sol ', 'ti'] and params are []\n",
      "embed_size is 256\n",
      "using TransformerClass = RopeCondDACTransformer\n",
      "basefname = out.e256.l4.h8\n",
      "outdir = runs/mini_test_256big\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'runs/mini_test_256big/params.yaml'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data dir\n",
    "\n",
    "# Load YAML file\n",
    "with open(paramfile, 'r') as file:\n",
    "    params = yaml.safe_load(file)\n",
    "\n",
    "data_dir = params['data_dir']\n",
    "data_frames =  params['data_frames']\n",
    "validator_data_dir = params['validator_data_dir']\n",
    "validator_data_frames = params['validator_data_frames']\n",
    "\n",
    "print(f'Validatador data dir is {validator_data_dir}')\n",
    "\n",
    "ftype = params['ftype'] #dac or mel\n",
    "\n",
    "Ti = params['Ti'] # mask size\n",
    "Tt = params['Tt'] # context length (sequence steps for training = timesteps in trainingset -1)\n",
    "\n",
    "# Create an instance of the dataset\n",
    "dataset = CustomDACDataset(data_dir=data_dir, metadata_excel=data_frames, ftype=ftype, Tt=Tt, transforms=None)\n",
    "\n",
    "# ---------     for the transformer  --------------#\n",
    "vocab_size = params['vocab_size']\n",
    "num_tokens = params['num_tokens']\n",
    "input_type = params['input_type']\n",
    "\n",
    "cond_classes = dataset.get_num_classes() # 0\n",
    "cond_params = dataset.get_num_params()\n",
    "cond_size = cond_classes + cond_params # num_classes + num params - not a FREE parameter!\n",
    "print(f'Dataset has for conditioning {cond_classes} classes and {cond_params} parameters.')\n",
    "print(f'class names are {dataset.get_class_names()} and params are {dataset.get_param_names()}')\n",
    "\n",
    "#embed_size = params['tblock_input_size'] -cond_size # 240 #32  # embed_size +cond_size must be divisible by num_heads and by num tokens\n",
    "embed_size = params['model_size']  # embed_size  must be divisible by num_heads and by num tokens\n",
    "print(f'embed_size is {embed_size}')\n",
    "\n",
    "batch_size = params['batch_size']\n",
    "\n",
    "sequence_length = Tt  # For training\n",
    "\n",
    "num_layers = params['num_layers']\n",
    "num_heads = params['num_heads']\n",
    "forward_expansion = params['forward_expansion']\n",
    "dropout_rate = params['dropout_rate']\n",
    "learning_rate = params['learning_rate']\n",
    "use_adaLN = params['use_adaLN']\n",
    "num_epochs=params['num_epochs']\n",
    "\n",
    "experiment_name=params['experiment'] \n",
    "outdir = 'runs' + '/' + experiment_name\n",
    "basefname= 'out' + '.e' + str(embed_size) + '.l' + str(num_layers) + '.h' + str(num_heads) \n",
    "\n",
    "ErrorLogRate = params['ErrorLogRate'] #10\n",
    "checkpoint_interval = params['checkpoint_interval']\n",
    "\n",
    "\n",
    "\n",
    "TransformerClass =  globals().get(params['TransformerClass'])  \n",
    "\n",
    "print(f\"using TransformerClass = {params['TransformerClass']}\") \n",
    "print(f'basefname = {basefname}')\n",
    "print(f'outdir = {outdir}')\n",
    "\n",
    "###########################################################################\n",
    "# Ensure the destination directory exists\n",
    "#destination_dir = os.path.dirname(outdir + '/' + paramfile)\n",
    "#if not os.path.exists(destination_dir):\n",
    "#    os.makedirs(destination_dir)\n",
    "    \n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "shutil.copy(paramfile, outdir + '/params.yaml')  # copy whatever paramfile was used to outdir and name it params.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebf3928",
   "metadata": {},
   "source": [
    "### <font color='blue'> Set up cuda. \n",
    "Without it, training runs about 10 times slower  \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ff0adcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memeory on cuda 0 is  25.37816064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if DEVICE == 'cuda' :\n",
    "    torch.cuda.device_count()\n",
    "    torch.cuda.get_device_properties(0).total_memory/1e9\n",
    "\n",
    "    device = torch.device(DEVICE) # if the docker was started with --gpus all, then can choose here with cuda:0 (or cpu)\n",
    "    torch.cuda.device_count()\n",
    "    print(f'memeory on cuda 0 is  {torch.cuda.get_device_properties(0).total_memory/1e9}')\n",
    "else :\n",
    "    device=DEVICE\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee7020c",
   "metadata": {},
   "source": [
    "### <font color='blue'> Load data \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c684557b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validatador data dir is None\n",
      "Batch 1\n",
      "Inputs shape: torch.Size([4, 429, 128])\n",
      "Targets shape: torch.Size([4, 429, 128])\n",
      "cvect shape: torch.Size([4, 8])\n",
      "cevect is tensor([[0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#Validator data set\n",
    "print(f'Validatador data dir is {validator_data_dir}')\n",
    "if validator_data_dir != None :\n",
    "    validator_dataset=CustomDACDataset(data_dir=validator_data_dir, metadata_excel=validator_data_frames, ftype=ftype, Tt=Tt)\n",
    "    validator_dataloader= DataLoader(validator_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "# Test data dir\n",
    "for batch_idx, (inputs, targets, cvect) in enumerate(dataloader):\n",
    "    #pass\n",
    "    # Your training code here\n",
    "    # inputs: batch of input data of shape [batch_size, N, T-1]\n",
    "    # targets: corresponding batch of target data of shape [batch_size, N, T-1]\n",
    "    \n",
    "    if (batch_idx == 0) : \n",
    "        print(f\"Batch {batch_idx + 1}\")\n",
    "        print(f\"Inputs shape: {inputs.shape}\")\n",
    "        print(f\"Targets shape: {targets.shape}\")\n",
    "        print(f\"cvect shape: {cvect.shape}\")\n",
    "        print(f'cevect is {cvect}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb0eb6c",
   "metadata": {},
   "source": [
    "### <font color='blue'> Make the mask \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3c9b110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask.shape is torch.Size([429, 429])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
       "        [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
       "        [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
       "        ...,\n",
       "        [-inf, -inf, -inf,  ..., 0., -inf, -inf],\n",
       "        [-inf, -inf, -inf,  ..., 0., 0., -inf],\n",
       "        [-inf, -inf, -inf,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = generate_mask(Tt, Ti).to(device)\n",
    "print(f'Mask.shape is {mask.shape}')\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11c4b392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model with embed_size=256, cond_size=8\n",
      "Initializing MultiEmbedding with vocab_size_or_input_dim=128, embed_dim = 256, and num_tokens = 1\n",
      "Total number of parameters: 2474368\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model, put it on the device\n",
    "#model = TransformerDecoder(embed_size, num_layers, num_heads, forward_expansion, dropout_rate, Tt, num_tokens, vocab_size).to(device)\n",
    "print(f'Creating model with embed_size={embed_size}, cond_size={cond_size}')\n",
    "\n",
    "if start_epoch == 0 : \n",
    "    model = TransformerClass(embed_size, num_layers, num_heads, forward_expansion, dropout_rate, Tt, cond_classes, num_tokens, vocab_size, cond_size, input_type=input_type, use_adaLN=use_adaLN, verbose=verboselevel).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "else:\n",
    "    checkpoint_path = outdir+\"/\"+basefname+\"_chkpt_\"+str(start_epoch).zfill(4) +\".pth\"\n",
    "    print(f'in train, start_epoch = {start_epoch} and checkpoint_path = {checkpoint_path}')\n",
    "    assert os.path.exists(checkpoint_path), f\"{checkpoint_path} does not exist.\"\n",
    "    if start_epoch != 0 and checkpoint_path and os.path.exists(checkpoint_path):\n",
    "        print(f\"Loading and creating model from {checkpoint_path}\")       \n",
    "        # Restore model weights\n",
    "        model, optimizer, _, vocab_size, num_tokens, cond_size = load_model(checkpoint_path,  TransformerClass, device)\n",
    "        #best_metric = checkpoint['best_metric']  # If you're tracking performance      \n",
    "        print(f\"Resuming from epoch {start_epoch}\")\n",
    "\n",
    "if ftype == 'dac':\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "if ftype == 'mel':\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "# Count the number of parameters\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Total number of parameters: {num_params}')\n",
    "\n",
    "# Initialize SummaryWriter for tensorboard \n",
    "writer = SummaryWriter(outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85526818-66e9-4bf0-9a94-0334ecd39d61",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; height: 20px; background-color: black;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf2f038",
   "metadata": {},
   "source": [
    "# <font color='blue'> Train !! \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccb439d-6d8f-4b1c-a4fd-6acac2a07db6",
   "metadata": {},
   "source": [
    "### loss is average CE across all output tokens\n",
    "\n",
    "$$\n",
    "L = \\frac{1}{N} \\sum_{n=1}^{N} \\text{CE}(x_n, y_n)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19920362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 25  (with max 2000), loss: 1.209867238998413\n",
      "train time for 25 epochs, was 0.9436795711517334\n",
      "\n",
      "EPOCH 50  (with max 2000), loss: 0.6509606838226318\n",
      "train time for 50 epochs, was 1.8208541870117188\n",
      "\n",
      "EPOCH 75  (with max 2000), loss: 0.45480796694755554\n",
      "train time for 75 epochs, was 2.68269681930542\n",
      "\n",
      "EPOCH 100  (with max 2000), loss: 0.2993588149547577\n",
      "train time for 100 epochs, was 3.562333106994629\n",
      "\n",
      "EPOCH 125  (with max 2000), loss: 0.25739622116088867\n",
      "train time for 125 epochs, was 4.3152008056640625\n",
      "\n",
      "EPOCH 150  (with max 2000), loss: 0.23369100689888\n",
      "train time for 150 epochs, was 5.232108116149902\n",
      "\n",
      "EPOCH 175  (with max 2000), loss: 0.2079920619726181\n",
      "train time for 175 epochs, was 6.128770351409912\n",
      "\n",
      "EPOCH 200  (with max 2000), loss: 0.1947982907295227\n",
      "train time for 200 epochs, was 7.020608425140381\n",
      "\n",
      "EPOCH 200 save model to : runs/mini_test_256big/out.e256.l4.h8_chkpt_0200.pth\n",
      "\n",
      "EPOCH 225  (with max 2000), loss: 0.1880442351102829\n",
      "train time for 225 epochs, was 8.023731470108032\n",
      "\n",
      "EPOCH 250  (with max 2000), loss: 0.1760568767786026\n",
      "train time for 250 epochs, was 8.85944128036499\n",
      "\n",
      "EPOCH 275  (with max 2000), loss: 0.16819657385349274\n",
      "train time for 275 epochs, was 9.702431678771973\n",
      "\n",
      "EPOCH 300  (with max 2000), loss: 0.15300969779491425\n",
      "train time for 300 epochs, was 10.544967651367188\n",
      "\n",
      "EPOCH 325  (with max 2000), loss: 0.13703767955303192\n",
      "train time for 325 epochs, was 11.494295120239258\n",
      "\n",
      "EPOCH 350  (with max 2000), loss: 0.14133527874946594\n",
      "train time for 350 epochs, was 12.304580688476562\n",
      "\n",
      "EPOCH 375  (with max 2000), loss: 0.14114569127559662\n",
      "train time for 375 epochs, was 13.25631046295166\n",
      "\n",
      "EPOCH 400  (with max 2000), loss: 0.12340686470270157\n",
      "train time for 400 epochs, was 14.12389326095581\n",
      "\n",
      "EPOCH 400 save model to : runs/mini_test_256big/out.e256.l4.h8_chkpt_0400.pth\n",
      "\n",
      "EPOCH 425  (with max 2000), loss: 0.12806816399097443\n",
      "train time for 425 epochs, was 15.004545211791992\n",
      "\n",
      "EPOCH 450  (with max 2000), loss: 0.10933855921030045\n",
      "train time for 450 epochs, was 15.799481630325317\n",
      "\n",
      "EPOCH 475  (with max 2000), loss: 0.09609707444906235\n",
      "train time for 475 epochs, was 16.64546275138855\n",
      "\n",
      "EPOCH 500  (with max 2000), loss: 0.09041055291891098\n",
      "train time for 500 epochs, was 17.655590295791626\n",
      "\n",
      "EPOCH 525  (with max 2000), loss: 0.09162504971027374\n",
      "train time for 525 epochs, was 18.528982877731323\n",
      "\n",
      "EPOCH 550  (with max 2000), loss: 0.1172095537185669\n",
      "train time for 550 epochs, was 19.370667457580566\n",
      "\n",
      "EPOCH 575  (with max 2000), loss: 0.08908109366893768\n",
      "train time for 575 epochs, was 20.339017629623413\n",
      "\n",
      "EPOCH 600  (with max 2000), loss: 0.08913759887218475\n",
      "train time for 600 epochs, was 21.36474108695984\n",
      "\n",
      "EPOCH 600 save model to : runs/mini_test_256big/out.e256.l4.h8_chkpt_0600.pth\n",
      "\n",
      "EPOCH 625  (with max 2000), loss: 0.08154813945293427\n",
      "train time for 625 epochs, was 22.26786971092224\n",
      "\n",
      "EPOCH 650  (with max 2000), loss: 0.07058056443929672\n",
      "train time for 650 epochs, was 23.101566553115845\n",
      "\n",
      "EPOCH 675  (with max 2000), loss: 0.07430735230445862\n",
      "train time for 675 epochs, was 23.859662771224976\n",
      "\n",
      "EPOCH 700  (with max 2000), loss: 0.06640525907278061\n",
      "train time for 700 epochs, was 24.66765332221985\n",
      "\n",
      "EPOCH 725  (with max 2000), loss: 0.06915979832410812\n",
      "train time for 725 epochs, was 25.477906703948975\n",
      "\n",
      "EPOCH 750  (with max 2000), loss: 0.07080715894699097\n",
      "train time for 750 epochs, was 26.27462339401245\n",
      "\n",
      "EPOCH 775  (with max 2000), loss: 0.07333315908908844\n",
      "train time for 775 epochs, was 27.060043573379517\n",
      "\n",
      "EPOCH 800  (with max 2000), loss: 0.0656287893652916\n",
      "train time for 800 epochs, was 27.931621074676514\n",
      "\n",
      "EPOCH 800 save model to : runs/mini_test_256big/out.e256.l4.h8_chkpt_0800.pth\n",
      "\n",
      "EPOCH 825  (with max 2000), loss: 0.058713242411613464\n",
      "train time for 825 epochs, was 28.71492338180542\n",
      "\n",
      "EPOCH 850  (with max 2000), loss: 0.05789651349186897\n",
      "train time for 850 epochs, was 29.623353481292725\n",
      "\n",
      "EPOCH 875  (with max 2000), loss: 0.06054776906967163\n",
      "train time for 875 epochs, was 30.484782218933105\n",
      "\n",
      "EPOCH 900  (with max 2000), loss: 0.05862967669963837\n",
      "train time for 900 epochs, was 31.287439107894897\n",
      "\n",
      "EPOCH 925  (with max 2000), loss: 0.0606013685464859\n",
      "train time for 925 epochs, was 32.16266202926636\n",
      "\n",
      "EPOCH 950  (with max 2000), loss: 0.052747417241334915\n",
      "train time for 950 epochs, was 32.880194664001465\n",
      "\n",
      "EPOCH 975  (with max 2000), loss: 0.05730728060007095\n",
      "train time for 975 epochs, was 33.67293953895569\n",
      "\n",
      "EPOCH 1000  (with max 2000), loss: 0.055093709379434586\n",
      "train time for 1000 epochs, was 34.547712564468384\n",
      "\n",
      "EPOCH 1000 save model to : runs/mini_test_256big/out.e256.l4.h8_chkpt_1000.pth\n",
      "\n",
      "EPOCH 1025  (with max 2000), loss: 0.053450848907232285\n",
      "train time for 1025 epochs, was 35.382524728775024\n",
      "\n",
      "EPOCH 1050  (with max 2000), loss: 0.05303943529725075\n",
      "train time for 1050 epochs, was 36.24576663970947\n",
      "\n",
      "EPOCH 1075  (with max 2000), loss: 0.05152754485607147\n",
      "train time for 1075 epochs, was 37.21657395362854\n",
      "\n",
      "EPOCH 1100  (with max 2000), loss: 0.048543352633714676\n",
      "train time for 1100 epochs, was 38.043723344802856\n",
      "\n",
      "EPOCH 1125  (with max 2000), loss: 0.04709780961275101\n",
      "train time for 1125 epochs, was 38.87532162666321\n",
      "\n",
      "EPOCH 1150  (with max 2000), loss: 0.053293582051992416\n",
      "train time for 1150 epochs, was 39.69804310798645\n",
      "\n",
      "EPOCH 1175  (with max 2000), loss: 0.04468443989753723\n",
      "train time for 1175 epochs, was 40.46625232696533\n",
      "\n",
      "EPOCH 1200  (with max 2000), loss: 0.044728800654411316\n",
      "train time for 1200 epochs, was 41.36297035217285\n",
      "\n",
      "EPOCH 1200 save model to : runs/mini_test_256big/out.e256.l4.h8_chkpt_1200.pth\n",
      "\n",
      "EPOCH 1225  (with max 2000), loss: 0.04470047354698181\n",
      "train time for 1225 epochs, was 42.238914012908936\n",
      "\n",
      "EPOCH 1250  (with max 2000), loss: 0.04348162189126015\n",
      "train time for 1250 epochs, was 43.15415048599243\n",
      "\n",
      "EPOCH 1275  (with max 2000), loss: 0.04225792735815048\n",
      "train time for 1275 epochs, was 44.07058620452881\n",
      "\n",
      "EPOCH 1300  (with max 2000), loss: 0.04816267639398575\n",
      "train time for 1300 epochs, was 45.04061818122864\n",
      "\n",
      "EPOCH 1325  (with max 2000), loss: 0.0462985597550869\n",
      "train time for 1325 epochs, was 45.93249487876892\n",
      "\n",
      "EPOCH 1350  (with max 2000), loss: 0.03917885199189186\n",
      "train time for 1350 epochs, was 46.71987843513489\n",
      "\n",
      "EPOCH 1375  (with max 2000), loss: 0.04335519298911095\n",
      "train time for 1375 epochs, was 47.587151288986206\n",
      "\n",
      "EPOCH 1400  (with max 2000), loss: 0.0406753234565258\n",
      "train time for 1400 epochs, was 48.42405414581299\n",
      "\n",
      "EPOCH 1400 save model to : runs/mini_test_256big/out.e256.l4.h8_chkpt_1400.pth\n",
      "\n",
      "EPOCH 1425  (with max 2000), loss: 0.036998193711042404\n",
      "train time for 1425 epochs, was 49.25588417053223\n",
      "\n",
      "EPOCH 1450  (with max 2000), loss: 0.03960180655121803\n",
      "train time for 1450 epochs, was 50.129090547561646\n",
      "\n",
      "EPOCH 1475  (with max 2000), loss: 0.03485056012868881\n",
      "train time for 1475 epochs, was 51.025116205215454\n",
      "\n",
      "EPOCH 1500  (with max 2000), loss: 0.03508111834526062\n",
      "train time for 1500 epochs, was 51.92943811416626\n",
      "\n",
      "EPOCH 1525  (with max 2000), loss: 0.04178928956389427\n",
      "train time for 1525 epochs, was 52.765947341918945\n",
      "\n",
      "EPOCH 1550  (with max 2000), loss: 0.039522986859083176\n",
      "train time for 1550 epochs, was 53.571725606918335\n",
      "\n",
      "EPOCH 1575  (with max 2000), loss: 0.035562239587306976\n",
      "train time for 1575 epochs, was 54.28582453727722\n",
      "\n",
      "EPOCH 1600  (with max 2000), loss: 0.036248985677957535\n",
      "train time for 1600 epochs, was 55.0812828540802\n",
      "\n",
      "EPOCH 1600 save model to : runs/mini_test_256big/out.e256.l4.h8_chkpt_1600.pth\n",
      "\n",
      "EPOCH 1625  (with max 2000), loss: 0.03756674751639366\n",
      "train time for 1625 epochs, was 56.001664876937866\n",
      "\n",
      "EPOCH 1650  (with max 2000), loss: 0.03464658558368683\n",
      "train time for 1650 epochs, was 56.845250606536865\n",
      "\n",
      "EPOCH 1675  (with max 2000), loss: 0.036442141979932785\n",
      "train time for 1675 epochs, was 57.62372350692749\n",
      "\n",
      "EPOCH 1700  (with max 2000), loss: 0.03412989526987076\n",
      "train time for 1700 epochs, was 58.53498697280884\n",
      "\n",
      "EPOCH 1725  (with max 2000), loss: 0.031307436525821686\n",
      "train time for 1725 epochs, was 59.29647874832153\n",
      "\n",
      "EPOCH 1750  (with max 2000), loss: 0.031653616577386856\n",
      "train time for 1750 epochs, was 60.21365809440613\n",
      "\n",
      "EPOCH 1775  (with max 2000), loss: 0.03213348984718323\n",
      "train time for 1775 epochs, was 61.09282350540161\n",
      "\n",
      "EPOCH 1800  (with max 2000), loss: 0.03529820963740349\n",
      "train time for 1800 epochs, was 61.92544960975647\n",
      "\n",
      "EPOCH 1800 save model to : runs/mini_test_256big/out.e256.l4.h8_chkpt_1800.pth\n",
      "\n",
      "EPOCH 1825  (with max 2000), loss: 0.030117092654109\n",
      "train time for 1825 epochs, was 62.71422338485718\n",
      "\n",
      "EPOCH 1850  (with max 2000), loss: 0.0329647995531559\n",
      "train time for 1850 epochs, was 63.51664924621582\n",
      "\n",
      "EPOCH 1875  (with max 2000), loss: 0.03105829283595085\n",
      "train time for 1875 epochs, was 64.34973978996277\n",
      "\n",
      "EPOCH 1900  (with max 2000), loss: 0.030816098675131798\n",
      "train time for 1900 epochs, was 65.21838879585266\n",
      "\n",
      "EPOCH 1925  (with max 2000), loss: 0.03223416581749916\n",
      "train time for 1925 epochs, was 66.03800058364868\n",
      "\n",
      "EPOCH 1950  (with max 2000), loss: 0.044054895639419556\n",
      "train time for 1950 epochs, was 66.78037238121033\n",
      "\n",
      "EPOCH 1975  (with max 2000), loss: 0.03134848549962044\n",
      "train time for 1975 epochs, was 67.58648586273193\n",
      "\n",
      "EPOCH 2000  (with max 2000), loss: 0.034539368003606796\n",
      "train time for 2000 epochs, was 68.47119450569153\n",
      "\n",
      "EPOCH 2000 save model to : runs/mini_test_256big/out.e256.l4.h8_chkpt_2000.pth\n",
      "\n",
      "train time for 2000 epochs, was 68.49600887298584\n",
      "loss  =  0.034539368003606796\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train(model, optimizer, dataloader, num_epochs, device, outdir, basefname, start_epoch=0, checkpoint_path=None):\n",
    "    t0 = time.time()\n",
    "    max_epoch = start_epoch + num_epochs\n",
    "    for epoch in range(start_epoch, max_epoch):\n",
    "        torch.cuda.empty_cache()\n",
    "        model.train()\n",
    "        for batch_idx, (input_data, target_data, cond_data) in enumerate(dataloader):\n",
    "            if verboselevel > 5 :\n",
    "                print(f' ---- submitting batch with input_data={input_data.shape}, target_data={target_data.shape}, cond_data={cond_data.shape}')\n",
    "            #print(f\"b{batch_idx} \", end='')\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # Move inputs and targets to the device\n",
    "            input_data, target_data, cond_data = input_data.to(device), target_data.to(device), cond_data.to(device)\n",
    "            \n",
    "            if cond_size==0 :  #Ignore conditioning data\n",
    "                cond_expanded=None\n",
    "            else : \n",
    "                # for dataset exammples, expand the conditioning info across all time steps before passing to models\n",
    "                cond_expanded = cond_data.unsqueeze(1).expand(-1, input_data.size(1), -1)\n",
    "\n",
    "            if verboselevel > 9 :\n",
    "                print(f'    after loading a batch,  input_data.shape is {input_data.shape}, and cond_data.shape is {cond_data.shape}')\n",
    "                print(f'    after loading a batch,  cond_expanded.shape is {cond_expanded.shape}')\n",
    "                #print(f'    after loading a batch,  mask.shape is {mask.shape}')\n",
    "                #print(f' model={model}')\n",
    "            \n",
    "            # torch.Size([batch_size, seq_len, num_tokens, vocab_size])\n",
    "            output = model(input_data, cond_expanded, mask)\n",
    "        \n",
    "            if verboselevel > 5 :\n",
    "                print(f' TTTTTTTT after training, output shape ={output.shape}, torch.Size([batch_size, seq_len, num_tokens, vocab_size])')\n",
    "                print(f' TTTTTTTT target_data shape ={target_data.shape}')\n",
    "                print(f' TTTTTTTT Passing to CRITERION with , output.reshape(-1, vocab_size) = {output.reshape(-1, vocab_size).shape} and target_data.reshape(-1) = {target_data.reshape(-1).shape}' )\n",
    "    \n",
    "            ##  this works, but is too verbose >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "            ##      # Original shape: (batch_size, seq_len, num_tokens, vocab_size)\n",
    "            ##      output = output.reshape(batch_size, sequence_length * num_tokens, vocab_size)\n",
    "            ##      # Original shape: (batch_size, seq_len, num_tokens)\n",
    "            ##      targets = targets.reshape(batch_size, sequence_length * num_tokens)\n",
    "            ##      loss = criterion(output.permute(0, 2, 1), targets) \n",
    "            \n",
    "            ##  more succinct <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "            #   Computes the CE for each token separately, and then averages them to get the loss.\n",
    "            #loss = criterion(output.reshape(-1, vocab_size), target_data.reshape(-1)) # collapses all target_data dimensions into a single dimension\n",
    "            if ftype == 'dac' :\n",
    "                loss = criterion(output.reshape(-1, vocab_size), target_data.reshape(-1).long())\n",
    "            if ftype == 'mel':\n",
    "                target_data =target_data.unsqueeze(2) # This is to put the \"num tokens\" dimension to match the shape in that appears in the network output\n",
    "                loss = criterion(output, target_data)\n",
    "            ## <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if (epoch+1) % ErrorLogRate == 0:\n",
    "            print(f'EPOCH {epoch+1}  (with max {max_epoch}), ', end='')\n",
    "            print(f'loss: {loss}')\n",
    "            # Log the loss to TensorBoard\n",
    "            writer.add_scalar('Loss/train', loss, epoch)\n",
    "            \n",
    "            if validator_data_dir != None :\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_loss = 0\n",
    "                    for val_inputs, val_targets, cond_data in validator_dataloader:\n",
    "                        val_inputs, val_targets, cond_data = val_inputs.to(device), val_targets.to(device), cond_data.to(device)\n",
    "                        \n",
    "                        if cond_size==0 :  #Ignore conditioning data\n",
    "                            cond_expanded=None\n",
    "                        else: \n",
    "                            # for dataset exammples, expand the conditioning info across all time steps before passing to models\n",
    "                            cond_expanded = cond_data.unsqueeze(1).expand(-1, input_data.size(1), -1)\n",
    "    \n",
    "                        \n",
    "                        val_outputs = model(val_inputs,cond_expanded, mask)\n",
    "                        \n",
    "                        val_loss += criterion(val_outputs.reshape(-1, vocab_size), val_targets.reshape(-1).long()) # collapses all target_data dimensions into a single dimension\n",
    "                        #val_loss += criterion(val_outputs, val_targets).item()\n",
    "    \n",
    "                print(f'Validation Loss: {val_loss / len(validator_dataloader)}')\n",
    "                writer.add_scalar('Loss/validation', val_loss / len(validator_dataloader), epoch)\n",
    "    \n",
    "            t1 = time.time()\n",
    "            train_time = t1-t0\n",
    "            print(f'train time for {epoch-start_epoch+1} epochs, was {train_time}' )\n",
    "            print(f'')\n",
    "                \n",
    "        if (epoch+1) % checkpoint_interval == 0:\n",
    "            lastbasename = outdir+\"/\"+basefname+\"_chkpt_\"+str(epoch+1).zfill(4)\n",
    "            print(f'EPOCH {epoch+1} save model to : {lastbasename}.pth')\n",
    "            print(f'')\n",
    "            save_model(model, optimizer, Ti,  lastbasename +\".pth\")\n",
    "        \n",
    "    \n",
    "    t1 = time.time()\n",
    "    train_time = t1-t0\n",
    "    print(f'train time for {num_epochs} epochs, was {train_time}' )\n",
    "    print(f'loss  =  {loss}' )\n",
    "    \n",
    "## -----------------------------------------------------------------------------------\n",
    "## OK, let's do it!\n",
    "train(model, optimizer, dataloader, num_epochs, device, outdir, basefname, start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16eb43b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
       "        [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
       "        [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., -inf, -inf],\n",
       "        [0., 0., 0.,  ..., 0., 0., -inf],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just check that inference attention mask will look right\n",
    "#Actually, the inference mask can be None since we are using a context window only as long as the maximum look-back in the training mask\n",
    "# thats why taking the mask with :TI is upper-triangular. Longer dims would show a banded mask again.\n",
    "foo=mask[:Ti, :Ti]\n",
    "foo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871a1f25-78a6-479b-8771-2910cf639d67",
   "metadata": {},
   "source": [
    "### <font color='blue'> Use Inference.Decode.ipynb to see and hear your generated audio   \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68274809-4986-4d54-a442-ba7ac8b48ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
