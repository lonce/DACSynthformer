{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9bb5a36d-0fea-4c17-b799-f7bae8b0db61",
   "metadata": {},
   "source": [
    "### chaptGPT specs   \n",
    "\n",
    "A decoder-only transformer in pytorch to predict 'next output' at each time step. \n",
    "\n",
    "Each time step t is represented by a vector of n=4 tokens from the Descript DAC encoder. \n",
    "The length of the sequence (context window) is Ti=86 for inference, and Tt=8*Ti for training. That is, the context window for training is 8 times the length of the context window for inference. \n",
    "The attention is \"causal\", looking only back in time, and the maximum look-back time for the attention blocks is Ti (even when the sequence is longer during training). That is, the masking matrix is *banded* - triangular to be causal, and limited in lookback which results in a diagonal band). This prevents much of the training on shortened context that happens when tokens are near the beginning of traning examples. \n",
    "\n",
    "The size of the vocabulary (the number of descrete values in each codebook) for each of the n tokens is V=1024. \n",
    "\n",
    "The dataloader will as is usual, supply batches in triplets  (input, target, conditioning info) where the size of each input and output is Tt*n (the sequence length times the number of tokens at each time step). The tokens are indexes for the vocabulary in the range of (0, V-1). The targets are shifted relative to the input sequence by 1 as is typical for networks the learn to predict the output for the next time step. \n",
    "\n",
    "The first layer in the architecture will be a learnable \"multiembedding\" layer that embeds each of the 4 tokens at each time step as an m-dimensional vector. The n m-dimensional vectors are concatenated to provide the n*m dimensional input embeddings for the transformer blocks at each time step. \n",
    "\n",
    "A positional code is is added to the K and Q matricies in each Transformer block using Rotary Position Embedding (RoPE).\n",
    "\n",
    "We use a stack of b transformer blocks that are standard (using layer norms, a relu for activation, and a forward expansion factor of 4 form the linear layer). Each transformer block consumes and produces a context window length sequence of m*n dimensional vectors. \n",
    "\n",
    "After the last transformer block, there is a linear layer that maps the m*n dimensional vectors to the output size which is V*n (the vocabulary size time the number of tokens stacked at each time step). These are the logits that will be fed to the softmax functions (one for each of the n to kens) that provide the probability distribtion across the vocabulary set. We use the criterion nn.CrossEntropyLoss() for computing the loss using the targets provided by the dataloader, and Adam for the optimizer.\n",
    "\n",
    "Again, at inference time, the fixed-length context window is shorter than the training sequence window length, and equal to the maximum look-back time of the attention blocks. The inference process takes the output produced at each time step (a stack of n tokens), and shift them in to a sliding window that is used for input for the next time step. The length of the sequences generated during inference is arbitrary and should be settable with a parameter. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8db8df-da27-4eb1-91c5-1d4945ff4161",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; height: 20px; background-color: black;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce614c-47d9-4e16-bee8-3fbcc556b08a",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad58d43c-b453-496f-8a43-f0a1722b8fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramfile = 'private/params_nsynth64.76.yaml' # 'params.yaml' #\n",
    "DEVICE='cuda' ##''cuda'\n",
    "start_epoch=0 # to start from a previous training checkpoint, otherwise must be 0\n",
    "verboselevel=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9760e14-8c2f-4a14-be94-f1ef300296ce",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; height: 20px; background-color: black;\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d67b59e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# and for creating a custom dataset and loader:\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import yaml\n",
    "import shutil\n",
    "\n",
    "from utils.utils import generate_mask, save_model, load_model, writeDACFile, interpolate_vectors\n",
    "from DACTransformer.RopeCondDACTransformer import RopeCondDACTransformer\n",
    "\n",
    "from dataloader.dataset import CustomDACDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76dcc87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953b85ef",
   "metadata": {},
   "source": [
    "### <font color='blue'> Derived parameters </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "638ee684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has for conditioning 2 classes and 2 parameters.\n",
      "class names are ['brass_acoustic', 'reed_acoustic'] and params are ['note', 'amp']\n",
      "embed_size is 256\n",
      "using TransformerClass = RopeCondDACTransformer\n",
      "basefname = out.e256.l4.h8\n",
      "outdir = runs/nsynth_test_256_class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lonce/miniconda3/envs/dacformer2/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'runs/nsynth_test_256_class/params.yaml'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data dir\n",
    "\n",
    "# Load YAML file\n",
    "with open(paramfile, 'r') as file:\n",
    "    params = yaml.safe_load(file)\n",
    "\n",
    "data_dir = params['data_dir']\n",
    "data_frames =  params['data_frames']\n",
    "validator_data_dir = params['validator_data_dir']\n",
    "validator_data_frames = params['validator_data_frames']\n",
    "\n",
    "Ti = params['Ti'] # mask size\n",
    "Tt = params['Tt'] # context length (sequence steps for training = timesteps in trainingset -1)\n",
    "\n",
    "# Create an instance of the dataset\n",
    "dataset = CustomDACDataset(data_dir=data_dir, metadata_excel=data_frames, Tt=Tt, transforms=None)\n",
    "\n",
    "# ---------     for the transformer  --------------#\n",
    "vocab_size = params['vocab_size']\n",
    "num_tokens = params['num_tokens']\n",
    "\n",
    "cond_classes = dataset.get_num_classes() # 0\n",
    "cond_params = dataset.get_num_params()\n",
    "cond_size = cond_classes + cond_params # num_classes + num params - not a FREE parameter!\n",
    "print(f'Dataset has for conditioning {cond_classes} classes and {cond_params} parameters.')\n",
    "print(f'class names are {dataset.get_class_names()} and params are {dataset.get_param_names()}')\n",
    "\n",
    "#embed_size = params['tblock_input_size'] -cond_size # 240 #32  # embed_size +cond_size must be divisible by num_heads and by num tokens\n",
    "embed_size = params['model_size']  # embed_size  must be divisible by num_heads and by num tokens\n",
    "print(f'embed_size is {embed_size}')\n",
    "\n",
    "batch_size = params['batch_size']\n",
    "\n",
    "sequence_length = Tt  # For training\n",
    "\n",
    "num_layers = params['num_layers']\n",
    "num_heads = params['num_heads']\n",
    "forward_expansion = params['forward_expansion']\n",
    "dropout_rate = params['dropout_rate']\n",
    "learning_rate = params['learning_rate']\n",
    "num_epochs=params['num_epochs']\n",
    "\n",
    "experiment_name=params['experiment'] \n",
    "outdir = 'runs' + '/' + experiment_name\n",
    "basefname= 'out' + '.e' + str(embed_size) + '.l' + str(num_layers) + '.h' + str(num_heads) \n",
    "\n",
    "ErrorLogRate = params['ErrorLogRate'] #10\n",
    "checkpoint_interval = params['checkpoint_interval']\n",
    "\n",
    "\n",
    "\n",
    "TransformerClass =  globals().get(params['TransformerClass'])  \n",
    "\n",
    "print(f\"using TransformerClass = {params['TransformerClass']}\") \n",
    "print(f'basefname = {basefname}')\n",
    "print(f'outdir = {outdir}')\n",
    "\n",
    "###########################################################################\n",
    "# Ensure the destination directory exists\n",
    "#destination_dir = os.path.dirname(outdir + '/' + paramfile)\n",
    "#if not os.path.exists(destination_dir):\n",
    "#    os.makedirs(destination_dir)\n",
    "    \n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "shutil.copy(paramfile, outdir + '/params.yaml')  # copy whatever paramfile was used to outdir and name it params.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebf3928",
   "metadata": {},
   "source": [
    "### <font color='blue'> Set up cuda. \n",
    "Without it, training runs about 10 times slower  \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ff0adcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memeory on cuda 0 is  25.37816064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if DEVICE == 'cuda' :\n",
    "    torch.cuda.device_count()\n",
    "    torch.cuda.get_device_properties(0).total_memory/1e9\n",
    "\n",
    "    device = torch.device(DEVICE) # if the docker was started with --gpus all, then can choose here with cuda:0 (or cpu)\n",
    "    torch.cuda.device_count()\n",
    "    print(f'memeory on cuda 0 is  {torch.cuda.get_device_properties(0).total_memory/1e9}')\n",
    "else :\n",
    "    device=DEVICE\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee7020c",
   "metadata": {},
   "source": [
    "### <font color='blue'> Load data \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c684557b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "Inputs shape: torch.Size([4, 215, 4])\n",
      "Targets shape: torch.Size([4, 215, 4])\n",
      "cvect shape: torch.Size([4, 4])\n",
      "cevect is tensor([[0.0000, 1.0000, 0.8300, 0.6700],\n",
      "        [1.0000, 0.0000, 0.5000, 0.3300],\n",
      "        [0.0000, 1.0000, 0.2500, 0.4400],\n",
      "        [1.0000, 0.0000, 0.6700, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#Validator data set\n",
    "if validator_data_dir != None :\n",
    "    validator_dataset=CustomDACDataset(data_dir=validator_data_dir, metadata_excel=validator_data_frames, Tt=Tt)\n",
    "    validator_dataloader= DataLoader(validator_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "# Test data dir\n",
    "for batch_idx, (inputs, targets, cvect) in enumerate(dataloader):\n",
    "    #pass\n",
    "    # Your training code here\n",
    "    # inputs: batch of input data of shape [batch_size, N, T-1]\n",
    "    # targets: corresponding batch of target data of shape [batch_size, N, T-1]\n",
    "    \n",
    "    if (batch_idx == 0) : \n",
    "        print(f\"Batch {batch_idx + 1}\")\n",
    "        print(f\"Inputs shape: {inputs.shape}\")\n",
    "        print(f\"Targets shape: {targets.shape}\")\n",
    "        print(f\"cvect shape: {cvect.shape}\")\n",
    "        print(f'cevect is {cvect}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb0eb6c",
   "metadata": {},
   "source": [
    "### <font color='blue'> Make the mask \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3c9b110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask.shape is torch.Size([215, 215])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
       "        [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
       "        [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
       "        ...,\n",
       "        [-inf, -inf, -inf,  ..., 0., -inf, -inf],\n",
       "        [-inf, -inf, -inf,  ..., 0., 0., -inf],\n",
       "        [-inf, -inf, -inf,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = generate_mask(Tt, Ti).to(device)\n",
    "print(f'Mask.shape is {mask.shape}')\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11c4b392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model with embed_size=256, cond_size=4\n",
      " ------------- embed_dim (256) must be divisible by num_heads (8)\n",
      "Setting up MultiEmbedding with vocab_size= 1024, embed_size= 256, num_codebooks= 4\n",
      "Setting up RotaryPositionalEmbedding with embed_size= 256, max_len= 215\n",
      "Total number of parameters: 4215808\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model, put it on the device\n",
    "#model = TransformerDecoder(embed_size, num_layers, num_heads, forward_expansion, dropout_rate, Tt, num_tokens, vocab_size).to(device)\n",
    "print(f'Creating model with embed_size={embed_size}, cond_size={cond_size}')\n",
    "\n",
    "if start_epoch == 0 : \n",
    "    model = TransformerClass(embed_size, num_layers, num_heads, forward_expansion, dropout_rate, Tt, cond_classes, num_tokens, vocab_size, cond_size, verboselevel).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "else:\n",
    "    checkpoint_path = outdir+\"/\"+basefname+\"_chkpt_\"+str(start_epoch).zfill(4) +\".pth\"\n",
    "    print(f'in train, start_epoch = {start_epoch} and checkpoint_path = {checkpoint_path}')\n",
    "    assert os.path.exists(checkpoint_path), f\"{checkpoint_path} does not exist.\"\n",
    "    if start_epoch != 0 and checkpoint_path and os.path.exists(checkpoint_path):\n",
    "        print(f\"Loading and creating model from {checkpoint_path}\")       \n",
    "        # Restore model weights\n",
    "        model, optimizer, _, vocab_size, num_tokens, cond_size = load_model(checkpoint_path,  TransformerClass, device)\n",
    "        #best_metric = checkpoint['best_metric']  # If you're tracking performance      \n",
    "        print(f\"Resuming from epoch {start_epoch}\")\n",
    "   \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Count the number of parameters\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Total number of parameters: {num_params}')\n",
    "\n",
    "# Initialize SummaryWriter for tensorboard \n",
    "writer = SummaryWriter(outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85526818-66e9-4bf0-9a94-0334ecd39d61",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; height: 20px; background-color: black;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf2f038",
   "metadata": {},
   "source": [
    "# <font color='blue'> Train !! \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccb439d-6d8f-4b1c-a4fd-6acac2a07db6",
   "metadata": {},
   "source": [
    "### loss is average CE across all output tokens\n",
    "\n",
    "$$\n",
    "L = \\frac{1}{N} \\sum_{n=1}^{N} \\text{CE}(x_n, y_n)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19920362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2  (with max 8000), loss: 2.4050190448760986\n",
      "train time for 2 epochs, was 1.7962002754211426\n",
      "\n",
      "EPOCH 4  (with max 8000), loss: 2.406697988510132\n",
      "train time for 4 epochs, was 3.5127625465393066\n",
      "\n",
      "EPOCH 6  (with max 8000), loss: 0.9143427610397339\n",
      "train time for 6 epochs, was 5.188417911529541\n",
      "\n",
      "EPOCH 8  (with max 8000), loss: 0.37159600853919983\n",
      "train time for 8 epochs, was 6.823329210281372\n",
      "\n",
      "EPOCH 10  (with max 8000), loss: 0.1647316813468933\n",
      "train time for 10 epochs, was 8.506021738052368\n",
      "\n",
      "EPOCH 12  (with max 8000), loss: 0.10933469980955124\n",
      "train time for 12 epochs, was 10.159823894500732\n",
      "\n",
      "EPOCH 14  (with max 8000), loss: 0.07762549817562103\n",
      "train time for 14 epochs, was 11.810559749603271\n",
      "\n",
      "EPOCH 16  (with max 8000), loss: 0.062336135655641556\n",
      "train time for 16 epochs, was 13.466983795166016\n",
      "\n",
      "EPOCH 18  (with max 8000), loss: 0.041957397013902664\n",
      "train time for 18 epochs, was 15.134094476699829\n",
      "\n",
      "EPOCH 20  (with max 8000), loss: 0.04488489404320717\n",
      "train time for 20 epochs, was 16.784314393997192\n",
      "\n",
      "EPOCH 22  (with max 8000), loss: 0.03171028569340706\n",
      "train time for 22 epochs, was 18.46662974357605\n",
      "\n",
      "EPOCH 24  (with max 8000), loss: 0.0303658377379179\n",
      "train time for 24 epochs, was 20.142122983932495\n",
      "\n",
      "EPOCH 26  (with max 8000), loss: 0.03296138346195221\n",
      "train time for 26 epochs, was 21.779146671295166\n",
      "\n",
      "EPOCH 28  (with max 8000), loss: 0.030946874991059303\n",
      "train time for 28 epochs, was 23.458590030670166\n",
      "\n",
      "EPOCH 30  (with max 8000), loss: 0.02352038584649563\n",
      "train time for 30 epochs, was 25.121326446533203\n",
      "\n",
      "EPOCH 32  (with max 8000), loss: 0.029035357758402824\n",
      "train time for 32 epochs, was 26.756715774536133\n",
      "\n",
      "EPOCH 34  (with max 8000), loss: 0.02888641506433487\n",
      "train time for 34 epochs, was 28.393827199935913\n",
      "\n",
      "EPOCH 36  (with max 8000), loss: 0.021941931918263435\n",
      "train time for 36 epochs, was 30.028726816177368\n",
      "\n",
      "EPOCH 38  (with max 8000), loss: 0.051483698189258575\n",
      "train time for 38 epochs, was 31.66363000869751\n",
      "\n",
      "EPOCH 40  (with max 8000), loss: 0.04053550213575363\n",
      "train time for 40 epochs, was 33.29790902137756\n",
      "\n",
      "EPOCH 42  (with max 8000), loss: 0.028815872967243195\n",
      "train time for 42 epochs, was 34.932743549346924\n",
      "\n",
      "EPOCH 44  (with max 8000), loss: 0.017319459468126297\n",
      "train time for 44 epochs, was 36.56978678703308\n",
      "\n",
      "EPOCH 46  (with max 8000), loss: 0.5251915454864502\n",
      "train time for 46 epochs, was 38.20377206802368\n",
      "\n",
      "EPOCH 48  (with max 8000), loss: 0.05464164912700653\n",
      "train time for 48 epochs, was 39.85942554473877\n",
      "\n",
      "EPOCH 50  (with max 8000), loss: 0.04166237264871597\n",
      "train time for 50 epochs, was 41.49439716339111\n",
      "\n",
      "EPOCH 52  (with max 8000), loss: 0.030179934576153755\n",
      "train time for 52 epochs, was 43.12847638130188\n",
      "\n",
      "EPOCH 54  (with max 8000), loss: 0.019801080226898193\n",
      "train time for 54 epochs, was 44.763259410858154\n",
      "\n",
      "EPOCH 56  (with max 8000), loss: 0.015609105117619038\n",
      "train time for 56 epochs, was 46.39741134643555\n",
      "\n",
      "EPOCH 58  (with max 8000), loss: 0.01911824755370617\n",
      "train time for 58 epochs, was 48.032328605651855\n",
      "\n",
      "EPOCH 60  (with max 8000), loss: 0.01693120039999485\n",
      "train time for 60 epochs, was 49.66957688331604\n",
      "\n",
      "EPOCH 62  (with max 8000), loss: 0.015384674072265625\n",
      "train time for 62 epochs, was 51.3430061340332\n",
      "\n",
      "EPOCH 64  (with max 8000), loss: 0.013010676950216293\n",
      "train time for 64 epochs, was 53.01670789718628\n",
      "\n",
      "EPOCH 66  (with max 8000), loss: 0.025169141590595245\n",
      "train time for 66 epochs, was 54.68977475166321\n",
      "\n",
      "EPOCH 68  (with max 8000), loss: 0.01529768854379654\n",
      "train time for 68 epochs, was 56.36676001548767\n",
      "\n",
      "EPOCH 70  (with max 8000), loss: 0.018611863255500793\n",
      "train time for 70 epochs, was 58.042059659957886\n",
      "\n",
      "EPOCH 72  (with max 8000), loss: 0.01409867126494646\n",
      "train time for 72 epochs, was 59.7182822227478\n",
      "\n",
      "EPOCH 74  (with max 8000), loss: 0.008042595349252224\n",
      "train time for 74 epochs, was 61.39717173576355\n",
      "\n",
      "EPOCH 76  (with max 8000), loss: 0.01286111306399107\n",
      "train time for 76 epochs, was 63.07126450538635\n",
      "\n",
      "EPOCH 78  (with max 8000), loss: 0.013264515437185764\n",
      "train time for 78 epochs, was 64.75306701660156\n",
      "\n",
      "EPOCH 80  (with max 8000), loss: 0.006797404494136572\n",
      "train time for 80 epochs, was 66.42552995681763\n",
      "\n",
      "EPOCH 82  (with max 8000), loss: 0.005678343120962381\n",
      "train time for 82 epochs, was 68.09952974319458\n",
      "\n",
      "EPOCH 84  (with max 8000), loss: 0.0045724124647676945\n",
      "train time for 84 epochs, was 69.77572321891785\n",
      "\n",
      "EPOCH 86  (with max 8000), loss: 0.015234203077852726\n",
      "train time for 86 epochs, was 71.45516157150269\n",
      "\n",
      "EPOCH 88  (with max 8000), loss: 0.010299088433384895\n",
      "train time for 88 epochs, was 73.1355836391449\n",
      "\n",
      "EPOCH 90  (with max 8000), loss: 0.014198052696883678\n",
      "train time for 90 epochs, was 74.81233739852905\n",
      "\n",
      "EPOCH 92  (with max 8000), loss: 0.009106730110943317\n",
      "train time for 92 epochs, was 76.4969539642334\n",
      "\n",
      "EPOCH 94  (with max 8000), loss: 0.01010820735245943\n",
      "train time for 94 epochs, was 78.1749975681305\n",
      "\n",
      "EPOCH 96  (with max 8000), loss: 0.020849505439400673\n",
      "train time for 96 epochs, was 79.84994769096375\n",
      "\n",
      "EPOCH 98  (with max 8000), loss: 0.010204404592514038\n",
      "train time for 98 epochs, was 81.52557349205017\n",
      "\n",
      "EPOCH 100  (with max 8000), loss: 0.008660937659442425\n",
      "train time for 100 epochs, was 83.19813299179077\n",
      "\n",
      "EPOCH 102  (with max 8000), loss: 0.01620291732251644\n",
      "train time for 102 epochs, was 84.87510967254639\n",
      "\n",
      "EPOCH 104  (with max 8000), loss: 0.009034482762217522\n",
      "train time for 104 epochs, was 86.5499165058136\n",
      "\n",
      "EPOCH 106  (with max 8000), loss: 0.015072443522512913\n",
      "train time for 106 epochs, was 88.22624683380127\n",
      "\n",
      "EPOCH 108  (with max 8000), loss: 0.016084222123026848\n",
      "train time for 108 epochs, was 89.90145349502563\n",
      "\n",
      "EPOCH 110  (with max 8000), loss: 0.011413419619202614\n",
      "train time for 110 epochs, was 91.57577967643738\n",
      "\n",
      "EPOCH 112  (with max 8000), loss: 0.016639025881886482\n",
      "train time for 112 epochs, was 93.25689435005188\n",
      "\n",
      "EPOCH 114  (with max 8000), loss: 0.025739120319485664\n",
      "train time for 114 epochs, was 94.933340549469\n",
      "\n",
      "EPOCH 116  (with max 8000), loss: 0.016313550993800163\n",
      "train time for 116 epochs, was 96.609375\n",
      "\n",
      "EPOCH 118  (with max 8000), loss: 0.019169310107827187\n",
      "train time for 118 epochs, was 98.28369927406311\n",
      "\n",
      "EPOCH 120  (with max 8000), loss: 0.01502908207476139\n",
      "train time for 120 epochs, was 99.9609010219574\n",
      "\n",
      "EPOCH 122  (with max 8000), loss: 0.018026961013674736\n",
      "train time for 122 epochs, was 101.63569164276123\n",
      "\n",
      "EPOCH 124  (with max 8000), loss: 0.023909084498882294\n",
      "train time for 124 epochs, was 103.30979490280151\n",
      "\n",
      "EPOCH 126  (with max 8000), loss: 0.017808444797992706\n",
      "train time for 126 epochs, was 104.98661470413208\n",
      "\n",
      "EPOCH 128  (with max 8000), loss: 0.006757962983101606\n",
      "train time for 128 epochs, was 106.65895652770996\n",
      "\n",
      "EPOCH 130  (with max 8000), loss: 0.012270423583686352\n",
      "train time for 130 epochs, was 108.33582258224487\n",
      "\n",
      "EPOCH 132  (with max 8000), loss: 0.01113617792725563\n",
      "train time for 132 epochs, was 110.00883197784424\n",
      "\n",
      "EPOCH 134  (with max 8000), loss: 0.014828217215836048\n",
      "train time for 134 epochs, was 111.67974925041199\n",
      "\n",
      "EPOCH 136  (with max 8000), loss: 0.010649057105183601\n",
      "train time for 136 epochs, was 113.37223100662231\n",
      "\n",
      "EPOCH 138  (with max 8000), loss: 0.011365017853677273\n",
      "train time for 138 epochs, was 115.04759788513184\n",
      "\n",
      "EPOCH 140  (with max 8000), loss: 0.010571771301329136\n",
      "train time for 140 epochs, was 116.72041726112366\n",
      "\n",
      "EPOCH 142  (with max 8000), loss: 0.021924464032053947\n",
      "train time for 142 epochs, was 118.39385342597961\n",
      "\n",
      "EPOCH 144  (with max 8000), loss: 0.011900321580469608\n",
      "train time for 144 epochs, was 120.06709408760071\n",
      "\n",
      "EPOCH 146  (with max 8000), loss: 0.01505108643323183\n",
      "train time for 146 epochs, was 121.74030089378357\n",
      "\n",
      "EPOCH 148  (with max 8000), loss: 0.014777461998164654\n",
      "train time for 148 epochs, was 123.4157087802887\n",
      "\n",
      "EPOCH 150  (with max 8000), loss: 0.014177704229950905\n",
      "train time for 150 epochs, was 125.08979201316833\n",
      "\n",
      "EPOCH 152  (with max 8000), loss: 0.022157343104481697\n",
      "train time for 152 epochs, was 126.76402235031128\n",
      "\n",
      "EPOCH 154  (with max 8000), loss: 0.015050317160785198\n",
      "train time for 154 epochs, was 128.43737387657166\n",
      "\n",
      "EPOCH 156  (with max 8000), loss: 0.01833128184080124\n",
      "train time for 156 epochs, was 130.10936975479126\n",
      "\n",
      "EPOCH 158  (with max 8000), loss: 0.01249734777957201\n",
      "train time for 158 epochs, was 131.7848448753357\n",
      "\n",
      "EPOCH 160  (with max 8000), loss: 0.01785605400800705\n",
      "train time for 160 epochs, was 133.45697331428528\n",
      "\n",
      "EPOCH 162  (with max 8000), loss: 0.017280826345086098\n",
      "train time for 162 epochs, was 135.1559762954712\n",
      "\n",
      "EPOCH 164  (with max 8000), loss: 0.0064991838298738\n",
      "train time for 164 epochs, was 136.8324830532074\n",
      "\n",
      "EPOCH 166  (with max 8000), loss: 0.014786424115300179\n",
      "train time for 166 epochs, was 138.50776386260986\n",
      "\n",
      "EPOCH 168  (with max 8000), loss: 0.006980225443840027\n",
      "train time for 168 epochs, was 140.1790041923523\n",
      "\n",
      "EPOCH 170  (with max 8000), loss: 0.01650283671915531\n",
      "train time for 170 epochs, was 141.8558793067932\n",
      "\n",
      "EPOCH 172  (with max 8000), loss: 0.013326329179108143\n",
      "train time for 172 epochs, was 143.5288553237915\n",
      "\n",
      "EPOCH 174  (with max 8000), loss: 0.012922297231853008\n",
      "train time for 174 epochs, was 145.20444107055664\n",
      "\n",
      "EPOCH 176  (with max 8000), loss: 0.010324141010642052\n",
      "train time for 176 epochs, was 146.877587556839\n",
      "\n",
      "EPOCH 178  (with max 8000), loss: 0.007872611284255981\n",
      "train time for 178 epochs, was 148.551127910614\n",
      "\n",
      "EPOCH 180  (with max 8000), loss: 0.009447991847991943\n",
      "train time for 180 epochs, was 150.22701358795166\n",
      "\n",
      "EPOCH 182  (with max 8000), loss: 0.0058274297043681145\n",
      "train time for 182 epochs, was 151.9053235054016\n",
      "\n",
      "EPOCH 184  (with max 8000), loss: 0.0062693385407328606\n",
      "train time for 184 epochs, was 153.58088660240173\n",
      "\n",
      "EPOCH 186  (with max 8000), loss: 0.01207919605076313\n",
      "train time for 186 epochs, was 155.25355410575867\n",
      "\n",
      "EPOCH 188  (with max 8000), loss: 0.007677839603275061\n",
      "train time for 188 epochs, was 156.92691922187805\n",
      "\n",
      "EPOCH 190  (with max 8000), loss: 0.012023111805319786\n",
      "train time for 190 epochs, was 158.59952855110168\n",
      "\n",
      "EPOCH 192  (with max 8000), loss: 0.01204123068600893\n",
      "train time for 192 epochs, was 160.27363228797913\n",
      "\n",
      "EPOCH 194  (with max 8000), loss: 0.005139930173754692\n",
      "train time for 194 epochs, was 161.94776558876038\n",
      "\n",
      "EPOCH 196  (with max 8000), loss: 0.012783241458237171\n",
      "train time for 196 epochs, was 163.61944150924683\n",
      "\n",
      "EPOCH 198  (with max 8000), loss: 0.01313682459294796\n",
      "train time for 198 epochs, was 165.29390859603882\n",
      "\n",
      "EPOCH 200  (with max 8000), loss: 0.05353553593158722\n",
      "train time for 200 epochs, was 166.96681928634644\n",
      "\n",
      "EPOCH 200 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_0200.pth\n",
      "\n",
      "EPOCH 202  (with max 8000), loss: 0.01396156009286642\n",
      "train time for 202 epochs, was 168.67699933052063\n",
      "\n",
      "EPOCH 204  (with max 8000), loss: 0.014522600919008255\n",
      "train time for 204 epochs, was 170.35198616981506\n",
      "\n",
      "EPOCH 206  (with max 8000), loss: 0.010689443908631802\n",
      "train time for 206 epochs, was 172.0258150100708\n",
      "\n",
      "EPOCH 208  (with max 8000), loss: 0.010093806311488152\n",
      "train time for 208 epochs, was 173.70393228530884\n",
      "\n",
      "EPOCH 210  (with max 8000), loss: 0.00920373946428299\n",
      "train time for 210 epochs, was 175.37588953971863\n",
      "\n",
      "EPOCH 212  (with max 8000), loss: 0.010873371735215187\n",
      "train time for 212 epochs, was 177.04909324645996\n",
      "\n",
      "EPOCH 214  (with max 8000), loss: 0.014826458878815174\n",
      "train time for 214 epochs, was 178.72381067276\n",
      "\n",
      "EPOCH 216  (with max 8000), loss: 0.0024987971410155296\n",
      "train time for 216 epochs, was 180.39658570289612\n",
      "\n",
      "EPOCH 218  (with max 8000), loss: 0.008441008627414703\n",
      "train time for 218 epochs, was 182.07056188583374\n",
      "\n",
      "EPOCH 220  (with max 8000), loss: 0.01014634221792221\n",
      "train time for 220 epochs, was 183.74243068695068\n",
      "\n",
      "EPOCH 222  (with max 8000), loss: 0.009816192090511322\n",
      "train time for 222 epochs, was 185.41479063034058\n",
      "\n",
      "EPOCH 224  (with max 8000), loss: 0.005117460619658232\n",
      "train time for 224 epochs, was 187.11397194862366\n",
      "\n",
      "EPOCH 226  (with max 8000), loss: 0.0064392234198749065\n",
      "train time for 226 epochs, was 188.78749918937683\n",
      "\n",
      "EPOCH 228  (with max 8000), loss: 0.009311752393841743\n",
      "train time for 228 epochs, was 190.45937061309814\n",
      "\n",
      "EPOCH 230  (with max 8000), loss: 0.011364824138581753\n",
      "train time for 230 epochs, was 192.13405776023865\n",
      "\n",
      "EPOCH 232  (with max 8000), loss: 0.012269914150238037\n",
      "train time for 232 epochs, was 193.80795764923096\n",
      "\n",
      "EPOCH 234  (with max 8000), loss: 0.012738296762108803\n",
      "train time for 234 epochs, was 195.4820535182953\n",
      "\n",
      "EPOCH 236  (with max 8000), loss: 0.005081635434180498\n",
      "train time for 236 epochs, was 197.1581380367279\n",
      "\n",
      "EPOCH 238  (with max 8000), loss: 0.009100093506276608\n",
      "train time for 238 epochs, was 198.83131909370422\n",
      "\n",
      "EPOCH 240  (with max 8000), loss: 0.01294772606343031\n",
      "train time for 240 epochs, was 200.50473523139954\n",
      "\n",
      "EPOCH 242  (with max 8000), loss: 0.011878914199769497\n",
      "train time for 242 epochs, was 202.17908549308777\n",
      "\n",
      "EPOCH 244  (with max 8000), loss: 0.003594965673983097\n",
      "train time for 244 epochs, was 203.8530969619751\n",
      "\n",
      "EPOCH 246  (with max 8000), loss: 0.00718926265835762\n",
      "train time for 246 epochs, was 205.52669620513916\n",
      "\n",
      "EPOCH 248  (with max 8000), loss: 0.00527563039213419\n",
      "train time for 248 epochs, was 207.20380520820618\n",
      "\n",
      "EPOCH 250  (with max 8000), loss: 0.006618037819862366\n",
      "train time for 250 epochs, was 208.87663674354553\n",
      "\n",
      "EPOCH 252  (with max 8000), loss: 0.01003324892371893\n",
      "train time for 252 epochs, was 210.550306558609\n",
      "\n",
      "EPOCH 254  (with max 8000), loss: 0.004437597468495369\n",
      "train time for 254 epochs, was 212.22566556930542\n",
      "\n",
      "EPOCH 256  (with max 8000), loss: 0.00818728655576706\n",
      "train time for 256 epochs, was 213.9021029472351\n",
      "\n",
      "EPOCH 258  (with max 8000), loss: 0.012041718699038029\n",
      "train time for 258 epochs, was 215.57430219650269\n",
      "\n",
      "EPOCH 260  (with max 8000), loss: 0.0021247905679047108\n",
      "train time for 260 epochs, was 217.24876856803894\n",
      "\n",
      "EPOCH 262  (with max 8000), loss: 0.009969333186745644\n",
      "train time for 262 epochs, was 218.92345881462097\n",
      "\n",
      "EPOCH 264  (with max 8000), loss: 0.008448116481304169\n",
      "train time for 264 epochs, was 220.59707736968994\n",
      "\n",
      "EPOCH 266  (with max 8000), loss: 0.00611915485933423\n",
      "train time for 266 epochs, was 222.27491521835327\n",
      "\n",
      "EPOCH 268  (with max 8000), loss: 0.0071088941767811775\n",
      "train time for 268 epochs, was 223.97308993339539\n",
      "\n",
      "EPOCH 270  (with max 8000), loss: 0.007767647970467806\n",
      "train time for 270 epochs, was 225.64749026298523\n",
      "\n",
      "EPOCH 272  (with max 8000), loss: 0.00390321621671319\n",
      "train time for 272 epochs, was 227.32392406463623\n",
      "\n",
      "EPOCH 274  (with max 8000), loss: 0.013610078021883965\n",
      "train time for 274 epochs, was 228.99812841415405\n",
      "\n",
      "EPOCH 276  (with max 8000), loss: 0.0072631132788956165\n",
      "train time for 276 epochs, was 230.6741316318512\n",
      "\n",
      "EPOCH 278  (with max 8000), loss: 0.014162571169435978\n",
      "train time for 278 epochs, was 232.34744310379028\n",
      "\n",
      "EPOCH 280  (with max 8000), loss: 0.006600267719477415\n",
      "train time for 280 epochs, was 234.02038431167603\n",
      "\n",
      "EPOCH 282  (with max 8000), loss: 0.011044432409107685\n",
      "train time for 282 epochs, was 235.6933674812317\n",
      "\n",
      "EPOCH 284  (with max 8000), loss: 0.007976818829774857\n",
      "train time for 284 epochs, was 237.3693277835846\n",
      "\n",
      "EPOCH 286  (with max 8000), loss: 0.009829273447394371\n",
      "train time for 286 epochs, was 239.04073429107666\n",
      "\n",
      "EPOCH 288  (with max 8000), loss: 0.004656492732465267\n",
      "train time for 288 epochs, was 240.71200799942017\n",
      "\n",
      "EPOCH 290  (with max 8000), loss: 0.008551451377570629\n",
      "train time for 290 epochs, was 242.38731241226196\n",
      "\n",
      "EPOCH 292  (with max 8000), loss: 0.012416526675224304\n",
      "train time for 292 epochs, was 244.0616705417633\n",
      "\n",
      "EPOCH 294  (with max 8000), loss: 0.007247129920870066\n",
      "train time for 294 epochs, was 245.73304843902588\n",
      "\n",
      "EPOCH 296  (with max 8000), loss: 0.006758658681064844\n",
      "train time for 296 epochs, was 247.40484309196472\n",
      "\n",
      "EPOCH 298  (with max 8000), loss: 0.01510564424097538\n",
      "train time for 298 epochs, was 249.07504987716675\n",
      "\n",
      "EPOCH 300  (with max 8000), loss: 0.004801605828106403\n",
      "train time for 300 epochs, was 250.74734711647034\n",
      "\n",
      "EPOCH 302  (with max 8000), loss: 0.004366383887827396\n",
      "train time for 302 epochs, was 252.4464168548584\n",
      "\n",
      "EPOCH 304  (with max 8000), loss: 0.007026369217783213\n",
      "train time for 304 epochs, was 254.13229942321777\n",
      "\n",
      "EPOCH 306  (with max 8000), loss: 0.009391004219651222\n",
      "train time for 306 epochs, was 255.8241536617279\n",
      "\n",
      "EPOCH 308  (with max 8000), loss: 0.010026843287050724\n",
      "train time for 308 epochs, was 257.50035190582275\n",
      "\n",
      "EPOCH 310  (with max 8000), loss: 0.012696828693151474\n",
      "train time for 310 epochs, was 259.17302942276\n",
      "\n",
      "EPOCH 312  (with max 8000), loss: 0.0030599108431488276\n",
      "train time for 312 epochs, was 260.871533870697\n",
      "\n",
      "EPOCH 314  (with max 8000), loss: 0.007301351521164179\n",
      "train time for 314 epochs, was 262.546169757843\n",
      "\n",
      "EPOCH 316  (with max 8000), loss: 0.003594011999666691\n",
      "train time for 316 epochs, was 264.2228591442108\n",
      "\n",
      "EPOCH 318  (with max 8000), loss: 0.003400471294298768\n",
      "train time for 318 epochs, was 265.8953945636749\n",
      "\n",
      "EPOCH 320  (with max 8000), loss: 0.004264840856194496\n",
      "train time for 320 epochs, was 267.57378792762756\n",
      "\n",
      "EPOCH 322  (with max 8000), loss: 0.006039261817932129\n",
      "train time for 322 epochs, was 269.24823570251465\n",
      "\n",
      "EPOCH 324  (with max 8000), loss: 0.013135701417922974\n",
      "train time for 324 epochs, was 270.92314982414246\n",
      "\n",
      "EPOCH 326  (with max 8000), loss: 0.010546044446527958\n",
      "train time for 326 epochs, was 272.5959544181824\n",
      "\n",
      "EPOCH 328  (with max 8000), loss: 0.005545927211642265\n",
      "train time for 328 epochs, was 274.2706627845764\n",
      "\n",
      "EPOCH 330  (with max 8000), loss: 0.008071348071098328\n",
      "train time for 330 epochs, was 275.94253873825073\n",
      "\n",
      "EPOCH 332  (with max 8000), loss: 0.004967555403709412\n",
      "train time for 332 epochs, was 277.6200485229492\n",
      "\n",
      "EPOCH 334  (with max 8000), loss: 0.008591366931796074\n",
      "train time for 334 epochs, was 279.30859088897705\n",
      "\n",
      "EPOCH 336  (with max 8000), loss: 0.008033833466470242\n",
      "train time for 336 epochs, was 280.9848620891571\n",
      "\n",
      "EPOCH 338  (with max 8000), loss: 0.004222497344017029\n",
      "train time for 338 epochs, was 282.6568350791931\n",
      "\n",
      "EPOCH 340  (with max 8000), loss: 0.006148826330900192\n",
      "train time for 340 epochs, was 284.3324122428894\n",
      "\n",
      "EPOCH 342  (with max 8000), loss: 0.007526390720158815\n",
      "train time for 342 epochs, was 286.00598978996277\n",
      "\n",
      "EPOCH 344  (with max 8000), loss: 0.004346941132098436\n",
      "train time for 344 epochs, was 287.6787598133087\n",
      "\n",
      "EPOCH 346  (with max 8000), loss: 0.007982783019542694\n",
      "train time for 346 epochs, was 289.35248827934265\n",
      "\n",
      "EPOCH 348  (with max 8000), loss: 0.008533976040780544\n",
      "train time for 348 epochs, was 291.02409958839417\n",
      "\n",
      "EPOCH 350  (with max 8000), loss: 0.014502049423754215\n",
      "train time for 350 epochs, was 292.6988286972046\n",
      "\n",
      "EPOCH 352  (with max 8000), loss: 0.008003490045666695\n",
      "train time for 352 epochs, was 294.3731973171234\n",
      "\n",
      "EPOCH 354  (with max 8000), loss: 0.007967885583639145\n",
      "train time for 354 epochs, was 296.04503440856934\n",
      "\n",
      "EPOCH 356  (with max 8000), loss: 0.40568479895591736\n",
      "train time for 356 epochs, was 297.7239098548889\n",
      "\n",
      "EPOCH 358  (with max 8000), loss: 0.025090862065553665\n",
      "train time for 358 epochs, was 299.39540219306946\n",
      "\n",
      "EPOCH 360  (with max 8000), loss: 0.009859846904873848\n",
      "train time for 360 epochs, was 301.0742452144623\n",
      "\n",
      "EPOCH 362  (with max 8000), loss: 0.010015446692705154\n",
      "train time for 362 epochs, was 302.74709033966064\n",
      "\n",
      "EPOCH 364  (with max 8000), loss: 0.006349754519760609\n",
      "train time for 364 epochs, was 304.4197278022766\n",
      "\n",
      "EPOCH 366  (with max 8000), loss: 0.009598860517144203\n",
      "train time for 366 epochs, was 306.0911626815796\n",
      "\n",
      "EPOCH 368  (with max 8000), loss: 0.006123725324869156\n",
      "train time for 368 epochs, was 307.7642331123352\n",
      "\n",
      "EPOCH 370  (with max 8000), loss: 0.009781746193766594\n",
      "train time for 370 epochs, was 309.43887305259705\n",
      "\n",
      "EPOCH 372  (with max 8000), loss: 0.00844272319227457\n",
      "train time for 372 epochs, was 311.1087441444397\n",
      "\n",
      "EPOCH 374  (with max 8000), loss: 0.014970189891755581\n",
      "train time for 374 epochs, was 312.78282833099365\n",
      "\n",
      "EPOCH 376  (with max 8000), loss: 0.007024487014859915\n",
      "train time for 376 epochs, was 314.45615243911743\n",
      "\n",
      "EPOCH 378  (with max 8000), loss: 0.004739927127957344\n",
      "train time for 378 epochs, was 316.1283805370331\n",
      "\n",
      "EPOCH 380  (with max 8000), loss: 0.00756653631106019\n",
      "train time for 380 epochs, was 317.8030652999878\n",
      "\n",
      "EPOCH 382  (with max 8000), loss: 0.0078214630484581\n",
      "train time for 382 epochs, was 319.4753198623657\n",
      "\n",
      "EPOCH 384  (with max 8000), loss: 0.010514074005186558\n",
      "train time for 384 epochs, was 321.1484489440918\n",
      "\n",
      "EPOCH 386  (with max 8000), loss: 0.006514545530080795\n",
      "train time for 386 epochs, was 322.8237931728363\n",
      "\n",
      "EPOCH 388  (with max 8000), loss: 0.003916741348803043\n",
      "train time for 388 epochs, was 324.49644446372986\n",
      "\n",
      "EPOCH 390  (with max 8000), loss: 0.004158904775977135\n",
      "train time for 390 epochs, was 326.1697177886963\n",
      "\n",
      "EPOCH 392  (with max 8000), loss: 0.0007841286715120077\n",
      "train time for 392 epochs, was 327.8410873413086\n",
      "\n",
      "EPOCH 394  (with max 8000), loss: 0.004309265408664942\n",
      "train time for 394 epochs, was 329.5399842262268\n",
      "\n",
      "EPOCH 396  (with max 8000), loss: 0.0026456457562744617\n",
      "train time for 396 epochs, was 331.22385573387146\n",
      "\n",
      "EPOCH 398  (with max 8000), loss: 0.0036648849491029978\n",
      "train time for 398 epochs, was 332.9063198566437\n",
      "\n",
      "EPOCH 400  (with max 8000), loss: 0.007695354521274567\n",
      "train time for 400 epochs, was 334.6022934913635\n",
      "\n",
      "EPOCH 400 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_0400.pth\n",
      "\n",
      "EPOCH 402  (with max 8000), loss: 0.003907714504748583\n",
      "train time for 402 epochs, was 336.3152241706848\n",
      "\n",
      "EPOCH 404  (with max 8000), loss: 0.00270528020337224\n",
      "train time for 404 epochs, was 337.9921112060547\n",
      "\n",
      "EPOCH 406  (with max 8000), loss: 0.0042882515117526054\n",
      "train time for 406 epochs, was 339.6754939556122\n",
      "\n",
      "EPOCH 408  (with max 8000), loss: 0.004712217021733522\n",
      "train time for 408 epochs, was 341.33158349990845\n",
      "\n",
      "EPOCH 410  (with max 8000), loss: 0.002167151076719165\n",
      "train time for 410 epochs, was 342.98462986946106\n",
      "\n",
      "EPOCH 412  (with max 8000), loss: 0.006689964793622494\n",
      "train time for 412 epochs, was 344.6375963687897\n",
      "\n",
      "EPOCH 414  (with max 8000), loss: 0.0039258552715182304\n",
      "train time for 414 epochs, was 346.2926287651062\n",
      "\n",
      "EPOCH 416  (with max 8000), loss: 0.003775116754695773\n",
      "train time for 416 epochs, was 347.9475255012512\n",
      "\n",
      "EPOCH 418  (with max 8000), loss: 0.0055735232308506966\n",
      "train time for 418 epochs, was 349.5999937057495\n",
      "\n",
      "EPOCH 420  (with max 8000), loss: 0.008257852867245674\n",
      "train time for 420 epochs, was 351.25315165519714\n",
      "\n",
      "EPOCH 422  (with max 8000), loss: 0.005999560467898846\n",
      "train time for 422 epochs, was 352.9058816432953\n",
      "\n",
      "EPOCH 424  (with max 8000), loss: 0.006839909125119448\n",
      "train time for 424 epochs, was 354.5566656589508\n",
      "\n",
      "EPOCH 426  (with max 8000), loss: 0.0031504719518125057\n",
      "train time for 426 epochs, was 356.21143555641174\n",
      "\n",
      "EPOCH 428  (with max 8000), loss: 0.0060486383736133575\n",
      "train time for 428 epochs, was 357.8644235134125\n",
      "\n",
      "EPOCH 430  (with max 8000), loss: 0.0056794979609549046\n",
      "train time for 430 epochs, was 359.5175836086273\n",
      "\n",
      "EPOCH 432  (with max 8000), loss: 0.006426726933568716\n",
      "train time for 432 epochs, was 361.1706635951996\n",
      "\n",
      "EPOCH 434  (with max 8000), loss: 0.008791034109890461\n",
      "train time for 434 epochs, was 362.82313203811646\n",
      "\n",
      "EPOCH 436  (with max 8000), loss: 0.0046936762519180775\n",
      "train time for 436 epochs, was 364.4757549762726\n",
      "\n",
      "EPOCH 438  (with max 8000), loss: 0.5208955407142639\n",
      "train time for 438 epochs, was 366.1293292045593\n",
      "\n",
      "EPOCH 440  (with max 8000), loss: 0.019218865782022476\n",
      "train time for 440 epochs, was 367.7864394187927\n",
      "\n",
      "EPOCH 442  (with max 8000), loss: 0.02104051411151886\n",
      "train time for 442 epochs, was 369.4415109157562\n",
      "\n",
      "EPOCH 444  (with max 8000), loss: 0.008347222581505775\n",
      "train time for 444 epochs, was 371.0967035293579\n",
      "\n",
      "EPOCH 446  (with max 8000), loss: 0.004673768300563097\n",
      "train time for 446 epochs, was 372.7745246887207\n",
      "\n",
      "EPOCH 448  (with max 8000), loss: 0.0037359814159572124\n",
      "train time for 448 epochs, was 374.4299602508545\n",
      "\n",
      "EPOCH 450  (with max 8000), loss: 0.0070295496843755245\n",
      "train time for 450 epochs, was 376.08297967910767\n",
      "\n",
      "EPOCH 452  (with max 8000), loss: 0.00931887049227953\n",
      "train time for 452 epochs, was 377.73569893836975\n",
      "\n",
      "EPOCH 454  (with max 8000), loss: 0.0031139752827584743\n",
      "train time for 454 epochs, was 379.3889172077179\n",
      "\n",
      "EPOCH 456  (with max 8000), loss: 0.0040460857562720776\n",
      "train time for 456 epochs, was 381.0505530834198\n",
      "\n",
      "EPOCH 458  (with max 8000), loss: 0.007335669826716185\n",
      "train time for 458 epochs, was 382.702760219574\n",
      "\n",
      "EPOCH 460  (with max 8000), loss: 0.0031365016475319862\n",
      "train time for 460 epochs, was 384.35967683792114\n",
      "\n",
      "EPOCH 462  (with max 8000), loss: 0.008282075636088848\n",
      "train time for 462 epochs, was 386.01311707496643\n",
      "\n",
      "EPOCH 464  (with max 8000), loss: 0.007448484189808369\n",
      "train time for 464 epochs, was 387.66918563842773\n",
      "\n",
      "EPOCH 466  (with max 8000), loss: 0.002965230494737625\n",
      "train time for 466 epochs, was 389.3297472000122\n",
      "\n",
      "EPOCH 468  (with max 8000), loss: 0.004468584433197975\n",
      "train time for 468 epochs, was 390.9827711582184\n",
      "\n",
      "EPOCH 470  (with max 8000), loss: 0.003497955622151494\n",
      "train time for 470 epochs, was 392.6335048675537\n",
      "\n",
      "EPOCH 472  (with max 8000), loss: 0.00680113397538662\n",
      "train time for 472 epochs, was 394.28857707977295\n",
      "\n",
      "EPOCH 474  (with max 8000), loss: 0.005587056744843721\n",
      "train time for 474 epochs, was 395.9430019855499\n",
      "\n",
      "EPOCH 476  (with max 8000), loss: 0.004755846224725246\n",
      "train time for 476 epochs, was 397.59541511535645\n",
      "\n",
      "EPOCH 478  (with max 8000), loss: 0.005684212315827608\n",
      "train time for 478 epochs, was 399.24818301200867\n",
      "\n",
      "EPOCH 480  (with max 8000), loss: 0.0018507090862840414\n",
      "train time for 480 epochs, was 400.9006712436676\n",
      "\n",
      "EPOCH 482  (with max 8000), loss: 0.0068601639941334724\n",
      "train time for 482 epochs, was 402.55352234840393\n",
      "\n",
      "EPOCH 484  (with max 8000), loss: 0.003685428062453866\n",
      "train time for 484 epochs, was 404.20669078826904\n",
      "\n",
      "EPOCH 486  (with max 8000), loss: 0.003880896605551243\n",
      "train time for 486 epochs, was 405.85963439941406\n",
      "\n",
      "EPOCH 488  (with max 8000), loss: 0.0048599219880998135\n",
      "train time for 488 epochs, was 407.5123972892761\n",
      "\n",
      "EPOCH 490  (with max 8000), loss: 0.007203701883554459\n",
      "train time for 490 epochs, was 409.1721999645233\n",
      "\n",
      "EPOCH 492  (with max 8000), loss: 0.004481516778469086\n",
      "train time for 492 epochs, was 410.83329701423645\n",
      "\n",
      "EPOCH 494  (with max 8000), loss: 0.0033976503182202578\n",
      "train time for 494 epochs, was 412.4860701560974\n",
      "\n",
      "EPOCH 496  (with max 8000), loss: 0.0049393982626497746\n",
      "train time for 496 epochs, was 414.14115715026855\n",
      "\n",
      "EPOCH 498  (with max 8000), loss: 0.0031303672585636377\n",
      "train time for 498 epochs, was 415.7930338382721\n",
      "\n",
      "EPOCH 500  (with max 8000), loss: 0.0038141708355396986\n",
      "train time for 500 epochs, was 417.451632976532\n",
      "\n",
      "EPOCH 502  (with max 8000), loss: 0.002245931886136532\n",
      "train time for 502 epochs, was 419.10645818710327\n",
      "\n",
      "EPOCH 504  (with max 8000), loss: 0.002661380684003234\n",
      "train time for 504 epochs, was 420.75742173194885\n",
      "\n",
      "EPOCH 506  (with max 8000), loss: 0.006313784513622522\n",
      "train time for 506 epochs, was 422.4119472503662\n",
      "\n",
      "EPOCH 508  (with max 8000), loss: 0.017958765849471092\n",
      "train time for 508 epochs, was 424.0650041103363\n",
      "\n",
      "EPOCH 510  (with max 8000), loss: 0.008941331878304482\n",
      "train time for 510 epochs, was 425.7179219722748\n",
      "\n",
      "EPOCH 512  (with max 8000), loss: 0.00921502523124218\n",
      "train time for 512 epochs, was 427.37108850479126\n",
      "\n",
      "EPOCH 514  (with max 8000), loss: 0.01989581063389778\n",
      "train time for 514 epochs, was 429.02330565452576\n",
      "\n",
      "EPOCH 516  (with max 8000), loss: 0.00835874117910862\n",
      "train time for 516 epochs, was 430.67883133888245\n",
      "\n",
      "EPOCH 518  (with max 8000), loss: 0.008112347684800625\n",
      "train time for 518 epochs, was 432.3284204006195\n",
      "\n",
      "EPOCH 520  (with max 8000), loss: 0.002506546676158905\n",
      "train time for 520 epochs, was 433.9789807796478\n",
      "\n",
      "EPOCH 522  (with max 8000), loss: 0.0052681430242955685\n",
      "train time for 522 epochs, was 435.6360206604004\n",
      "\n",
      "EPOCH 524  (with max 8000), loss: 0.010105443187057972\n",
      "train time for 524 epochs, was 437.2892303466797\n",
      "\n",
      "EPOCH 526  (with max 8000), loss: 0.010724177584052086\n",
      "train time for 526 epochs, was 439.0001447200775\n",
      "\n",
      "EPOCH 528  (with max 8000), loss: 0.0037927657831460238\n",
      "train time for 528 epochs, was 440.6527178287506\n",
      "\n",
      "EPOCH 530  (with max 8000), loss: 0.0039347256533801556\n",
      "train time for 530 epochs, was 442.30795097351074\n",
      "\n",
      "EPOCH 532  (with max 8000), loss: 0.011899166740477085\n",
      "train time for 532 epochs, was 443.98184084892273\n",
      "\n",
      "EPOCH 534  (with max 8000), loss: 0.0028868140652775764\n",
      "train time for 534 epochs, was 445.6430423259735\n",
      "\n",
      "EPOCH 536  (with max 8000), loss: 0.005556932184845209\n",
      "train time for 536 epochs, was 447.34444880485535\n",
      "\n",
      "EPOCH 538  (with max 8000), loss: 0.010994866490364075\n",
      "train time for 538 epochs, was 449.0429861545563\n",
      "\n",
      "EPOCH 540  (with max 8000), loss: 0.0019446165533736348\n",
      "train time for 540 epochs, was 450.6967041492462\n",
      "\n",
      "EPOCH 542  (with max 8000), loss: 0.005116961896419525\n",
      "train time for 542 epochs, was 452.3490619659424\n",
      "\n",
      "EPOCH 544  (with max 8000), loss: 0.011320398189127445\n",
      "train time for 544 epochs, was 454.00106739997864\n",
      "\n",
      "EPOCH 546  (with max 8000), loss: 0.005134310107678175\n",
      "train time for 546 epochs, was 455.6614279747009\n",
      "\n",
      "EPOCH 548  (with max 8000), loss: 0.013624732382595539\n",
      "train time for 548 epochs, was 457.3451888561249\n",
      "\n",
      "EPOCH 550  (with max 8000), loss: 0.01008417084813118\n",
      "train time for 550 epochs, was 459.0034611225128\n",
      "\n",
      "EPOCH 552  (with max 8000), loss: 0.007766003720462322\n",
      "train time for 552 epochs, was 460.65499448776245\n",
      "\n",
      "EPOCH 554  (with max 8000), loss: 0.009226481430232525\n",
      "train time for 554 epochs, was 462.30425214767456\n",
      "\n",
      "EPOCH 556  (with max 8000), loss: 0.0047662821598351\n",
      "train time for 556 epochs, was 463.9926142692566\n",
      "\n",
      "EPOCH 558  (with max 8000), loss: 0.005725115537643433\n",
      "train time for 558 epochs, was 465.6494948863983\n",
      "\n",
      "EPOCH 560  (with max 8000), loss: 0.003788284258916974\n",
      "train time for 560 epochs, was 467.2911515235901\n",
      "\n",
      "EPOCH 562  (with max 8000), loss: 0.005054845474660397\n",
      "train time for 562 epochs, was 468.94677782058716\n",
      "\n",
      "EPOCH 564  (with max 8000), loss: 0.009390530176460743\n",
      "train time for 564 epochs, was 470.5812864303589\n",
      "\n",
      "EPOCH 566  (with max 8000), loss: 0.004330325871706009\n",
      "train time for 566 epochs, was 472.2182366847992\n",
      "\n",
      "EPOCH 568  (with max 8000), loss: 0.009365186095237732\n",
      "train time for 568 epochs, was 473.8532338142395\n",
      "\n",
      "EPOCH 570  (with max 8000), loss: 0.0065224491991102695\n",
      "train time for 570 epochs, was 475.48763060569763\n",
      "\n",
      "EPOCH 572  (with max 8000), loss: 0.005085773300379515\n",
      "train time for 572 epochs, was 477.12248253822327\n",
      "\n",
      "EPOCH 574  (with max 8000), loss: 0.007169700693339109\n",
      "train time for 574 epochs, was 478.7595212459564\n",
      "\n",
      "EPOCH 576  (with max 8000), loss: 0.4695833921432495\n",
      "train time for 576 epochs, was 480.39604020118713\n",
      "\n",
      "EPOCH 578  (with max 8000), loss: 0.014646251685917377\n",
      "train time for 578 epochs, was 482.03077149391174\n",
      "\n",
      "EPOCH 580  (with max 8000), loss: 0.01172027550637722\n",
      "train time for 580 epochs, was 483.67824721336365\n",
      "\n",
      "EPOCH 582  (with max 8000), loss: 0.009005690924823284\n",
      "train time for 582 epochs, was 485.3356409072876\n",
      "\n",
      "EPOCH 584  (with max 8000), loss: 0.00281332666054368\n",
      "train time for 584 epochs, was 486.9739053249359\n",
      "\n",
      "EPOCH 586  (with max 8000), loss: 0.0044281273148953915\n",
      "train time for 586 epochs, was 488.6371560096741\n",
      "\n",
      "EPOCH 588  (with max 8000), loss: 0.0034884654451161623\n",
      "train time for 588 epochs, was 490.27865195274353\n",
      "\n",
      "EPOCH 590  (with max 8000), loss: 0.00958638172596693\n",
      "train time for 590 epochs, was 491.9188988208771\n",
      "\n",
      "EPOCH 592  (with max 8000), loss: 0.0015864558517932892\n",
      "train time for 592 epochs, was 493.5706932544708\n",
      "\n",
      "EPOCH 594  (with max 8000), loss: 0.004099922254681587\n",
      "train time for 594 epochs, was 495.26794028282166\n",
      "\n",
      "EPOCH 596  (with max 8000), loss: 0.004734453279525042\n",
      "train time for 596 epochs, was 496.9464695453644\n",
      "\n",
      "EPOCH 598  (with max 8000), loss: 0.005474632140249014\n",
      "train time for 598 epochs, was 498.6262836456299\n",
      "\n",
      "EPOCH 600  (with max 8000), loss: 0.00226191570982337\n",
      "train time for 600 epochs, was 500.31315755844116\n",
      "\n",
      "EPOCH 600 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_0600.pth\n",
      "\n",
      "EPOCH 602  (with max 8000), loss: 0.004693903960287571\n",
      "train time for 602 epochs, was 502.03063797950745\n",
      "\n",
      "EPOCH 604  (with max 8000), loss: 0.0028229542076587677\n",
      "train time for 604 epochs, was 503.7088646888733\n",
      "\n",
      "EPOCH 606  (with max 8000), loss: 0.00844418816268444\n",
      "train time for 606 epochs, was 505.38599848747253\n",
      "\n",
      "EPOCH 608  (with max 8000), loss: 0.006182544399052858\n",
      "train time for 608 epochs, was 507.0599994659424\n",
      "\n",
      "EPOCH 610  (with max 8000), loss: 0.0017900519305840135\n",
      "train time for 610 epochs, was 508.74710392951965\n",
      "\n",
      "EPOCH 612  (with max 8000), loss: 0.003448686795309186\n",
      "train time for 612 epochs, was 510.4254937171936\n",
      "\n",
      "EPOCH 614  (with max 8000), loss: 0.001063465024344623\n",
      "train time for 614 epochs, was 512.1029579639435\n",
      "\n",
      "EPOCH 616  (with max 8000), loss: 0.002533826744183898\n",
      "train time for 616 epochs, was 513.7813436985016\n",
      "\n",
      "EPOCH 618  (with max 8000), loss: 0.0072639635764062405\n",
      "train time for 618 epochs, was 515.4593472480774\n",
      "\n",
      "EPOCH 620  (with max 8000), loss: 0.005052863620221615\n",
      "train time for 620 epochs, was 517.1327705383301\n",
      "\n",
      "EPOCH 622  (with max 8000), loss: 0.0056215738877654076\n",
      "train time for 622 epochs, was 518.808874130249\n",
      "\n",
      "EPOCH 624  (with max 8000), loss: 0.004960209596902132\n",
      "train time for 624 epochs, was 520.4935801029205\n",
      "\n",
      "EPOCH 626  (with max 8000), loss: 0.007700164336711168\n",
      "train time for 626 epochs, was 522.1766581535339\n",
      "\n",
      "EPOCH 628  (with max 8000), loss: 0.001044265110976994\n",
      "train time for 628 epochs, was 523.8538944721222\n",
      "\n",
      "EPOCH 630  (with max 8000), loss: 0.00203976733610034\n",
      "train time for 630 epochs, was 525.5356106758118\n",
      "\n",
      "EPOCH 632  (with max 8000), loss: 0.09253378212451935\n",
      "train time for 632 epochs, was 527.185474395752\n",
      "\n",
      "EPOCH 634  (with max 8000), loss: 0.01012493297457695\n",
      "train time for 634 epochs, was 528.8512389659882\n",
      "\n",
      "EPOCH 636  (with max 8000), loss: 0.004739066585898399\n",
      "train time for 636 epochs, was 530.4985949993134\n",
      "\n",
      "EPOCH 638  (with max 8000), loss: 0.002600194187834859\n",
      "train time for 638 epochs, was 532.1808843612671\n",
      "\n",
      "EPOCH 640  (with max 8000), loss: 0.005865426734089851\n",
      "train time for 640 epochs, was 533.8574593067169\n",
      "\n",
      "EPOCH 642  (with max 8000), loss: 0.005624751094728708\n",
      "train time for 642 epochs, was 535.4919788837433\n",
      "\n",
      "EPOCH 644  (with max 8000), loss: 0.004207606427371502\n",
      "train time for 644 epochs, was 537.1647958755493\n",
      "\n",
      "EPOCH 646  (with max 8000), loss: 0.004208059515804052\n",
      "train time for 646 epochs, was 538.8052725791931\n",
      "\n",
      "EPOCH 648  (with max 8000), loss: 0.008621297776699066\n",
      "train time for 648 epochs, was 540.4621007442474\n",
      "\n",
      "EPOCH 650  (with max 8000), loss: 0.0025389729999005795\n",
      "train time for 650 epochs, was 542.112931728363\n",
      "\n",
      "EPOCH 652  (with max 8000), loss: 0.0025534285232424736\n",
      "train time for 652 epochs, was 543.7744901180267\n",
      "\n",
      "EPOCH 654  (with max 8000), loss: 0.005268045235425234\n",
      "train time for 654 epochs, was 545.4105520248413\n",
      "\n",
      "EPOCH 656  (with max 8000), loss: 0.00821848213672638\n",
      "train time for 656 epochs, was 547.0871353149414\n",
      "\n",
      "EPOCH 658  (with max 8000), loss: 0.007774551399052143\n",
      "train time for 658 epochs, was 548.782075881958\n",
      "\n",
      "EPOCH 660  (with max 8000), loss: 0.007459617219865322\n",
      "train time for 660 epochs, was 550.4250190258026\n",
      "\n",
      "EPOCH 662  (with max 8000), loss: 0.011558995582163334\n",
      "train time for 662 epochs, was 552.0658957958221\n",
      "\n",
      "EPOCH 664  (with max 8000), loss: 0.0026827394030988216\n",
      "train time for 664 epochs, was 553.7062895298004\n",
      "\n",
      "EPOCH 666  (with max 8000), loss: 0.01000883337110281\n",
      "train time for 666 epochs, was 555.3460521697998\n",
      "\n",
      "EPOCH 668  (with max 8000), loss: 0.009555370546877384\n",
      "train time for 668 epochs, was 557.0198156833649\n",
      "\n",
      "EPOCH 670  (with max 8000), loss: 0.006596508901566267\n",
      "train time for 670 epochs, was 558.659786939621\n",
      "\n",
      "EPOCH 672  (with max 8000), loss: 0.010304237715899944\n",
      "train time for 672 epochs, was 560.296201467514\n",
      "\n",
      "EPOCH 674  (with max 8000), loss: 0.004076425451785326\n",
      "train time for 674 epochs, was 561.9343779087067\n",
      "\n",
      "EPOCH 676  (with max 8000), loss: 0.00392697099596262\n",
      "train time for 676 epochs, was 563.5794882774353\n",
      "\n",
      "EPOCH 678  (with max 8000), loss: 0.007459479384124279\n",
      "train time for 678 epochs, was 565.2181098461151\n",
      "\n",
      "EPOCH 680  (with max 8000), loss: 0.004766884725540876\n",
      "train time for 680 epochs, was 566.8588230609894\n",
      "\n",
      "EPOCH 682  (with max 8000), loss: 0.004709651228040457\n",
      "train time for 682 epochs, was 568.4957871437073\n",
      "\n",
      "EPOCH 684  (with max 8000), loss: 0.004983748774975538\n",
      "train time for 684 epochs, was 570.133914232254\n",
      "\n",
      "EPOCH 686  (with max 8000), loss: 0.006004312075674534\n",
      "train time for 686 epochs, was 571.7730803489685\n",
      "\n",
      "EPOCH 688  (with max 8000), loss: 0.013835364021360874\n",
      "train time for 688 epochs, was 573.4183316230774\n",
      "\n",
      "EPOCH 690  (with max 8000), loss: 0.0063346619717776775\n",
      "train time for 690 epochs, was 575.0545151233673\n",
      "\n",
      "EPOCH 692  (with max 8000), loss: 0.014677200466394424\n",
      "train time for 692 epochs, was 576.7294099330902\n",
      "\n",
      "EPOCH 694  (with max 8000), loss: 0.007102645933628082\n",
      "train time for 694 epochs, was 578.4035913944244\n",
      "\n",
      "EPOCH 696  (with max 8000), loss: 0.0024588133674114943\n",
      "train time for 696 epochs, was 580.0783312320709\n",
      "\n",
      "EPOCH 698  (with max 8000), loss: 0.004669841378927231\n",
      "train time for 698 epochs, was 581.7611203193665\n",
      "\n",
      "EPOCH 700  (with max 8000), loss: 0.0053990245796740055\n",
      "train time for 700 epochs, was 583.4419965744019\n",
      "\n",
      "EPOCH 702  (with max 8000), loss: 0.00458725867792964\n",
      "train time for 702 epochs, was 585.1170575618744\n",
      "\n",
      "EPOCH 704  (with max 8000), loss: 0.00510198250412941\n",
      "train time for 704 epochs, was 586.8068642616272\n",
      "\n",
      "EPOCH 706  (with max 8000), loss: 0.005320737138390541\n",
      "train time for 706 epochs, was 588.4985463619232\n",
      "\n",
      "EPOCH 708  (with max 8000), loss: 0.005287903361022472\n",
      "train time for 708 epochs, was 590.1742308139801\n",
      "\n",
      "EPOCH 710  (with max 8000), loss: 0.006002024747431278\n",
      "train time for 710 epochs, was 591.8536422252655\n",
      "\n",
      "EPOCH 712  (with max 8000), loss: 0.00718920212239027\n",
      "train time for 712 epochs, was 593.5468728542328\n",
      "\n",
      "EPOCH 714  (with max 8000), loss: 0.029253356158733368\n",
      "train time for 714 epochs, was 595.2214410305023\n",
      "\n",
      "EPOCH 716  (with max 8000), loss: 0.011174904182553291\n",
      "train time for 716 epochs, was 596.8945281505585\n",
      "\n",
      "EPOCH 718  (with max 8000), loss: 0.01656476780772209\n",
      "train time for 718 epochs, was 598.5517077445984\n",
      "\n",
      "EPOCH 720  (with max 8000), loss: 0.026666421443223953\n",
      "train time for 720 epochs, was 600.2141518592834\n",
      "\n",
      "EPOCH 722  (with max 8000), loss: 0.016744375228881836\n",
      "train time for 722 epochs, was 601.8973960876465\n",
      "\n",
      "EPOCH 724  (with max 8000), loss: 0.00963354017585516\n",
      "train time for 724 epochs, was 603.5778684616089\n",
      "\n",
      "EPOCH 726  (with max 8000), loss: 0.004386198241263628\n",
      "train time for 726 epochs, was 605.2337987422943\n",
      "\n",
      "EPOCH 728  (with max 8000), loss: 0.0058920723386108875\n",
      "train time for 728 epochs, was 606.908463716507\n",
      "\n",
      "EPOCH 730  (with max 8000), loss: 0.013404167257249355\n",
      "train time for 730 epochs, was 608.5848906040192\n",
      "\n",
      "EPOCH 732  (with max 8000), loss: 0.007841931656002998\n",
      "train time for 732 epochs, was 610.2614152431488\n",
      "\n",
      "EPOCH 734  (with max 8000), loss: 0.011897589080035686\n",
      "train time for 734 epochs, was 611.9353795051575\n",
      "\n",
      "EPOCH 736  (with max 8000), loss: 0.007263348437845707\n",
      "train time for 736 epochs, was 613.6105637550354\n",
      "\n",
      "EPOCH 738  (with max 8000), loss: 0.0017402765806764364\n",
      "train time for 738 epochs, was 615.2700383663177\n",
      "\n",
      "EPOCH 740  (with max 8000), loss: 0.005030730739235878\n",
      "train time for 740 epochs, was 616.9253327846527\n",
      "\n",
      "EPOCH 742  (with max 8000), loss: 0.004334848374128342\n",
      "train time for 742 epochs, was 618.5612227916718\n",
      "\n",
      "EPOCH 744  (with max 8000), loss: 0.005815956275910139\n",
      "train time for 744 epochs, was 620.1964037418365\n",
      "\n",
      "EPOCH 746  (with max 8000), loss: 0.0031078308820724487\n",
      "train time for 746 epochs, was 621.8311932086945\n",
      "\n",
      "EPOCH 748  (with max 8000), loss: 0.0019993570167571306\n",
      "train time for 748 epochs, was 623.470986366272\n",
      "\n",
      "EPOCH 750  (with max 8000), loss: 0.0016662308480590582\n",
      "train time for 750 epochs, was 625.1054840087891\n",
      "\n",
      "EPOCH 752  (with max 8000), loss: 0.0021672085858881474\n",
      "train time for 752 epochs, was 626.7426333427429\n",
      "\n",
      "EPOCH 754  (with max 8000), loss: 0.0032635752577334642\n",
      "train time for 754 epochs, was 628.3778204917908\n",
      "\n",
      "EPOCH 756  (with max 8000), loss: 0.00615364545956254\n",
      "train time for 756 epochs, was 630.0415325164795\n",
      "\n",
      "EPOCH 758  (with max 8000), loss: 0.0018845063168555498\n",
      "train time for 758 epochs, was 631.6764907836914\n",
      "\n",
      "EPOCH 760  (with max 8000), loss: 0.0017695585265755653\n",
      "train time for 760 epochs, was 633.311749458313\n",
      "\n",
      "EPOCH 762  (with max 8000), loss: 0.004702914971858263\n",
      "train time for 762 epochs, was 634.9461207389832\n",
      "\n",
      "EPOCH 764  (with max 8000), loss: 0.0030201079789549112\n",
      "train time for 764 epochs, was 636.581300497055\n",
      "\n",
      "EPOCH 766  (with max 8000), loss: 0.004998954012989998\n",
      "train time for 766 epochs, was 638.2166056632996\n",
      "\n",
      "EPOCH 768  (with max 8000), loss: 0.000963892787694931\n",
      "train time for 768 epochs, was 639.8510854244232\n",
      "\n",
      "EPOCH 770  (with max 8000), loss: 0.0036189048551023006\n",
      "train time for 770 epochs, was 641.4860472679138\n",
      "\n",
      "EPOCH 772  (with max 8000), loss: 0.0035602760035544634\n",
      "train time for 772 epochs, was 643.1205589771271\n",
      "\n",
      "EPOCH 774  (with max 8000), loss: 0.006324380170553923\n",
      "train time for 774 epochs, was 644.7556772232056\n",
      "\n",
      "EPOCH 776  (with max 8000), loss: 0.003545153420418501\n",
      "train time for 776 epochs, was 646.4284272193909\n",
      "\n",
      "EPOCH 778  (with max 8000), loss: 0.003373151645064354\n",
      "train time for 778 epochs, was 648.1034240722656\n",
      "\n",
      "EPOCH 780  (with max 8000), loss: 0.0012825781013816595\n",
      "train time for 780 epochs, was 649.7790930271149\n",
      "\n",
      "EPOCH 782  (with max 8000), loss: 0.008660003542900085\n",
      "train time for 782 epochs, was 651.4521241188049\n",
      "\n",
      "EPOCH 784  (with max 8000), loss: 0.003857251023873687\n",
      "train time for 784 epochs, was 653.1292288303375\n",
      "\n",
      "EPOCH 786  (with max 8000), loss: 0.004054034594446421\n",
      "train time for 786 epochs, was 654.8068685531616\n",
      "\n",
      "EPOCH 788  (with max 8000), loss: 0.004734324757009745\n",
      "train time for 788 epochs, was 656.4807937145233\n",
      "\n",
      "EPOCH 790  (with max 8000), loss: 0.005726458504796028\n",
      "train time for 790 epochs, was 658.1530435085297\n",
      "\n",
      "EPOCH 792  (with max 8000), loss: 0.002799344016239047\n",
      "train time for 792 epochs, was 659.8288812637329\n",
      "\n",
      "EPOCH 794  (with max 8000), loss: 0.005721097346395254\n",
      "train time for 794 epochs, was 661.5037603378296\n",
      "\n",
      "EPOCH 796  (with max 8000), loss: 0.010885817930102348\n",
      "train time for 796 epochs, was 663.1768205165863\n",
      "\n",
      "EPOCH 798  (with max 8000), loss: 0.002639569342136383\n",
      "train time for 798 epochs, was 664.8503012657166\n",
      "\n",
      "EPOCH 800  (with max 8000), loss: 0.009426482021808624\n",
      "train time for 800 epochs, was 666.5272393226624\n",
      "\n",
      "EPOCH 800 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_0800.pth\n",
      "\n",
      "EPOCH 802  (with max 8000), loss: 0.005939055699855089\n",
      "train time for 802 epochs, was 668.2339720726013\n",
      "\n",
      "EPOCH 804  (with max 8000), loss: 0.009113001637160778\n",
      "train time for 804 epochs, was 669.9073629379272\n",
      "\n",
      "EPOCH 806  (with max 8000), loss: 0.0022999632637947798\n",
      "train time for 806 epochs, was 671.5804736614227\n",
      "\n",
      "EPOCH 808  (with max 8000), loss: 0.009035276249051094\n",
      "train time for 808 epochs, was 673.2536046504974\n",
      "\n",
      "EPOCH 810  (with max 8000), loss: 0.8301580548286438\n",
      "train time for 810 epochs, was 674.929131269455\n",
      "\n",
      "EPOCH 812  (with max 8000), loss: 0.026812735944986343\n",
      "train time for 812 epochs, was 676.6025824546814\n",
      "\n",
      "EPOCH 814  (with max 8000), loss: 0.009383457712829113\n",
      "train time for 814 epochs, was 678.2812509536743\n",
      "\n",
      "EPOCH 816  (with max 8000), loss: 0.012244711630046368\n",
      "train time for 816 epochs, was 679.9559772014618\n",
      "\n",
      "EPOCH 818  (with max 8000), loss: 0.006593206897377968\n",
      "train time for 818 epochs, was 681.6322281360626\n",
      "\n",
      "EPOCH 820  (with max 8000), loss: 0.008112381212413311\n",
      "train time for 820 epochs, was 683.3064095973969\n",
      "\n",
      "EPOCH 822  (with max 8000), loss: 0.013201527297496796\n",
      "train time for 822 epochs, was 684.9796957969666\n",
      "\n",
      "EPOCH 824  (with max 8000), loss: 0.010006170719861984\n",
      "train time for 824 epochs, was 686.6537330150604\n",
      "\n",
      "EPOCH 826  (with max 8000), loss: 0.010201571509242058\n",
      "train time for 826 epochs, was 688.3291306495667\n",
      "\n",
      "EPOCH 828  (with max 8000), loss: 0.008133080787956715\n",
      "train time for 828 epochs, was 690.002096414566\n",
      "\n",
      "EPOCH 830  (with max 8000), loss: 0.010626756586134434\n",
      "train time for 830 epochs, was 691.6777038574219\n",
      "\n",
      "EPOCH 832  (with max 8000), loss: 0.005915314424782991\n",
      "train time for 832 epochs, was 693.3539702892303\n",
      "\n",
      "EPOCH 834  (with max 8000), loss: 0.0058023687452077866\n",
      "train time for 834 epochs, was 695.0305948257446\n",
      "\n",
      "EPOCH 836  (with max 8000), loss: 0.008544993586838245\n",
      "train time for 836 epochs, was 696.703266620636\n",
      "\n",
      "EPOCH 838  (with max 8000), loss: 0.0018861002754420042\n",
      "train time for 838 epochs, was 698.380049943924\n",
      "\n",
      "EPOCH 840  (with max 8000), loss: 0.015302704647183418\n",
      "train time for 840 epochs, was 700.0551812648773\n",
      "\n",
      "EPOCH 842  (with max 8000), loss: 0.0050060744397342205\n",
      "train time for 842 epochs, was 701.7282862663269\n",
      "\n",
      "EPOCH 844  (with max 8000), loss: 0.004509628750383854\n",
      "train time for 844 epochs, was 703.4081664085388\n",
      "\n",
      "EPOCH 846  (with max 8000), loss: 0.012605313211679459\n",
      "train time for 846 epochs, was 705.0888361930847\n",
      "\n",
      "EPOCH 848  (with max 8000), loss: 0.00378087698481977\n",
      "train time for 848 epochs, was 706.766176700592\n",
      "\n",
      "EPOCH 850  (with max 8000), loss: 0.003426254028454423\n",
      "train time for 850 epochs, was 708.4419722557068\n",
      "\n",
      "EPOCH 852  (with max 8000), loss: 0.00332840858027339\n",
      "train time for 852 epochs, was 710.1157193183899\n",
      "\n",
      "EPOCH 854  (with max 8000), loss: 0.010369922965765\n",
      "train time for 854 epochs, was 711.788902759552\n",
      "\n",
      "EPOCH 856  (with max 8000), loss: 0.007747962139546871\n",
      "train time for 856 epochs, was 713.4670271873474\n",
      "\n",
      "EPOCH 858  (with max 8000), loss: 0.003545863786712289\n",
      "train time for 858 epochs, was 715.1398324966431\n",
      "\n",
      "EPOCH 860  (with max 8000), loss: 0.010849022306501865\n",
      "train time for 860 epochs, was 716.8148348331451\n",
      "\n",
      "EPOCH 862  (with max 8000), loss: 0.006197676993906498\n",
      "train time for 862 epochs, was 718.4909448623657\n",
      "\n",
      "EPOCH 864  (with max 8000), loss: 0.009477534331381321\n",
      "train time for 864 epochs, was 720.1644463539124\n",
      "\n",
      "EPOCH 866  (with max 8000), loss: 0.0044240630231797695\n",
      "train time for 866 epochs, was 721.8442115783691\n",
      "\n",
      "EPOCH 868  (with max 8000), loss: 0.0025968425907194614\n",
      "train time for 868 epochs, was 723.5217461585999\n",
      "\n",
      "EPOCH 870  (with max 8000), loss: 0.002883852692320943\n",
      "train time for 870 epochs, was 725.1947169303894\n",
      "\n",
      "EPOCH 872  (with max 8000), loss: 0.005942214280366898\n",
      "train time for 872 epochs, was 726.868898153305\n",
      "\n",
      "EPOCH 874  (with max 8000), loss: 0.0038475384935736656\n",
      "train time for 874 epochs, was 728.5431928634644\n",
      "\n",
      "EPOCH 876  (with max 8000), loss: 0.004607131704688072\n",
      "train time for 876 epochs, was 730.2176959514618\n",
      "\n",
      "EPOCH 878  (with max 8000), loss: 0.0035779057070612907\n",
      "train time for 878 epochs, was 731.8912146091461\n",
      "\n",
      "EPOCH 880  (with max 8000), loss: 0.0027466577012091875\n",
      "train time for 880 epochs, was 733.564425945282\n",
      "\n",
      "EPOCH 882  (with max 8000), loss: 0.005887313280254602\n",
      "train time for 882 epochs, was 735.2395775318146\n",
      "\n",
      "EPOCH 884  (with max 8000), loss: 0.0021506964694708586\n",
      "train time for 884 epochs, was 736.9144530296326\n",
      "\n",
      "EPOCH 886  (with max 8000), loss: 0.003283547004684806\n",
      "train time for 886 epochs, was 738.5887622833252\n",
      "\n",
      "EPOCH 888  (with max 8000), loss: 0.0054768649861216545\n",
      "train time for 888 epochs, was 740.2627530097961\n",
      "\n",
      "EPOCH 890  (with max 8000), loss: 0.0056190756149590015\n",
      "train time for 890 epochs, was 741.9377648830414\n",
      "\n",
      "EPOCH 892  (with max 8000), loss: 0.006657730787992477\n",
      "train time for 892 epochs, was 743.6125326156616\n",
      "\n",
      "EPOCH 894  (with max 8000), loss: 0.0021979163866490126\n",
      "train time for 894 epochs, was 745.2869462966919\n",
      "\n",
      "EPOCH 896  (with max 8000), loss: 0.004845191724598408\n",
      "train time for 896 epochs, was 746.9625992774963\n",
      "\n",
      "EPOCH 898  (with max 8000), loss: 0.006283967290073633\n",
      "train time for 898 epochs, was 748.6358828544617\n",
      "\n",
      "EPOCH 900  (with max 8000), loss: 0.005720537155866623\n",
      "train time for 900 epochs, was 750.3084254264832\n",
      "\n",
      "EPOCH 902  (with max 8000), loss: 0.00640071602538228\n",
      "train time for 902 epochs, was 751.9835093021393\n",
      "\n",
      "EPOCH 904  (with max 8000), loss: 0.010983072221279144\n",
      "train time for 904 epochs, was 753.6573040485382\n",
      "\n",
      "EPOCH 906  (with max 8000), loss: 0.007001257501542568\n",
      "train time for 906 epochs, was 755.3311717510223\n",
      "\n",
      "EPOCH 908  (with max 8000), loss: 0.0026430608704686165\n",
      "train time for 908 epochs, was 757.0048007965088\n",
      "\n",
      "EPOCH 910  (with max 8000), loss: 0.0024470435455441475\n",
      "train time for 910 epochs, was 758.6805558204651\n",
      "\n",
      "EPOCH 912  (with max 8000), loss: 0.00788056943565607\n",
      "train time for 912 epochs, was 760.3544383049011\n",
      "\n",
      "EPOCH 914  (with max 8000), loss: 0.003302555298432708\n",
      "train time for 914 epochs, was 762.0297002792358\n",
      "\n",
      "EPOCH 916  (with max 8000), loss: 0.005160653963685036\n",
      "train time for 916 epochs, was 763.7015492916107\n",
      "\n",
      "EPOCH 918  (with max 8000), loss: 0.004292662255465984\n",
      "train time for 918 epochs, was 765.3764159679413\n",
      "\n",
      "EPOCH 920  (with max 8000), loss: 0.006566048599779606\n",
      "train time for 920 epochs, was 767.0507037639618\n",
      "\n",
      "EPOCH 922  (with max 8000), loss: 0.006596507970243692\n",
      "train time for 922 epochs, was 768.7277112007141\n",
      "\n",
      "EPOCH 924  (with max 8000), loss: 0.005573258735239506\n",
      "train time for 924 epochs, was 770.4020164012909\n",
      "\n",
      "EPOCH 926  (with max 8000), loss: 0.004545267671346664\n",
      "train time for 926 epochs, was 772.0753216743469\n",
      "\n",
      "EPOCH 928  (with max 8000), loss: 0.004440923687070608\n",
      "train time for 928 epochs, was 773.7490484714508\n",
      "\n",
      "EPOCH 930  (with max 8000), loss: 0.0038118683733046055\n",
      "train time for 930 epochs, was 775.4279789924622\n",
      "\n",
      "EPOCH 932  (with max 8000), loss: 0.005005591548979282\n",
      "train time for 932 epochs, was 777.1314234733582\n",
      "\n",
      "EPOCH 934  (with max 8000), loss: 0.005598882213234901\n",
      "train time for 934 epochs, was 778.8246774673462\n",
      "\n",
      "EPOCH 936  (with max 8000), loss: 0.002386830048635602\n",
      "train time for 936 epochs, was 780.515095949173\n",
      "\n",
      "EPOCH 938  (with max 8000), loss: 0.005616602022200823\n",
      "train time for 938 epochs, was 782.1980724334717\n",
      "\n",
      "EPOCH 940  (with max 8000), loss: 0.005378373432904482\n",
      "train time for 940 epochs, was 783.8745157718658\n",
      "\n",
      "EPOCH 942  (with max 8000), loss: 0.0066503239795565605\n",
      "train time for 942 epochs, was 785.5521423816681\n",
      "\n",
      "EPOCH 944  (with max 8000), loss: 0.007761219050735235\n",
      "train time for 944 epochs, was 787.2284932136536\n",
      "\n",
      "EPOCH 946  (with max 8000), loss: 0.005636980291455984\n",
      "train time for 946 epochs, was 788.9017522335052\n",
      "\n",
      "EPOCH 948  (with max 8000), loss: 0.004787453915923834\n",
      "train time for 948 epochs, was 790.5764110088348\n",
      "\n",
      "EPOCH 950  (with max 8000), loss: 0.019541742280125618\n",
      "train time for 950 epochs, was 792.2496106624603\n",
      "\n",
      "EPOCH 952  (with max 8000), loss: 0.004407213069498539\n",
      "train time for 952 epochs, was 793.9348938465118\n",
      "\n",
      "EPOCH 954  (with max 8000), loss: 0.00744283152744174\n",
      "train time for 954 epochs, was 795.6125149726868\n",
      "\n",
      "EPOCH 956  (with max 8000), loss: 0.003895377041772008\n",
      "train time for 956 epochs, was 797.287106513977\n",
      "\n",
      "EPOCH 958  (with max 8000), loss: 0.00437500886619091\n",
      "train time for 958 epochs, was 798.9660320281982\n",
      "\n",
      "EPOCH 960  (with max 8000), loss: 0.011750089935958385\n",
      "train time for 960 epochs, was 800.642338514328\n",
      "\n",
      "EPOCH 962  (with max 8000), loss: 0.009967920370399952\n",
      "train time for 962 epochs, was 802.3169302940369\n",
      "\n",
      "EPOCH 964  (with max 8000), loss: 0.0066794417798519135\n",
      "train time for 964 epochs, was 803.9915502071381\n",
      "\n",
      "EPOCH 966  (with max 8000), loss: 0.003294998547062278\n",
      "train time for 966 epochs, was 805.6664214134216\n",
      "\n",
      "EPOCH 968  (with max 8000), loss: 0.003511689370498061\n",
      "train time for 968 epochs, was 807.3413999080658\n",
      "\n",
      "EPOCH 970  (with max 8000), loss: 0.004620913881808519\n",
      "train time for 970 epochs, was 809.0033459663391\n",
      "\n",
      "EPOCH 972  (with max 8000), loss: 0.0034746299497783184\n",
      "train time for 972 epochs, was 810.6533598899841\n",
      "\n",
      "EPOCH 974  (with max 8000), loss: 0.004785711411386728\n",
      "train time for 974 epochs, was 812.3188683986664\n",
      "\n",
      "EPOCH 976  (with max 8000), loss: 0.004527481272816658\n",
      "train time for 976 epochs, was 813.983371257782\n",
      "\n",
      "EPOCH 978  (with max 8000), loss: 0.0067629688419401646\n",
      "train time for 978 epochs, was 815.6464765071869\n",
      "\n",
      "EPOCH 980  (with max 8000), loss: 0.004804724827408791\n",
      "train time for 980 epochs, was 817.3399546146393\n",
      "\n",
      "EPOCH 982  (with max 8000), loss: 0.007649707142263651\n",
      "train time for 982 epochs, was 818.977258682251\n",
      "\n",
      "EPOCH 984  (with max 8000), loss: 0.0033361243549734354\n",
      "train time for 984 epochs, was 820.6380739212036\n",
      "\n",
      "EPOCH 986  (with max 8000), loss: 0.003862905316054821\n",
      "train time for 986 epochs, was 822.2797689437866\n",
      "\n",
      "EPOCH 988  (with max 8000), loss: 0.005445078946650028\n",
      "train time for 988 epochs, was 823.9175169467926\n",
      "\n",
      "EPOCH 990  (with max 8000), loss: 0.0048753321170806885\n",
      "train time for 990 epochs, was 825.552472114563\n",
      "\n",
      "EPOCH 992  (with max 8000), loss: 0.0049619306810200214\n",
      "train time for 992 epochs, was 827.2158036231995\n",
      "\n",
      "EPOCH 994  (with max 8000), loss: 0.007387132849544287\n",
      "train time for 994 epochs, was 828.8642911911011\n",
      "\n",
      "EPOCH 996  (with max 8000), loss: 0.0021540431771427393\n",
      "train time for 996 epochs, was 830.5013959407806\n",
      "\n",
      "EPOCH 998  (with max 8000), loss: 0.01063232496380806\n",
      "train time for 998 epochs, was 832.1612522602081\n",
      "\n",
      "EPOCH 1000  (with max 8000), loss: 0.004631746094673872\n",
      "train time for 1000 epochs, was 833.81493973732\n",
      "\n",
      "EPOCH 1000 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_1000.pth\n",
      "\n",
      "EPOCH 1002  (with max 8000), loss: 0.005306505598127842\n",
      "train time for 1002 epochs, was 835.5296857357025\n",
      "\n",
      "EPOCH 1004  (with max 8000), loss: 0.29979610443115234\n",
      "train time for 1004 epochs, was 837.2061750888824\n",
      "\n",
      "EPOCH 1006  (with max 8000), loss: 0.019856275990605354\n",
      "train time for 1006 epochs, was 838.9101984500885\n",
      "\n",
      "EPOCH 1008  (with max 8000), loss: 0.007781586609780788\n",
      "train time for 1008 epochs, was 840.5445275306702\n",
      "\n",
      "EPOCH 1010  (with max 8000), loss: 0.00748413847759366\n",
      "train time for 1010 epochs, was 842.1988337039948\n",
      "\n",
      "EPOCH 1012  (with max 8000), loss: 0.009842784143984318\n",
      "train time for 1012 epochs, was 843.844714641571\n",
      "\n",
      "EPOCH 1014  (with max 8000), loss: 0.005900043528527021\n",
      "train time for 1014 epochs, was 845.4819197654724\n",
      "\n",
      "EPOCH 1016  (with max 8000), loss: 0.003110111691057682\n",
      "train time for 1016 epochs, was 847.147932767868\n",
      "\n",
      "EPOCH 1018  (with max 8000), loss: 0.002669035457074642\n",
      "train time for 1018 epochs, was 848.7955467700958\n",
      "\n",
      "EPOCH 1020  (with max 8000), loss: 0.0054291835986077785\n",
      "train time for 1020 epochs, was 850.4648041725159\n",
      "\n",
      "EPOCH 1022  (with max 8000), loss: 0.0003008664061781019\n",
      "train time for 1022 epochs, was 852.121985912323\n",
      "\n",
      "EPOCH 1024  (with max 8000), loss: 0.005020902492105961\n",
      "train time for 1024 epochs, was 853.7605142593384\n",
      "\n",
      "EPOCH 1026  (with max 8000), loss: 0.0013376242714002728\n",
      "train time for 1026 epochs, was 855.4272027015686\n",
      "\n",
      "EPOCH 1028  (with max 8000), loss: 0.0026712261606007814\n",
      "train time for 1028 epochs, was 857.0620527267456\n",
      "\n",
      "EPOCH 1030  (with max 8000), loss: 0.004158323165029287\n",
      "train time for 1030 epochs, was 858.724062204361\n",
      "\n",
      "EPOCH 1032  (with max 8000), loss: 0.002882177708670497\n",
      "train time for 1032 epochs, was 860.3849775791168\n",
      "\n",
      "EPOCH 1034  (with max 8000), loss: 0.0021876709070056677\n",
      "train time for 1034 epochs, was 862.0282621383667\n",
      "\n",
      "EPOCH 1036  (with max 8000), loss: 0.0011172067606821656\n",
      "train time for 1036 epochs, was 863.6890802383423\n",
      "\n",
      "EPOCH 1038  (with max 8000), loss: 0.0019669535104185343\n",
      "train time for 1038 epochs, was 865.3493719100952\n",
      "\n",
      "EPOCH 1040  (with max 8000), loss: 0.0028773092199116945\n",
      "train time for 1040 epochs, was 867.0217761993408\n",
      "\n",
      "EPOCH 1042  (with max 8000), loss: 0.0008642384200356901\n",
      "train time for 1042 epochs, was 868.6901443004608\n",
      "\n",
      "EPOCH 1044  (with max 8000), loss: 0.0006449357024393976\n",
      "train time for 1044 epochs, was 870.3525757789612\n",
      "\n",
      "EPOCH 1046  (with max 8000), loss: 0.0010671293130144477\n",
      "train time for 1046 epochs, was 871.9913034439087\n",
      "\n",
      "EPOCH 1048  (with max 8000), loss: 0.002634482691064477\n",
      "train time for 1048 epochs, was 873.6295120716095\n",
      "\n",
      "EPOCH 1050  (with max 8000), loss: 0.005446908995509148\n",
      "train time for 1050 epochs, was 875.2971305847168\n",
      "\n",
      "EPOCH 1052  (with max 8000), loss: 0.0021903763990849257\n",
      "train time for 1052 epochs, was 876.9537024497986\n",
      "\n",
      "EPOCH 1054  (with max 8000), loss: 0.003364423755556345\n",
      "train time for 1054 epochs, was 878.5863783359528\n",
      "\n",
      "EPOCH 1056  (with max 8000), loss: 0.0005994908860884607\n",
      "train time for 1056 epochs, was 880.2237334251404\n",
      "\n",
      "EPOCH 1058  (with max 8000), loss: 0.0018159776227548718\n",
      "train time for 1058 epochs, was 881.8565406799316\n",
      "\n",
      "EPOCH 1060  (with max 8000), loss: 0.004840791691094637\n",
      "train time for 1060 epochs, was 883.4912579059601\n",
      "\n",
      "EPOCH 1062  (with max 8000), loss: 0.003027450991794467\n",
      "train time for 1062 epochs, was 885.1260287761688\n",
      "\n",
      "EPOCH 1064  (with max 8000), loss: 0.0030432925559580326\n",
      "train time for 1064 epochs, was 886.7838788032532\n",
      "\n",
      "EPOCH 1066  (with max 8000), loss: 0.0029900504741817713\n",
      "train time for 1066 epochs, was 888.4242563247681\n",
      "\n",
      "EPOCH 1068  (with max 8000), loss: 0.002648585243150592\n",
      "train time for 1068 epochs, was 890.129959821701\n",
      "\n",
      "EPOCH 1070  (with max 8000), loss: 0.0025089983828365803\n",
      "train time for 1070 epochs, was 891.7997179031372\n",
      "\n",
      "EPOCH 1072  (with max 8000), loss: 0.0027045481838285923\n",
      "train time for 1072 epochs, was 893.4343123435974\n",
      "\n",
      "EPOCH 1074  (with max 8000), loss: 0.0033812234178185463\n",
      "train time for 1074 epochs, was 895.0698833465576\n",
      "\n",
      "EPOCH 1076  (with max 8000), loss: 0.0035501800011843443\n",
      "train time for 1076 epochs, was 896.7422935962677\n",
      "\n",
      "EPOCH 1078  (with max 8000), loss: 0.0033941513393074274\n",
      "train time for 1078 epochs, was 898.3962788581848\n",
      "\n",
      "EPOCH 1080  (with max 8000), loss: 0.004733937326818705\n",
      "train time for 1080 epochs, was 900.0502717494965\n",
      "\n",
      "EPOCH 1082  (with max 8000), loss: 0.007663333788514137\n",
      "train time for 1082 epochs, was 901.703455209732\n",
      "\n",
      "EPOCH 1084  (with max 8000), loss: 0.0036634865682572126\n",
      "train time for 1084 epochs, was 903.3582527637482\n",
      "\n",
      "EPOCH 1086  (with max 8000), loss: 0.010388506576418877\n",
      "train time for 1086 epochs, was 905.0408277511597\n",
      "\n",
      "EPOCH 1088  (with max 8000), loss: 0.0015239272033795714\n",
      "train time for 1088 epochs, was 906.7028019428253\n",
      "\n",
      "EPOCH 1090  (with max 8000), loss: 0.0035007146652787924\n",
      "train time for 1090 epochs, was 908.3557088375092\n",
      "\n",
      "EPOCH 1092  (with max 8000), loss: 0.0045761484652757645\n",
      "train time for 1092 epochs, was 910.0138928890228\n",
      "\n",
      "EPOCH 1094  (with max 8000), loss: 0.008018173277378082\n",
      "train time for 1094 epochs, was 911.6849563121796\n",
      "\n",
      "EPOCH 1096  (with max 8000), loss: 0.009263793006539345\n",
      "train time for 1096 epochs, was 913.3427331447601\n",
      "\n",
      "EPOCH 1098  (with max 8000), loss: 0.0031131128780543804\n",
      "train time for 1098 epochs, was 914.9810891151428\n",
      "\n",
      "EPOCH 1100  (with max 8000), loss: 0.006415811832994223\n",
      "train time for 1100 epochs, was 916.6464705467224\n",
      "\n",
      "EPOCH 1102  (with max 8000), loss: 0.003517256584018469\n",
      "train time for 1102 epochs, was 918.2908730506897\n",
      "\n",
      "EPOCH 1104  (with max 8000), loss: 0.005457328632473946\n",
      "train time for 1104 epochs, was 919.9517583847046\n",
      "\n",
      "EPOCH 1106  (with max 8000), loss: 0.0022510401904582977\n",
      "train time for 1106 epochs, was 921.6028077602386\n",
      "\n",
      "EPOCH 1108  (with max 8000), loss: 0.002666489453986287\n",
      "train time for 1108 epochs, was 923.2768681049347\n",
      "\n",
      "EPOCH 1110  (with max 8000), loss: 0.0046757846139371395\n",
      "train time for 1110 epochs, was 924.9525010585785\n",
      "\n",
      "EPOCH 1112  (with max 8000), loss: 0.002282720757648349\n",
      "train time for 1112 epochs, was 926.5922541618347\n",
      "\n",
      "EPOCH 1114  (with max 8000), loss: 0.00634584529325366\n",
      "train time for 1114 epochs, was 928.2369818687439\n",
      "\n",
      "EPOCH 1116  (with max 8000), loss: 0.0025614737533032894\n",
      "train time for 1116 epochs, was 929.9086720943451\n",
      "\n",
      "EPOCH 1118  (with max 8000), loss: 0.0011093341745436192\n",
      "train time for 1118 epochs, was 931.5516800880432\n",
      "\n",
      "EPOCH 1120  (with max 8000), loss: 0.007478342857211828\n",
      "train time for 1120 epochs, was 933.2188675403595\n",
      "\n",
      "EPOCH 1122  (with max 8000), loss: 0.005571192596107721\n",
      "train time for 1122 epochs, was 934.8616147041321\n",
      "\n",
      "EPOCH 1124  (with max 8000), loss: 0.004511513747274876\n",
      "train time for 1124 epochs, was 936.4989223480225\n",
      "\n",
      "EPOCH 1126  (with max 8000), loss: 0.005343661643564701\n",
      "train time for 1126 epochs, was 938.1408920288086\n",
      "\n",
      "EPOCH 1128  (with max 8000), loss: 0.0017933167982846498\n",
      "train time for 1128 epochs, was 939.7797148227692\n",
      "\n",
      "EPOCH 1130  (with max 8000), loss: 0.0024473269004374743\n",
      "train time for 1130 epochs, was 941.4277966022491\n",
      "\n",
      "EPOCH 1132  (with max 8000), loss: 0.002909501316025853\n",
      "train time for 1132 epochs, was 943.073971748352\n",
      "\n",
      "EPOCH 1134  (with max 8000), loss: 0.0056312368251383305\n",
      "train time for 1134 epochs, was 944.714319229126\n",
      "\n",
      "EPOCH 1136  (with max 8000), loss: 0.011833597905933857\n",
      "train time for 1136 epochs, was 946.357449054718\n",
      "\n",
      "EPOCH 1138  (with max 8000), loss: 0.015010704286396503\n",
      "train time for 1138 epochs, was 947.9967613220215\n",
      "\n",
      "EPOCH 1140  (with max 8000), loss: 0.003445604583248496\n",
      "train time for 1140 epochs, was 949.6405158042908\n",
      "\n",
      "EPOCH 1142  (with max 8000), loss: 0.0013389774831011891\n",
      "train time for 1142 epochs, was 951.2801325321198\n",
      "\n",
      "EPOCH 1144  (with max 8000), loss: 0.002170068910345435\n",
      "train time for 1144 epochs, was 952.9242513179779\n",
      "\n",
      "EPOCH 1146  (with max 8000), loss: 0.00972443912178278\n",
      "train time for 1146 epochs, was 954.5637629032135\n",
      "\n",
      "EPOCH 1148  (with max 8000), loss: 0.005299199838191271\n",
      "train time for 1148 epochs, was 956.2059345245361\n",
      "\n",
      "EPOCH 1150  (with max 8000), loss: 0.002398985205218196\n",
      "train time for 1150 epochs, was 957.8503732681274\n",
      "\n",
      "EPOCH 1152  (with max 8000), loss: 0.002055163960903883\n",
      "train time for 1152 epochs, was 959.4907813072205\n",
      "\n",
      "EPOCH 1154  (with max 8000), loss: 0.003945617470890284\n",
      "train time for 1154 epochs, was 961.1643838882446\n",
      "\n",
      "EPOCH 1156  (with max 8000), loss: 0.0019523887895047665\n",
      "train time for 1156 epochs, was 962.8113083839417\n",
      "\n",
      "EPOCH 1158  (with max 8000), loss: 0.0014581267023459077\n",
      "train time for 1158 epochs, was 964.4524807929993\n",
      "\n",
      "EPOCH 1160  (with max 8000), loss: 0.005145304836332798\n",
      "train time for 1160 epochs, was 966.092759847641\n",
      "\n",
      "EPOCH 1162  (with max 8000), loss: 0.0037933241110295057\n",
      "train time for 1162 epochs, was 967.7381978034973\n",
      "\n",
      "EPOCH 1164  (with max 8000), loss: 0.0030989402439445257\n",
      "train time for 1164 epochs, was 969.4321074485779\n",
      "\n",
      "EPOCH 1166  (with max 8000), loss: 0.005060527939349413\n",
      "train time for 1166 epochs, was 971.0687277317047\n",
      "\n",
      "EPOCH 1168  (with max 8000), loss: 0.003367023076862097\n",
      "train time for 1168 epochs, was 972.7163274288177\n",
      "\n",
      "EPOCH 1170  (with max 8000), loss: 0.0030824162531644106\n",
      "train time for 1170 epochs, was 974.3605124950409\n",
      "\n",
      "EPOCH 1172  (with max 8000), loss: 0.003246844979003072\n",
      "train time for 1172 epochs, was 976.002890586853\n",
      "\n",
      "EPOCH 1174  (with max 8000), loss: 0.010934843681752682\n",
      "train time for 1174 epochs, was 977.6712939739227\n",
      "\n",
      "EPOCH 1176  (with max 8000), loss: 0.0035692667588591576\n",
      "train time for 1176 epochs, was 979.3204905986786\n",
      "\n",
      "EPOCH 1178  (with max 8000), loss: 0.0057211765088140965\n",
      "train time for 1178 epochs, was 980.9985783100128\n",
      "\n",
      "EPOCH 1180  (with max 8000), loss: 0.010798820294439793\n",
      "train time for 1180 epochs, was 982.645961523056\n",
      "\n",
      "EPOCH 1182  (with max 8000), loss: 0.0037251710891723633\n",
      "train time for 1182 epochs, was 984.3204746246338\n",
      "\n",
      "EPOCH 1184  (with max 8000), loss: 0.00553977582603693\n",
      "train time for 1184 epochs, was 985.9617409706116\n",
      "\n",
      "EPOCH 1186  (with max 8000), loss: 0.003446671413257718\n",
      "train time for 1186 epochs, was 987.6346440315247\n",
      "\n",
      "EPOCH 1188  (with max 8000), loss: 0.004711728543043137\n",
      "train time for 1188 epochs, was 989.3052334785461\n",
      "\n",
      "EPOCH 1190  (with max 8000), loss: 0.003784588538110256\n",
      "train time for 1190 epochs, was 990.9535284042358\n",
      "\n",
      "EPOCH 1192  (with max 8000), loss: 0.009759101085364819\n",
      "train time for 1192 epochs, was 992.6075513362885\n",
      "\n",
      "EPOCH 1194  (with max 8000), loss: 0.009496869519352913\n",
      "train time for 1194 epochs, was 994.2705252170563\n",
      "\n",
      "EPOCH 1196  (with max 8000), loss: 0.0027549827937036753\n",
      "train time for 1196 epochs, was 995.9040243625641\n",
      "\n",
      "EPOCH 1198  (with max 8000), loss: 0.006145827006548643\n",
      "train time for 1198 epochs, was 997.545170545578\n",
      "\n",
      "EPOCH 1200  (with max 8000), loss: 0.0063989064656198025\n",
      "train time for 1200 epochs, was 999.2055459022522\n",
      "\n",
      "EPOCH 1200 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_1200.pth\n",
      "\n",
      "EPOCH 1202  (with max 8000), loss: 0.003938149660825729\n",
      "train time for 1202 epochs, was 1000.8791148662567\n",
      "\n",
      "EPOCH 1204  (with max 8000), loss: 0.006412087008357048\n",
      "train time for 1204 epochs, was 1002.5628592967987\n",
      "\n",
      "EPOCH 1206  (with max 8000), loss: 0.0031446360517293215\n",
      "train time for 1206 epochs, was 1004.228150844574\n",
      "\n",
      "EPOCH 1208  (with max 8000), loss: 0.0023262454196810722\n",
      "train time for 1208 epochs, was 1005.9108355045319\n",
      "\n",
      "EPOCH 1210  (with max 8000), loss: 0.0017481250688433647\n",
      "train time for 1210 epochs, was 1007.5883529186249\n",
      "\n",
      "EPOCH 1212  (with max 8000), loss: 0.009782140143215656\n",
      "train time for 1212 epochs, was 1009.2800364494324\n",
      "\n",
      "EPOCH 1214  (with max 8000), loss: 0.008139186538755894\n",
      "train time for 1214 epochs, was 1010.9139785766602\n",
      "\n",
      "EPOCH 1216  (with max 8000), loss: 0.0010265993187204003\n",
      "train time for 1216 epochs, was 1012.5703189373016\n",
      "\n",
      "EPOCH 1218  (with max 8000), loss: 0.0018484059255570173\n",
      "train time for 1218 epochs, was 1014.2254972457886\n",
      "\n",
      "EPOCH 1220  (with max 8000), loss: 0.003974991850554943\n",
      "train time for 1220 epochs, was 1015.8793110847473\n",
      "\n",
      "EPOCH 1222  (with max 8000), loss: 0.007924092933535576\n",
      "train time for 1222 epochs, was 1017.5355777740479\n",
      "\n",
      "EPOCH 1224  (with max 8000), loss: 0.001305383280850947\n",
      "train time for 1224 epochs, was 1019.2081055641174\n",
      "\n",
      "EPOCH 1226  (with max 8000), loss: 0.003066110424697399\n",
      "train time for 1226 epochs, was 1020.8686938285828\n",
      "\n",
      "EPOCH 1228  (with max 8000), loss: 0.0038815485313534737\n",
      "train time for 1228 epochs, was 1022.525866985321\n",
      "\n",
      "EPOCH 1230  (with max 8000), loss: 0.0057397764176130295\n",
      "train time for 1230 epochs, was 1024.1625800132751\n",
      "\n",
      "EPOCH 1232  (with max 8000), loss: 0.009428875520825386\n",
      "train time for 1232 epochs, was 1025.819791316986\n",
      "\n",
      "EPOCH 1234  (with max 8000), loss: 0.0029146638698875904\n",
      "train time for 1234 epochs, was 1027.46284365654\n",
      "\n",
      "EPOCH 1236  (with max 8000), loss: 0.005013436544686556\n",
      "train time for 1236 epochs, was 1029.1188895702362\n",
      "\n",
      "EPOCH 1238  (with max 8000), loss: 0.006155502516776323\n",
      "train time for 1238 epochs, was 1030.7689094543457\n",
      "\n",
      "EPOCH 1240  (with max 8000), loss: 0.002920727478340268\n",
      "train time for 1240 epochs, was 1032.421006679535\n",
      "\n",
      "EPOCH 1242  (with max 8000), loss: 0.0028681817930191755\n",
      "train time for 1242 epochs, was 1034.0574946403503\n",
      "\n",
      "EPOCH 1244  (with max 8000), loss: 0.009316496551036835\n",
      "train time for 1244 epochs, was 1035.737313747406\n",
      "\n",
      "EPOCH 1246  (with max 8000), loss: 0.0019619616214185953\n",
      "train time for 1246 epochs, was 1037.4227023124695\n",
      "\n",
      "EPOCH 1248  (with max 8000), loss: 0.04131576791405678\n",
      "train time for 1248 epochs, was 1039.097685098648\n",
      "\n",
      "EPOCH 1250  (with max 8000), loss: 0.008509151637554169\n",
      "train time for 1250 epochs, was 1040.777381181717\n",
      "\n",
      "EPOCH 1252  (with max 8000), loss: 0.008023589849472046\n",
      "train time for 1252 epochs, was 1042.4177224636078\n",
      "\n",
      "EPOCH 1254  (with max 8000), loss: 0.003350751241669059\n",
      "train time for 1254 epochs, was 1044.0855519771576\n",
      "\n",
      "EPOCH 1256  (with max 8000), loss: 0.005818852689117193\n",
      "train time for 1256 epochs, was 1045.7424793243408\n",
      "\n",
      "EPOCH 1258  (with max 8000), loss: 0.005213641561567783\n",
      "train time for 1258 epochs, was 1047.3991868495941\n",
      "\n",
      "EPOCH 1260  (with max 8000), loss: 0.004589753225445747\n",
      "train time for 1260 epochs, was 1049.0448596477509\n",
      "\n",
      "EPOCH 1262  (with max 8000), loss: 0.0016657173400744796\n",
      "train time for 1262 epochs, was 1050.6815509796143\n",
      "\n",
      "EPOCH 1264  (with max 8000), loss: 0.0037526849191635847\n",
      "train time for 1264 epochs, was 1052.3864636421204\n",
      "\n",
      "EPOCH 1266  (with max 8000), loss: 0.002175290836021304\n",
      "train time for 1266 epochs, was 1054.0653870105743\n",
      "\n",
      "EPOCH 1268  (with max 8000), loss: 0.0007366444915533066\n",
      "train time for 1268 epochs, was 1055.7377338409424\n",
      "\n",
      "EPOCH 1270  (with max 8000), loss: 0.0005579147837124765\n",
      "train time for 1270 epochs, was 1057.3736011981964\n",
      "\n",
      "EPOCH 1272  (with max 8000), loss: 0.0007656575180590153\n",
      "train time for 1272 epochs, was 1059.0378255844116\n",
      "\n",
      "EPOCH 1274  (with max 8000), loss: 0.0031137929763644934\n",
      "train time for 1274 epochs, was 1060.6716725826263\n",
      "\n",
      "EPOCH 1276  (with max 8000), loss: 0.0029213749803602695\n",
      "train time for 1276 epochs, was 1062.3274610042572\n",
      "\n",
      "EPOCH 1278  (with max 8000), loss: 0.002598196966573596\n",
      "train time for 1278 epochs, was 1063.9610946178436\n",
      "\n",
      "EPOCH 1280  (with max 8000), loss: 0.003005344420671463\n",
      "train time for 1280 epochs, was 1065.6291995048523\n",
      "\n",
      "EPOCH 1282  (with max 8000), loss: 0.0027896601241081953\n",
      "train time for 1282 epochs, was 1067.275197982788\n",
      "\n",
      "EPOCH 1284  (with max 8000), loss: 0.000818873755633831\n",
      "train time for 1284 epochs, was 1068.937135219574\n",
      "\n",
      "EPOCH 1286  (with max 8000), loss: 0.0014545045560225844\n",
      "train time for 1286 epochs, was 1070.5945115089417\n",
      "\n",
      "EPOCH 1288  (with max 8000), loss: 0.0030239447951316833\n",
      "train time for 1288 epochs, was 1072.2368109226227\n",
      "\n",
      "EPOCH 1290  (with max 8000), loss: 0.004168783780187368\n",
      "train time for 1290 epochs, was 1073.8754296302795\n",
      "\n",
      "EPOCH 1292  (with max 8000), loss: 0.001795819029211998\n",
      "train time for 1292 epochs, was 1075.5114650726318\n",
      "\n",
      "EPOCH 1294  (with max 8000), loss: 0.001078902860172093\n",
      "train time for 1294 epochs, was 1077.1975755691528\n",
      "\n",
      "EPOCH 1296  (with max 8000), loss: 0.0009199547930620611\n",
      "train time for 1296 epochs, was 1078.8549749851227\n",
      "\n",
      "EPOCH 1298  (with max 8000), loss: 0.005456914659589529\n",
      "train time for 1298 epochs, was 1080.4975419044495\n",
      "\n",
      "EPOCH 1300  (with max 8000), loss: 0.003991281148046255\n",
      "train time for 1300 epochs, was 1082.1547298431396\n",
      "\n",
      "EPOCH 1302  (with max 8000), loss: 0.0005203430773690343\n",
      "train time for 1302 epochs, was 1083.791559934616\n",
      "\n",
      "EPOCH 1304  (with max 8000), loss: 0.005212659947574139\n",
      "train time for 1304 epochs, was 1085.430466413498\n",
      "\n",
      "EPOCH 1306  (with max 8000), loss: 0.0015151167754083872\n",
      "train time for 1306 epochs, was 1087.0702476501465\n",
      "\n",
      "EPOCH 1308  (with max 8000), loss: 0.000987029168754816\n",
      "train time for 1308 epochs, was 1088.7062373161316\n",
      "\n",
      "EPOCH 1310  (with max 8000), loss: 0.0029493356123566628\n",
      "train time for 1310 epochs, was 1090.3432159423828\n",
      "\n",
      "EPOCH 1312  (with max 8000), loss: 0.018161043524742126\n",
      "train time for 1312 epochs, was 1091.9834072589874\n",
      "\n",
      "EPOCH 1314  (with max 8000), loss: 0.007554142270237207\n",
      "train time for 1314 epochs, was 1093.642677783966\n",
      "\n",
      "EPOCH 1316  (with max 8000), loss: 0.007119280751794577\n",
      "train time for 1316 epochs, was 1095.3021824359894\n",
      "\n",
      "EPOCH 1318  (with max 8000), loss: 0.0007896884344518185\n",
      "train time for 1318 epochs, was 1096.9360451698303\n",
      "\n",
      "EPOCH 1320  (with max 8000), loss: 0.0025244655553251505\n",
      "train time for 1320 epochs, was 1098.5700194835663\n",
      "\n",
      "EPOCH 1322  (with max 8000), loss: 0.0028798053972423077\n",
      "train time for 1322 epochs, was 1100.2039320468903\n",
      "\n",
      "EPOCH 1324  (with max 8000), loss: 0.0036755423061549664\n",
      "train time for 1324 epochs, was 1101.8377702236176\n",
      "\n",
      "EPOCH 1326  (with max 8000), loss: 0.0017299721948802471\n",
      "train time for 1326 epochs, was 1103.4738202095032\n",
      "\n",
      "EPOCH 1328  (with max 8000), loss: 0.00309580541215837\n",
      "train time for 1328 epochs, was 1105.1344892978668\n",
      "\n",
      "EPOCH 1330  (with max 8000), loss: 0.0047530424781143665\n",
      "train time for 1330 epochs, was 1106.7886197566986\n",
      "\n",
      "EPOCH 1332  (with max 8000), loss: 0.00573704531416297\n",
      "train time for 1332 epochs, was 1108.4445295333862\n",
      "\n",
      "EPOCH 1334  (with max 8000), loss: 0.0038808442186564207\n",
      "train time for 1334 epochs, was 1110.0832569599152\n",
      "\n",
      "EPOCH 1336  (with max 8000), loss: 0.0020359924528747797\n",
      "train time for 1336 epochs, was 1111.7647943496704\n",
      "\n",
      "EPOCH 1338  (with max 8000), loss: 0.002718304516747594\n",
      "train time for 1338 epochs, was 1113.4221749305725\n",
      "\n",
      "EPOCH 1340  (with max 8000), loss: 0.0016014627180993557\n",
      "train time for 1340 epochs, was 1115.0564486980438\n",
      "\n",
      "EPOCH 1342  (with max 8000), loss: 0.009209522977471352\n",
      "train time for 1342 epochs, was 1116.6902284622192\n",
      "\n",
      "EPOCH 1344  (with max 8000), loss: 0.0030963392928242683\n",
      "train time for 1344 epochs, was 1118.3243927955627\n",
      "\n",
      "EPOCH 1346  (with max 8000), loss: 0.0022422464098781347\n",
      "train time for 1346 epochs, was 1119.9602766036987\n",
      "\n",
      "EPOCH 1348  (with max 8000), loss: 0.001380607602186501\n",
      "train time for 1348 epochs, was 1121.5943386554718\n",
      "\n",
      "EPOCH 1350  (with max 8000), loss: 0.0013691310305148363\n",
      "train time for 1350 epochs, was 1123.2282285690308\n",
      "\n",
      "EPOCH 1352  (with max 8000), loss: 0.0027869255281984806\n",
      "train time for 1352 epochs, was 1124.8662614822388\n",
      "\n",
      "EPOCH 1354  (with max 8000), loss: 0.003167761955410242\n",
      "train time for 1354 epochs, was 1126.5005950927734\n",
      "\n",
      "EPOCH 1356  (with max 8000), loss: 0.002490580314770341\n",
      "train time for 1356 epochs, was 1128.1711640357971\n",
      "\n",
      "EPOCH 1358  (with max 8000), loss: 0.0027777759823948145\n",
      "train time for 1358 epochs, was 1129.8258409500122\n",
      "\n",
      "EPOCH 1360  (with max 8000), loss: 0.0024377412628382444\n",
      "train time for 1360 epochs, was 1131.4677703380585\n",
      "\n",
      "EPOCH 1362  (with max 8000), loss: 0.0016069345874711871\n",
      "train time for 1362 epochs, was 1133.1081562042236\n",
      "\n",
      "EPOCH 1364  (with max 8000), loss: 0.003828752785921097\n",
      "train time for 1364 epochs, was 1134.7631192207336\n",
      "\n",
      "EPOCH 1366  (with max 8000), loss: 0.004064343404024839\n",
      "train time for 1366 epochs, was 1136.4021224975586\n",
      "\n",
      "EPOCH 1368  (with max 8000), loss: 0.0034624640829861164\n",
      "train time for 1368 epochs, was 1138.066635131836\n",
      "\n",
      "EPOCH 1370  (with max 8000), loss: 0.001992413541302085\n",
      "train time for 1370 epochs, was 1139.7242596149445\n",
      "\n",
      "EPOCH 1372  (with max 8000), loss: 0.005144532769918442\n",
      "train time for 1372 epochs, was 1141.395544052124\n",
      "\n",
      "EPOCH 1374  (with max 8000), loss: 0.005977463908493519\n",
      "train time for 1374 epochs, was 1143.0602989196777\n",
      "\n",
      "EPOCH 1376  (with max 8000), loss: 0.0012891700025647879\n",
      "train time for 1376 epochs, was 1144.7048635482788\n",
      "\n",
      "EPOCH 1378  (with max 8000), loss: 0.0027082646265625954\n",
      "train time for 1378 epochs, was 1146.369607925415\n",
      "\n",
      "EPOCH 1380  (with max 8000), loss: 0.006921152584254742\n",
      "train time for 1380 epochs, was 1148.0334899425507\n",
      "\n",
      "EPOCH 1382  (with max 8000), loss: 0.0029846923425793648\n",
      "train time for 1382 epochs, was 1149.6762201786041\n",
      "\n",
      "EPOCH 1384  (with max 8000), loss: 0.011053071357309818\n",
      "train time for 1384 epochs, was 1151.3205213546753\n",
      "\n",
      "EPOCH 1386  (with max 8000), loss: 0.011817291378974915\n",
      "train time for 1386 epochs, was 1153.0051164627075\n",
      "\n",
      "EPOCH 1388  (with max 8000), loss: 0.007945642806589603\n",
      "train time for 1388 epochs, was 1154.6623294353485\n",
      "\n",
      "EPOCH 1390  (with max 8000), loss: 0.005448672454804182\n",
      "train time for 1390 epochs, was 1156.3560917377472\n",
      "\n",
      "EPOCH 1392  (with max 8000), loss: 0.009445971809327602\n",
      "train time for 1392 epochs, was 1158.3379311561584\n",
      "\n",
      "EPOCH 1394  (with max 8000), loss: 0.00918771792203188\n",
      "train time for 1394 epochs, was 1160.63716506958\n",
      "\n",
      "EPOCH 1396  (with max 8000), loss: 0.005728065501898527\n",
      "train time for 1396 epochs, was 1162.4711203575134\n",
      "\n",
      "EPOCH 1398  (with max 8000), loss: 0.006018009968101978\n",
      "train time for 1398 epochs, was 1164.198323249817\n",
      "\n",
      "EPOCH 1400  (with max 8000), loss: 0.00644890358671546\n",
      "train time for 1400 epochs, was 1165.885422706604\n",
      "\n",
      "EPOCH 1400 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_1400.pth\n",
      "\n",
      "EPOCH 1402  (with max 8000), loss: 0.007077105809003115\n",
      "train time for 1402 epochs, was 1167.6134185791016\n",
      "\n",
      "EPOCH 1404  (with max 8000), loss: 0.00236594770103693\n",
      "train time for 1404 epochs, was 1169.2469005584717\n",
      "\n",
      "EPOCH 1406  (with max 8000), loss: 0.0022196786012500525\n",
      "train time for 1406 epochs, was 1170.902226448059\n",
      "\n",
      "EPOCH 1408  (with max 8000), loss: 0.0037489442620426416\n",
      "train time for 1408 epochs, was 1172.5358819961548\n",
      "\n",
      "EPOCH 1410  (with max 8000), loss: 0.002896658843383193\n",
      "train time for 1410 epochs, was 1174.2218725681305\n",
      "\n",
      "EPOCH 1412  (with max 8000), loss: 0.0035815672017633915\n",
      "train time for 1412 epochs, was 1175.8990333080292\n",
      "\n",
      "EPOCH 1414  (with max 8000), loss: 0.006497562862932682\n",
      "train time for 1414 epochs, was 1177.5949339866638\n",
      "\n",
      "EPOCH 1416  (with max 8000), loss: 0.000703713740222156\n",
      "train time for 1416 epochs, was 1179.2614743709564\n",
      "\n",
      "EPOCH 1418  (with max 8000), loss: 0.003858397714793682\n",
      "train time for 1418 epochs, was 1180.9289531707764\n",
      "\n",
      "EPOCH 1420  (with max 8000), loss: 0.0040593380108475685\n",
      "train time for 1420 epochs, was 1182.6890921592712\n",
      "\n",
      "EPOCH 1422  (with max 8000), loss: 0.0024753797333687544\n",
      "train time for 1422 epochs, was 1184.4132702350616\n",
      "\n",
      "EPOCH 1424  (with max 8000), loss: 0.003803140250965953\n",
      "train time for 1424 epochs, was 1186.1403024196625\n",
      "\n",
      "EPOCH 1426  (with max 8000), loss: 0.00439878273755312\n",
      "train time for 1426 epochs, was 1187.8647410869598\n",
      "\n",
      "EPOCH 1428  (with max 8000), loss: 0.004244290292263031\n",
      "train time for 1428 epochs, was 1189.5919065475464\n",
      "\n",
      "EPOCH 1430  (with max 8000), loss: 0.007243746891617775\n",
      "train time for 1430 epochs, was 1191.3212883472443\n",
      "\n",
      "EPOCH 1432  (with max 8000), loss: 0.004195684567093849\n",
      "train time for 1432 epochs, was 1193.0468719005585\n",
      "\n",
      "EPOCH 1434  (with max 8000), loss: 0.003846743144094944\n",
      "train time for 1434 epochs, was 1194.771476984024\n",
      "\n",
      "EPOCH 1436  (with max 8000), loss: 0.005124114919453859\n",
      "train time for 1436 epochs, was 1196.4931898117065\n",
      "\n",
      "EPOCH 1438  (with max 8000), loss: 0.0037536011077463627\n",
      "train time for 1438 epochs, was 1198.2131643295288\n",
      "\n",
      "EPOCH 1440  (with max 8000), loss: 0.002067150315269828\n",
      "train time for 1440 epochs, was 1199.9306948184967\n",
      "\n",
      "EPOCH 1442  (with max 8000), loss: 0.0011219034204259515\n",
      "train time for 1442 epochs, was 1201.616022825241\n",
      "\n",
      "EPOCH 1444  (with max 8000), loss: 0.003940897062420845\n",
      "train time for 1444 epochs, was 1203.272870540619\n",
      "\n",
      "EPOCH 1446  (with max 8000), loss: 0.0038947933353483677\n",
      "train time for 1446 epochs, was 1204.9291408061981\n",
      "\n",
      "EPOCH 1448  (with max 8000), loss: 0.0065217334777116776\n",
      "train time for 1448 epochs, was 1206.5622744560242\n",
      "\n",
      "EPOCH 1450  (with max 8000), loss: 0.007138877175748348\n",
      "train time for 1450 epochs, was 1208.1954944133759\n",
      "\n",
      "EPOCH 1452  (with max 8000), loss: 0.005969783756881952\n",
      "train time for 1452 epochs, was 1209.828777551651\n",
      "\n",
      "EPOCH 1454  (with max 8000), loss: 0.005073122680187225\n",
      "train time for 1454 epochs, was 1211.462285041809\n",
      "\n",
      "EPOCH 1456  (with max 8000), loss: 0.0026121430564671755\n",
      "train time for 1456 epochs, was 1213.1004483699799\n",
      "\n",
      "EPOCH 1458  (with max 8000), loss: 0.0040977345779538155\n",
      "train time for 1458 epochs, was 1214.7615723609924\n",
      "\n",
      "EPOCH 1460  (with max 8000), loss: 0.006082466803491116\n",
      "train time for 1460 epochs, was 1216.420375585556\n",
      "\n",
      "EPOCH 1462  (with max 8000), loss: 0.0021017405670136213\n",
      "train time for 1462 epochs, was 1218.086045742035\n",
      "\n",
      "EPOCH 1464  (with max 8000), loss: 0.002276128390803933\n",
      "train time for 1464 epochs, was 1219.765793800354\n",
      "\n",
      "EPOCH 1466  (with max 8000), loss: 0.0026919308584183455\n",
      "train time for 1466 epochs, was 1221.439787864685\n",
      "\n",
      "EPOCH 1468  (with max 8000), loss: 0.0034756509121507406\n",
      "train time for 1468 epochs, was 1223.1246514320374\n",
      "\n",
      "EPOCH 1470  (with max 8000), loss: 0.004093151073902845\n",
      "train time for 1470 epochs, was 1224.872364282608\n",
      "\n",
      "EPOCH 1472  (with max 8000), loss: 0.0014423737302422523\n",
      "train time for 1472 epochs, was 1226.553678035736\n",
      "\n",
      "EPOCH 1474  (with max 8000), loss: 0.006158558186143637\n",
      "train time for 1474 epochs, was 1228.298433303833\n",
      "\n",
      "EPOCH 1476  (with max 8000), loss: 0.0038698813877999783\n",
      "train time for 1476 epochs, was 1229.9529452323914\n",
      "\n",
      "EPOCH 1478  (with max 8000), loss: 0.0016931678401306272\n",
      "train time for 1478 epochs, was 1231.5858218669891\n",
      "\n",
      "EPOCH 1480  (with max 8000), loss: 0.0013157223584130406\n",
      "train time for 1480 epochs, was 1233.218930721283\n",
      "\n",
      "EPOCH 1482  (with max 8000), loss: 0.0029746433719992638\n",
      "train time for 1482 epochs, was 1234.851999759674\n",
      "\n",
      "EPOCH 1484  (with max 8000), loss: 0.00179897656198591\n",
      "train time for 1484 epochs, was 1236.4846940040588\n",
      "\n",
      "EPOCH 1486  (with max 8000), loss: 0.0011035156203433871\n",
      "train time for 1486 epochs, was 1238.1174414157867\n",
      "\n",
      "EPOCH 1488  (with max 8000), loss: 0.006599894259124994\n",
      "train time for 1488 epochs, was 1239.7502090930939\n",
      "\n",
      "EPOCH 1490  (with max 8000), loss: 0.006189264822751284\n",
      "train time for 1490 epochs, was 1241.3851721286774\n",
      "\n",
      "EPOCH 1492  (with max 8000), loss: 0.0025124521926045418\n",
      "train time for 1492 epochs, was 1243.0179224014282\n",
      "\n",
      "EPOCH 1494  (with max 8000), loss: 0.010919605381786823\n",
      "train time for 1494 epochs, was 1244.6549470424652\n",
      "\n",
      "EPOCH 1496  (with max 8000), loss: 0.001679749577306211\n",
      "train time for 1496 epochs, was 1246.2877275943756\n",
      "\n",
      "EPOCH 1498  (with max 8000), loss: 0.0023703009355813265\n",
      "train time for 1498 epochs, was 1247.9204471111298\n",
      "\n",
      "EPOCH 1500  (with max 8000), loss: 0.004170733969658613\n",
      "train time for 1500 epochs, was 1249.555968284607\n",
      "\n",
      "EPOCH 1502  (with max 8000), loss: 0.004301736131310463\n",
      "train time for 1502 epochs, was 1251.1907258033752\n",
      "\n",
      "EPOCH 1504  (with max 8000), loss: 0.002567349234595895\n",
      "train time for 1504 epochs, was 1252.833854675293\n",
      "\n",
      "EPOCH 1506  (with max 8000), loss: 0.004988073371350765\n",
      "train time for 1506 epochs, was 1254.4665429592133\n",
      "\n",
      "EPOCH 1508  (with max 8000), loss: 0.007828439585864544\n",
      "train time for 1508 epochs, was 1256.1014828681946\n",
      "\n",
      "EPOCH 1510  (with max 8000), loss: 0.0056496295146644115\n",
      "train time for 1510 epochs, was 1257.7342646121979\n",
      "\n",
      "EPOCH 1512  (with max 8000), loss: 0.0042943647131323814\n",
      "train time for 1512 epochs, was 1259.367045879364\n",
      "\n",
      "EPOCH 1514  (with max 8000), loss: 0.004654837306588888\n",
      "train time for 1514 epochs, was 1260.9997622966766\n",
      "\n",
      "EPOCH 1516  (with max 8000), loss: 0.0016624063719063997\n",
      "train time for 1516 epochs, was 1262.6324870586395\n",
      "\n",
      "EPOCH 1518  (with max 8000), loss: 0.0018730622250586748\n",
      "train time for 1518 epochs, was 1264.265387058258\n",
      "\n",
      "EPOCH 1520  (with max 8000), loss: 0.0017777748871594667\n",
      "train time for 1520 epochs, was 1265.8981370925903\n",
      "\n",
      "EPOCH 1522  (with max 8000), loss: 0.004328711424022913\n",
      "train time for 1522 epochs, was 1267.53080534935\n",
      "\n",
      "EPOCH 1524  (with max 8000), loss: 0.0011782471556216478\n",
      "train time for 1524 epochs, was 1269.1636250019073\n",
      "\n",
      "EPOCH 1526  (with max 8000), loss: 0.003232502844184637\n",
      "train time for 1526 epochs, was 1270.7965242862701\n",
      "\n",
      "EPOCH 1528  (with max 8000), loss: 0.0002943742729257792\n",
      "train time for 1528 epochs, was 1272.4291746616364\n",
      "\n",
      "EPOCH 1530  (with max 8000), loss: 0.002342319581657648\n",
      "train time for 1530 epochs, was 1274.063854932785\n",
      "\n",
      "EPOCH 1532  (with max 8000), loss: 0.005400541238486767\n",
      "train time for 1532 epochs, was 1275.6966135501862\n",
      "\n",
      "EPOCH 1534  (with max 8000), loss: 0.0014092909405007958\n",
      "train time for 1534 epochs, was 1277.329454421997\n",
      "\n",
      "EPOCH 1536  (with max 8000), loss: 0.002411399967968464\n",
      "train time for 1536 epochs, was 1278.9622583389282\n",
      "\n",
      "EPOCH 1538  (with max 8000), loss: 0.006019121035933495\n",
      "train time for 1538 epochs, was 1280.5970966815948\n",
      "\n",
      "EPOCH 1540  (with max 8000), loss: 0.004740918055176735\n",
      "train time for 1540 epochs, was 1282.2299025058746\n",
      "\n",
      "EPOCH 1542  (with max 8000), loss: 0.008337501436471939\n",
      "train time for 1542 epochs, was 1283.862720489502\n",
      "\n",
      "EPOCH 1544  (with max 8000), loss: 0.006143973674625158\n",
      "train time for 1544 epochs, was 1285.4957087039948\n",
      "\n",
      "EPOCH 1546  (with max 8000), loss: 0.0036852785851806402\n",
      "train time for 1546 epochs, was 1287.128437757492\n",
      "\n",
      "EPOCH 1548  (with max 8000), loss: 0.008330459706485271\n",
      "train time for 1548 epochs, was 1288.7611644268036\n",
      "\n",
      "EPOCH 1550  (with max 8000), loss: 0.0032961044926196337\n",
      "train time for 1550 epochs, was 1290.3960886001587\n",
      "\n",
      "EPOCH 1552  (with max 8000), loss: 0.0007974545005708933\n",
      "train time for 1552 epochs, was 1292.0479881763458\n",
      "\n",
      "EPOCH 1554  (with max 8000), loss: 0.008142132312059402\n",
      "train time for 1554 epochs, was 1293.680639743805\n",
      "\n",
      "EPOCH 1556  (with max 8000), loss: 0.008112559095025063\n",
      "train time for 1556 epochs, was 1295.313274860382\n",
      "\n",
      "EPOCH 1558  (with max 8000), loss: 0.0038979887031018734\n",
      "train time for 1558 epochs, was 1296.9460434913635\n",
      "\n",
      "EPOCH 1560  (with max 8000), loss: 0.0022678121458739042\n",
      "train time for 1560 epochs, was 1298.578733921051\n",
      "\n",
      "EPOCH 1562  (with max 8000), loss: 0.0036976903211325407\n",
      "train time for 1562 epochs, was 1300.213636636734\n",
      "\n",
      "EPOCH 1564  (with max 8000), loss: 0.0010946894763037562\n",
      "train time for 1564 epochs, was 1301.846295595169\n",
      "\n",
      "EPOCH 1566  (with max 8000), loss: 0.0015889005735516548\n",
      "train time for 1566 epochs, was 1303.4790287017822\n",
      "\n",
      "EPOCH 1568  (with max 8000), loss: 0.002262372523546219\n",
      "train time for 1568 epochs, was 1305.1117951869965\n",
      "\n",
      "EPOCH 1570  (with max 8000), loss: 0.0036607689689844847\n",
      "train time for 1570 epochs, was 1306.744648218155\n",
      "\n",
      "EPOCH 1572  (with max 8000), loss: 0.0017832316225394607\n",
      "train time for 1572 epochs, was 1308.3795249462128\n",
      "\n",
      "EPOCH 1574  (with max 8000), loss: 0.005471375305205584\n",
      "train time for 1574 epochs, was 1310.012523174286\n",
      "\n",
      "EPOCH 1576  (with max 8000), loss: 0.0027622247580438852\n",
      "train time for 1576 epochs, was 1311.6453413963318\n",
      "\n",
      "EPOCH 1578  (with max 8000), loss: 0.0014443788677453995\n",
      "train time for 1578 epochs, was 1313.27840924263\n",
      "\n",
      "EPOCH 1580  (with max 8000), loss: 0.005037378519773483\n",
      "train time for 1580 epochs, was 1314.911188840866\n",
      "\n",
      "EPOCH 1582  (with max 8000), loss: 0.002540356945246458\n",
      "train time for 1582 epochs, was 1316.5441899299622\n",
      "\n",
      "EPOCH 1584  (with max 8000), loss: 0.0005716566811315715\n",
      "train time for 1584 epochs, was 1318.1770601272583\n",
      "\n",
      "EPOCH 1586  (with max 8000), loss: 0.002006992930546403\n",
      "train time for 1586 epochs, was 1319.8097269535065\n",
      "\n",
      "EPOCH 1588  (with max 8000), loss: 0.0010607640724629164\n",
      "train time for 1588 epochs, was 1321.4425687789917\n",
      "\n",
      "EPOCH 1590  (with max 8000), loss: 0.003277445677667856\n",
      "train time for 1590 epochs, was 1323.075219154358\n",
      "\n",
      "EPOCH 1592  (with max 8000), loss: 0.00042916942038573325\n",
      "train time for 1592 epochs, was 1324.7080006599426\n",
      "\n",
      "EPOCH 1594  (with max 8000), loss: 0.0022831945680081844\n",
      "train time for 1594 epochs, was 1326.3407654762268\n",
      "\n",
      "EPOCH 1596  (with max 8000), loss: 0.0019909911789000034\n",
      "train time for 1596 epochs, was 1327.977828502655\n",
      "\n",
      "EPOCH 1598  (with max 8000), loss: 0.0013131967280060053\n",
      "train time for 1598 epochs, was 1329.610927581787\n",
      "\n",
      "EPOCH 1600  (with max 8000), loss: 0.007946951314806938\n",
      "train time for 1600 epochs, was 1331.2436950206757\n",
      "\n",
      "EPOCH 1600 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_1600.pth\n",
      "\n",
      "EPOCH 1602  (with max 8000), loss: 0.0026162504218518734\n",
      "train time for 1602 epochs, was 1332.9099705219269\n",
      "\n",
      "EPOCH 1604  (with max 8000), loss: 0.0029585312586277723\n",
      "train time for 1604 epochs, was 1334.5429062843323\n",
      "\n",
      "EPOCH 1606  (with max 8000), loss: 0.0028772747609764338\n",
      "train time for 1606 epochs, was 1336.1777663230896\n",
      "\n",
      "EPOCH 1608  (with max 8000), loss: 0.004435682203620672\n",
      "train time for 1608 epochs, was 1337.8105454444885\n",
      "\n",
      "EPOCH 1610  (with max 8000), loss: 0.004892382305115461\n",
      "train time for 1610 epochs, was 1339.4432728290558\n",
      "\n",
      "EPOCH 1612  (with max 8000), loss: 0.0018123642075806856\n",
      "train time for 1612 epochs, was 1341.0758996009827\n",
      "\n",
      "EPOCH 1614  (with max 8000), loss: 0.003100303467363119\n",
      "train time for 1614 epochs, was 1342.7089071273804\n",
      "\n",
      "EPOCH 1616  (with max 8000), loss: 0.0019503036746755242\n",
      "train time for 1616 epochs, was 1344.3415496349335\n",
      "\n",
      "EPOCH 1618  (with max 8000), loss: 0.0037502339109778404\n",
      "train time for 1618 epochs, was 1345.974155664444\n",
      "\n",
      "EPOCH 1620  (with max 8000), loss: 0.0025316954124718904\n",
      "train time for 1620 epochs, was 1347.606920003891\n",
      "\n",
      "EPOCH 1622  (with max 8000), loss: 0.0027018659748136997\n",
      "train time for 1622 epochs, was 1349.2401914596558\n",
      "\n",
      "EPOCH 1624  (with max 8000), loss: 0.001527448184788227\n",
      "train time for 1624 epochs, was 1350.873143196106\n",
      "\n",
      "EPOCH 1626  (with max 8000), loss: 0.0017566302558407187\n",
      "train time for 1626 epochs, was 1352.506046295166\n",
      "\n",
      "EPOCH 1628  (with max 8000), loss: 0.004178140312433243\n",
      "train time for 1628 epochs, was 1354.1389436721802\n",
      "\n",
      "EPOCH 1630  (with max 8000), loss: 0.0004940772196277976\n",
      "train time for 1630 epochs, was 1355.7717394828796\n",
      "\n",
      "EPOCH 1632  (with max 8000), loss: 0.0027069016359746456\n",
      "train time for 1632 epochs, was 1357.4046831130981\n",
      "\n",
      "EPOCH 1634  (with max 8000), loss: 0.0021269575227051973\n",
      "train time for 1634 epochs, was 1359.0374553203583\n",
      "\n",
      "EPOCH 1636  (with max 8000), loss: 0.0035112150944769382\n",
      "train time for 1636 epochs, was 1360.6702525615692\n",
      "\n",
      "EPOCH 1638  (with max 8000), loss: 0.002702010329812765\n",
      "train time for 1638 epochs, was 1362.302990913391\n",
      "\n",
      "EPOCH 1640  (with max 8000), loss: 0.0018559532472863793\n",
      "train time for 1640 epochs, was 1363.956820487976\n",
      "\n",
      "EPOCH 1642  (with max 8000), loss: 0.001791859045624733\n",
      "train time for 1642 epochs, was 1365.5897598266602\n",
      "\n",
      "EPOCH 1644  (with max 8000), loss: 0.002730077365413308\n",
      "train time for 1644 epochs, was 1367.2247619628906\n",
      "\n",
      "EPOCH 1646  (with max 8000), loss: 0.0019385976484045386\n",
      "train time for 1646 epochs, was 1368.8617503643036\n",
      "\n",
      "EPOCH 1648  (with max 8000), loss: 0.0013019851176068187\n",
      "train time for 1648 epochs, was 1370.4971556663513\n",
      "\n",
      "EPOCH 1650  (with max 8000), loss: 0.005334789864718914\n",
      "train time for 1650 epochs, was 1372.1320271492004\n",
      "\n",
      "EPOCH 1652  (with max 8000), loss: 0.002402279758825898\n",
      "train time for 1652 epochs, was 1373.7649536132812\n",
      "\n",
      "EPOCH 1654  (with max 8000), loss: 0.0018579550087451935\n",
      "train time for 1654 epochs, was 1375.397753238678\n",
      "\n",
      "EPOCH 1656  (with max 8000), loss: 0.00031112448778003454\n",
      "train time for 1656 epochs, was 1377.0305814743042\n",
      "\n",
      "EPOCH 1658  (with max 8000), loss: 0.0022703828290104866\n",
      "train time for 1658 epochs, was 1378.663763999939\n",
      "\n",
      "EPOCH 1660  (with max 8000), loss: 0.0038026776164770126\n",
      "train time for 1660 epochs, was 1380.2967586517334\n",
      "\n",
      "EPOCH 1662  (with max 8000), loss: 0.004811457358300686\n",
      "train time for 1662 epochs, was 1381.9294424057007\n",
      "\n",
      "EPOCH 1664  (with max 8000), loss: 0.007875965908169746\n",
      "train time for 1664 epochs, was 1383.5623207092285\n",
      "\n",
      "EPOCH 1666  (with max 8000), loss: 0.0031865350902080536\n",
      "train time for 1666 epochs, was 1385.1951911449432\n",
      "\n",
      "EPOCH 1668  (with max 8000), loss: 0.0033484387677162886\n",
      "train time for 1668 epochs, was 1386.8279757499695\n",
      "\n",
      "EPOCH 1670  (with max 8000), loss: 0.0023948331363499165\n",
      "train time for 1670 epochs, was 1388.461017370224\n",
      "\n",
      "EPOCH 1672  (with max 8000), loss: 0.005118473898619413\n",
      "train time for 1672 epochs, was 1390.0937948226929\n",
      "\n",
      "EPOCH 1674  (with max 8000), loss: 0.0011943114222958684\n",
      "train time for 1674 epochs, was 1391.726592540741\n",
      "\n",
      "EPOCH 1676  (with max 8000), loss: 0.00038574053905904293\n",
      "train time for 1676 epochs, was 1393.3594608306885\n",
      "\n",
      "EPOCH 1678  (with max 8000), loss: 0.0008592164958827198\n",
      "train time for 1678 epochs, was 1394.994341135025\n",
      "\n",
      "EPOCH 1680  (with max 8000), loss: 0.004885729867964983\n",
      "train time for 1680 epochs, was 1396.627280473709\n",
      "\n",
      "EPOCH 1682  (with max 8000), loss: 0.006506823468953371\n",
      "train time for 1682 epochs, was 1398.2599558830261\n",
      "\n",
      "EPOCH 1684  (with max 8000), loss: 0.005034043453633785\n",
      "train time for 1684 epochs, was 1399.9263155460358\n",
      "\n",
      "EPOCH 1686  (with max 8000), loss: 0.00480981171131134\n",
      "train time for 1686 epochs, was 1401.5592012405396\n",
      "\n",
      "EPOCH 1688  (with max 8000), loss: 0.004992981441318989\n",
      "train time for 1688 epochs, was 1403.191893339157\n",
      "\n",
      "EPOCH 1690  (with max 8000), loss: 0.0005560243153013289\n",
      "train time for 1690 epochs, was 1404.8247356414795\n",
      "\n",
      "EPOCH 1692  (with max 8000), loss: 0.0016390876844525337\n",
      "train time for 1692 epochs, was 1406.4576501846313\n",
      "\n",
      "EPOCH 1694  (with max 8000), loss: 0.002045142464339733\n",
      "train time for 1694 epochs, was 1408.0924308300018\n",
      "\n",
      "EPOCH 1696  (with max 8000), loss: 0.002014290541410446\n",
      "train time for 1696 epochs, was 1409.7252371311188\n",
      "\n",
      "EPOCH 1698  (with max 8000), loss: 0.0014100840780884027\n",
      "train time for 1698 epochs, was 1411.358065366745\n",
      "\n",
      "EPOCH 1700  (with max 8000), loss: 0.0022883417550474405\n",
      "train time for 1700 epochs, was 1412.9908709526062\n",
      "\n",
      "EPOCH 1702  (with max 8000), loss: 0.0023311555851250887\n",
      "train time for 1702 epochs, was 1414.6237411499023\n",
      "\n",
      "EPOCH 1704  (with max 8000), loss: 0.0022245522122830153\n",
      "train time for 1704 epochs, was 1416.2564957141876\n",
      "\n",
      "EPOCH 1706  (with max 8000), loss: 0.0033971741795539856\n",
      "train time for 1706 epochs, was 1417.8891146183014\n",
      "\n",
      "EPOCH 1708  (with max 8000), loss: 0.0035896210465580225\n",
      "train time for 1708 epochs, was 1419.5281088352203\n",
      "\n",
      "EPOCH 1710  (with max 8000), loss: 0.006501663941890001\n",
      "train time for 1710 epochs, was 1421.161170721054\n",
      "\n",
      "EPOCH 1712  (with max 8000), loss: 0.002483678050339222\n",
      "train time for 1712 epochs, was 1422.7941963672638\n",
      "\n",
      "EPOCH 1714  (with max 8000), loss: 0.002849851967766881\n",
      "train time for 1714 epochs, was 1424.4269707202911\n",
      "\n",
      "EPOCH 1716  (with max 8000), loss: 0.0027817520312964916\n",
      "train time for 1716 epochs, was 1426.067993402481\n",
      "\n",
      "EPOCH 1718  (with max 8000), loss: 0.00106719508767128\n",
      "train time for 1718 epochs, was 1427.7008426189423\n",
      "\n",
      "EPOCH 1720  (with max 8000), loss: 0.003552954876795411\n",
      "train time for 1720 epochs, was 1429.3359835147858\n",
      "\n",
      "EPOCH 1722  (with max 8000), loss: 0.005696515087038279\n",
      "train time for 1722 epochs, was 1430.9689319133759\n",
      "\n",
      "EPOCH 1724  (with max 8000), loss: 0.0035345987416803837\n",
      "train time for 1724 epochs, was 1432.6016907691956\n",
      "\n",
      "EPOCH 1726  (with max 8000), loss: 0.001942143659107387\n",
      "train time for 1726 epochs, was 1434.2343819141388\n",
      "\n",
      "EPOCH 1728  (with max 8000), loss: 0.0007026995299383998\n",
      "train time for 1728 epochs, was 1435.890307188034\n",
      "\n",
      "EPOCH 1730  (with max 8000), loss: 0.003024327103048563\n",
      "train time for 1730 epochs, was 1437.5251183509827\n",
      "\n",
      "EPOCH 1732  (with max 8000), loss: 0.0018555037677288055\n",
      "train time for 1732 epochs, was 1439.1578063964844\n",
      "\n",
      "EPOCH 1734  (with max 8000), loss: 0.002718935953453183\n",
      "train time for 1734 epochs, was 1440.7905769348145\n",
      "\n",
      "EPOCH 1736  (with max 8000), loss: 0.0044548967853188515\n",
      "train time for 1736 epochs, was 1442.4235846996307\n",
      "\n",
      "EPOCH 1738  (with max 8000), loss: 0.0036845062859356403\n",
      "train time for 1738 epochs, was 1444.056293964386\n",
      "\n",
      "EPOCH 1740  (with max 8000), loss: 0.00048575460095889866\n",
      "train time for 1740 epochs, was 1445.688994884491\n",
      "\n",
      "EPOCH 1742  (with max 8000), loss: 0.0030294510070234537\n",
      "train time for 1742 epochs, was 1447.3218202590942\n",
      "\n",
      "EPOCH 1744  (with max 8000), loss: 0.000986632308922708\n",
      "train time for 1744 epochs, was 1448.9545238018036\n",
      "\n",
      "EPOCH 1746  (with max 8000), loss: 0.0034848442301154137\n",
      "train time for 1746 epochs, was 1450.5874562263489\n",
      "\n",
      "EPOCH 1748  (with max 8000), loss: 0.0037678119260817766\n",
      "train time for 1748 epochs, was 1452.2202541828156\n",
      "\n",
      "EPOCH 1750  (with max 8000), loss: 0.002138156211003661\n",
      "train time for 1750 epochs, was 1453.8530504703522\n",
      "\n",
      "EPOCH 1752  (with max 8000), loss: 0.005817206110805273\n",
      "train time for 1752 epochs, was 1455.4861931800842\n",
      "\n",
      "EPOCH 1754  (with max 8000), loss: 0.004362140782177448\n",
      "train time for 1754 epochs, was 1457.1192119121552\n",
      "\n",
      "EPOCH 1756  (with max 8000), loss: 0.002925940789282322\n",
      "train time for 1756 epochs, was 1458.7520172595978\n",
      "\n",
      "EPOCH 1758  (with max 8000), loss: 0.004737321753054857\n",
      "train time for 1758 epochs, was 1460.3848700523376\n",
      "\n",
      "EPOCH 1760  (with max 8000), loss: 0.0024137450382113457\n",
      "train time for 1760 epochs, was 1462.0177204608917\n",
      "\n",
      "EPOCH 1762  (with max 8000), loss: 0.002488153288140893\n",
      "train time for 1762 epochs, was 1463.6527564525604\n",
      "\n",
      "EPOCH 1764  (with max 8000), loss: 0.0013948441483080387\n",
      "train time for 1764 epochs, was 1465.2938876152039\n",
      "\n",
      "EPOCH 1766  (with max 8000), loss: 0.0022044512443244457\n",
      "train time for 1766 epochs, was 1466.9266231060028\n",
      "\n",
      "EPOCH 1768  (with max 8000), loss: 0.003862447803840041\n",
      "train time for 1768 epochs, was 1468.5614359378815\n",
      "\n",
      "EPOCH 1770  (with max 8000), loss: 0.8886932134628296\n",
      "train time for 1770 epochs, was 1470.1942846775055\n",
      "\n",
      "EPOCH 1772  (with max 8000), loss: 0.01311506424099207\n",
      "train time for 1772 epochs, was 1471.839694261551\n",
      "\n",
      "EPOCH 1774  (with max 8000), loss: 0.011307290755212307\n",
      "train time for 1774 epochs, was 1473.4724254608154\n",
      "\n",
      "EPOCH 1776  (with max 8000), loss: 0.0036571037489920855\n",
      "train time for 1776 epochs, was 1475.1054425239563\n",
      "\n",
      "EPOCH 1778  (with max 8000), loss: 0.008596380241215229\n",
      "train time for 1778 epochs, was 1476.7383522987366\n",
      "\n",
      "EPOCH 1780  (with max 8000), loss: 0.008274607360363007\n",
      "train time for 1780 epochs, was 1478.3714122772217\n",
      "\n",
      "EPOCH 1782  (with max 8000), loss: 0.004666673950850964\n",
      "train time for 1782 epochs, was 1480.0041728019714\n",
      "\n",
      "EPOCH 1784  (with max 8000), loss: 0.002244823845103383\n",
      "train time for 1784 epochs, was 1481.6369247436523\n",
      "\n",
      "EPOCH 1786  (with max 8000), loss: 0.0035584582947194576\n",
      "train time for 1786 epochs, was 1483.2696766853333\n",
      "\n",
      "EPOCH 1788  (with max 8000), loss: 0.0015485171461477876\n",
      "train time for 1788 epochs, was 1484.9026818275452\n",
      "\n",
      "EPOCH 1790  (with max 8000), loss: 0.001832519075833261\n",
      "train time for 1790 epochs, was 1486.5354948043823\n",
      "\n",
      "EPOCH 1792  (with max 8000), loss: 0.0018427777104079723\n",
      "train time for 1792 epochs, was 1488.1683621406555\n",
      "\n",
      "EPOCH 1794  (with max 8000), loss: 0.0015737457433715463\n",
      "train time for 1794 epochs, was 1489.8015687465668\n",
      "\n",
      "EPOCH 1796  (with max 8000), loss: 0.0008581553120166063\n",
      "train time for 1796 epochs, was 1491.4345352649689\n",
      "\n",
      "EPOCH 1798  (with max 8000), loss: 0.0037278381641954184\n",
      "train time for 1798 epochs, was 1493.067692041397\n",
      "\n",
      "EPOCH 1800  (with max 8000), loss: 0.001494255498982966\n",
      "train time for 1800 epochs, was 1494.7006425857544\n",
      "\n",
      "EPOCH 1800 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_1800.pth\n",
      "\n",
      "EPOCH 1802  (with max 8000), loss: 0.002352318959310651\n",
      "train time for 1802 epochs, was 1496.3691306114197\n",
      "\n",
      "EPOCH 1804  (with max 8000), loss: 0.0014348573749884963\n",
      "train time for 1804 epochs, was 1498.001894235611\n",
      "\n",
      "EPOCH 1806  (with max 8000), loss: 0.00020116884843446314\n",
      "train time for 1806 epochs, was 1499.6348428726196\n",
      "\n",
      "EPOCH 1808  (with max 8000), loss: 0.0021482035517692566\n",
      "train time for 1808 epochs, was 1501.2698256969452\n",
      "\n",
      "EPOCH 1810  (with max 8000), loss: 0.00353440223261714\n",
      "train time for 1810 epochs, was 1502.902826309204\n",
      "\n",
      "EPOCH 1812  (with max 8000), loss: 0.0031493769492954016\n",
      "train time for 1812 epochs, was 1504.5359168052673\n",
      "\n",
      "EPOCH 1814  (with max 8000), loss: 0.001968872733414173\n",
      "train time for 1814 epochs, was 1506.1686840057373\n",
      "\n",
      "EPOCH 1816  (with max 8000), loss: 0.0005416085477918386\n",
      "train time for 1816 epochs, was 1507.8036966323853\n",
      "\n",
      "EPOCH 1818  (with max 8000), loss: 0.00357429007999599\n",
      "train time for 1818 epochs, was 1509.4595391750336\n",
      "\n",
      "EPOCH 1820  (with max 8000), loss: 0.0009371489868499339\n",
      "train time for 1820 epochs, was 1511.0965473651886\n",
      "\n",
      "EPOCH 1822  (with max 8000), loss: 0.0019360389560461044\n",
      "train time for 1822 epochs, was 1512.7565207481384\n",
      "\n",
      "EPOCH 1824  (with max 8000), loss: 0.0003452943929005414\n",
      "train time for 1824 epochs, was 1514.3917446136475\n",
      "\n",
      "EPOCH 1826  (with max 8000), loss: 0.002083543222397566\n",
      "train time for 1826 epochs, was 1516.0247209072113\n",
      "\n",
      "EPOCH 1828  (with max 8000), loss: 0.00014314608415588737\n",
      "train time for 1828 epochs, was 1517.6575849056244\n",
      "\n",
      "EPOCH 1830  (with max 8000), loss: 0.0018861292628571391\n",
      "train time for 1830 epochs, was 1519.290672302246\n",
      "\n",
      "EPOCH 1832  (with max 8000), loss: 0.0027275157626718283\n",
      "train time for 1832 epochs, was 1520.9238407611847\n",
      "\n",
      "EPOCH 1834  (with max 8000), loss: 0.0016801990568637848\n",
      "train time for 1834 epochs, was 1522.5567555427551\n",
      "\n",
      "EPOCH 1836  (with max 8000), loss: 0.0020119629334658384\n",
      "train time for 1836 epochs, was 1524.1957747936249\n",
      "\n",
      "EPOCH 1838  (with max 8000), loss: 0.0008384995744563639\n",
      "train time for 1838 epochs, was 1525.8285837173462\n",
      "\n",
      "EPOCH 1840  (with max 8000), loss: 0.0015154238790273666\n",
      "train time for 1840 epochs, was 1527.4634943008423\n",
      "\n",
      "EPOCH 1842  (with max 8000), loss: 0.0072559635154902935\n",
      "train time for 1842 epochs, was 1529.1107285022736\n",
      "\n",
      "EPOCH 1844  (with max 8000), loss: 0.002380196237936616\n",
      "train time for 1844 epochs, was 1530.7655334472656\n",
      "\n",
      "EPOCH 1846  (with max 8000), loss: 0.002807190641760826\n",
      "train time for 1846 epochs, was 1532.4141261577606\n",
      "\n",
      "EPOCH 1848  (with max 8000), loss: 0.001057521323673427\n",
      "train time for 1848 epochs, was 1534.0589864253998\n",
      "\n",
      "EPOCH 1850  (with max 8000), loss: 0.0020177571568638086\n",
      "train time for 1850 epochs, was 1535.6998882293701\n",
      "\n",
      "EPOCH 1852  (with max 8000), loss: 0.002405388979241252\n",
      "train time for 1852 epochs, was 1537.3369460105896\n",
      "\n",
      "EPOCH 1854  (with max 8000), loss: 0.0009290864109061658\n",
      "train time for 1854 epochs, was 1538.9719240665436\n",
      "\n",
      "EPOCH 1856  (with max 8000), loss: 0.0013232855126261711\n",
      "train time for 1856 epochs, was 1540.6046614646912\n",
      "\n",
      "EPOCH 1858  (with max 8000), loss: 0.0007680722628720105\n",
      "train time for 1858 epochs, was 1542.2374949455261\n",
      "\n",
      "EPOCH 1860  (with max 8000), loss: 0.0008503441931679845\n",
      "train time for 1860 epochs, was 1543.8724992275238\n",
      "\n",
      "EPOCH 1862  (with max 8000), loss: 0.002400265773758292\n",
      "train time for 1862 epochs, was 1545.5156893730164\n",
      "\n",
      "EPOCH 1864  (with max 8000), loss: 0.008130544796586037\n",
      "train time for 1864 epochs, was 1547.157161474228\n",
      "\n",
      "EPOCH 1866  (with max 8000), loss: 0.0011759253684431314\n",
      "train time for 1866 epochs, was 1548.796499967575\n",
      "\n",
      "EPOCH 1868  (with max 8000), loss: 0.001694223959930241\n",
      "train time for 1868 epochs, was 1550.431842803955\n",
      "\n",
      "EPOCH 1870  (with max 8000), loss: 0.0042884922586381435\n",
      "train time for 1870 epochs, was 1552.0646812915802\n",
      "\n",
      "EPOCH 1872  (with max 8000), loss: 0.002728150226175785\n",
      "train time for 1872 epochs, was 1553.6975967884064\n",
      "\n",
      "EPOCH 1874  (with max 8000), loss: 0.00026598243857733905\n",
      "train time for 1874 epochs, was 1555.3304235935211\n",
      "\n",
      "EPOCH 1876  (with max 8000), loss: 0.0016715106321498752\n",
      "train time for 1876 epochs, was 1556.967536687851\n",
      "\n",
      "EPOCH 1878  (with max 8000), loss: 0.0022332414519041777\n",
      "train time for 1878 epochs, was 1558.6003959178925\n",
      "\n",
      "EPOCH 1880  (with max 8000), loss: 0.004156978335231543\n",
      "train time for 1880 epochs, was 1560.2333464622498\n",
      "\n",
      "EPOCH 1882  (with max 8000), loss: 0.0030943709425628185\n",
      "train time for 1882 epochs, was 1561.8661239147186\n",
      "\n",
      "EPOCH 1884  (with max 8000), loss: 0.003083988791331649\n",
      "train time for 1884 epochs, was 1563.501009941101\n",
      "\n",
      "EPOCH 1886  (with max 8000), loss: 0.0010763657046481967\n",
      "train time for 1886 epochs, was 1565.1340594291687\n",
      "\n",
      "EPOCH 1888  (with max 8000), loss: 0.005329606588929892\n",
      "train time for 1888 epochs, was 1566.7667679786682\n",
      "\n",
      "EPOCH 1890  (with max 8000), loss: 0.0013730988139286637\n",
      "train time for 1890 epochs, was 1568.40367436409\n",
      "\n",
      "EPOCH 1892  (with max 8000), loss: 0.003808514215052128\n",
      "train time for 1892 epochs, was 1570.0363383293152\n",
      "\n",
      "EPOCH 1894  (with max 8000), loss: 0.0027930373325943947\n",
      "train time for 1894 epochs, was 1571.6816582679749\n",
      "\n",
      "EPOCH 1896  (with max 8000), loss: 0.0030397665686905384\n",
      "train time for 1896 epochs, was 1573.3145310878754\n",
      "\n",
      "EPOCH 1898  (with max 8000), loss: 0.0020176912657916546\n",
      "train time for 1898 epochs, was 1574.9474442005157\n",
      "\n",
      "EPOCH 1900  (with max 8000), loss: 0.004132208880037069\n",
      "train time for 1900 epochs, was 1576.5803809165955\n",
      "\n",
      "EPOCH 1902  (with max 8000), loss: 0.002445229096338153\n",
      "train time for 1902 epochs, was 1578.2133708000183\n",
      "\n",
      "EPOCH 1904  (with max 8000), loss: 0.0036837118677794933\n",
      "train time for 1904 epochs, was 1579.8463435173035\n",
      "\n",
      "EPOCH 1906  (with max 8000), loss: 0.050376616418361664\n",
      "train time for 1906 epochs, was 1581.4915721416473\n",
      "\n",
      "EPOCH 1908  (with max 8000), loss: 0.006642879918217659\n",
      "train time for 1908 epochs, was 1583.1243233680725\n",
      "\n",
      "EPOCH 1910  (with max 8000), loss: 0.016972554847598076\n",
      "train time for 1910 epochs, was 1584.7611556053162\n",
      "\n",
      "EPOCH 1912  (with max 8000), loss: 0.004340291488915682\n",
      "train time for 1912 epochs, was 1586.3939793109894\n",
      "\n",
      "EPOCH 1914  (with max 8000), loss: 0.007945136167109013\n",
      "train time for 1914 epochs, was 1588.033063173294\n",
      "\n",
      "EPOCH 1916  (with max 8000), loss: 0.002100145211443305\n",
      "train time for 1916 epochs, was 1589.6677868366241\n",
      "\n",
      "EPOCH 1918  (with max 8000), loss: 0.003254872979596257\n",
      "train time for 1918 epochs, was 1591.3004982471466\n",
      "\n",
      "EPOCH 1920  (with max 8000), loss: 0.002931753406301141\n",
      "train time for 1920 epochs, was 1592.9334008693695\n",
      "\n",
      "EPOCH 1922  (with max 8000), loss: 0.0014612495433539152\n",
      "train time for 1922 epochs, was 1594.5662107467651\n",
      "\n",
      "EPOCH 1924  (with max 8000), loss: 0.008355118334293365\n",
      "train time for 1924 epochs, was 1596.199015378952\n",
      "\n",
      "EPOCH 1926  (with max 8000), loss: 0.0023725582286715508\n",
      "train time for 1926 epochs, was 1597.8338510990143\n",
      "\n",
      "EPOCH 1928  (with max 8000), loss: 0.00348901329562068\n",
      "train time for 1928 epochs, was 1599.4665839672089\n",
      "\n",
      "EPOCH 1930  (with max 8000), loss: 0.0006993359420448542\n",
      "train time for 1930 epochs, was 1601.0994112491608\n",
      "\n",
      "EPOCH 1932  (with max 8000), loss: 0.0030940985307097435\n",
      "train time for 1932 epochs, was 1602.7321486473083\n",
      "\n",
      "EPOCH 1934  (with max 8000), loss: 0.0010883505456149578\n",
      "train time for 1934 epochs, was 1604.364930152893\n",
      "\n",
      "EPOCH 1936  (with max 8000), loss: 0.0007862873608246446\n",
      "train time for 1936 epochs, was 1605.9977295398712\n",
      "\n",
      "EPOCH 1938  (with max 8000), loss: 0.003588823601603508\n",
      "train time for 1938 epochs, was 1607.6349217891693\n",
      "\n",
      "EPOCH 1940  (with max 8000), loss: 0.005440774839371443\n",
      "train time for 1940 epochs, was 1609.267968416214\n",
      "\n",
      "EPOCH 1942  (with max 8000), loss: 0.0034097630996257067\n",
      "train time for 1942 epochs, was 1610.9007723331451\n",
      "\n",
      "EPOCH 1944  (with max 8000), loss: 0.000616700213868171\n",
      "train time for 1944 epochs, was 1612.5335760116577\n",
      "\n",
      "EPOCH 1946  (with max 8000), loss: 0.000746044737752527\n",
      "train time for 1946 epochs, was 1614.1685361862183\n",
      "\n",
      "EPOCH 1948  (with max 8000), loss: 0.00020726045477204025\n",
      "train time for 1948 epochs, was 1615.8012111186981\n",
      "\n",
      "EPOCH 1950  (with max 8000), loss: 0.00108159554656595\n",
      "train time for 1950 epochs, was 1617.4611129760742\n",
      "\n",
      "EPOCH 1952  (with max 8000), loss: 0.0014749723486602306\n",
      "train time for 1952 epochs, was 1619.0938937664032\n",
      "\n",
      "EPOCH 1954  (with max 8000), loss: 0.002145919715985656\n",
      "train time for 1954 epochs, was 1620.7288291454315\n",
      "\n",
      "EPOCH 1956  (with max 8000), loss: 0.0020641149021685123\n",
      "train time for 1956 epochs, was 1622.363849401474\n",
      "\n",
      "EPOCH 1958  (with max 8000), loss: 0.0006232141749933362\n",
      "train time for 1958 epochs, was 1623.9965889453888\n",
      "\n",
      "EPOCH 1960  (with max 8000), loss: 0.0005012704059481621\n",
      "train time for 1960 epochs, was 1625.6292834281921\n",
      "\n",
      "EPOCH 1962  (with max 8000), loss: 0.0018581124022603035\n",
      "train time for 1962 epochs, was 1627.262110710144\n",
      "\n",
      "EPOCH 1964  (with max 8000), loss: 0.0005116545944474638\n",
      "train time for 1964 epochs, was 1628.895005941391\n",
      "\n",
      "EPOCH 1966  (with max 8000), loss: 0.0011919531971216202\n",
      "train time for 1966 epochs, was 1630.5278067588806\n",
      "\n",
      "EPOCH 1968  (with max 8000), loss: 0.0006022134330123663\n",
      "train time for 1968 epochs, was 1632.1607537269592\n",
      "\n",
      "EPOCH 1970  (with max 8000), loss: 0.0009262884850613773\n",
      "train time for 1970 epochs, was 1633.7957458496094\n",
      "\n",
      "EPOCH 1972  (with max 8000), loss: 0.0007689340272918344\n",
      "train time for 1972 epochs, was 1635.428547859192\n",
      "\n",
      "EPOCH 1974  (with max 8000), loss: 0.002773076994344592\n",
      "train time for 1974 epochs, was 1637.0615303516388\n",
      "\n",
      "EPOCH 1976  (with max 8000), loss: 0.003044883022084832\n",
      "train time for 1976 epochs, was 1638.694492340088\n",
      "\n",
      "EPOCH 1978  (with max 8000), loss: 0.001486610621213913\n",
      "train time for 1978 epochs, was 1640.3272790908813\n",
      "\n",
      "EPOCH 1980  (with max 8000), loss: 0.001863167155534029\n",
      "train time for 1980 epochs, was 1641.9602980613708\n",
      "\n",
      "EPOCH 1982  (with max 8000), loss: 0.0015327736036852002\n",
      "train time for 1982 epochs, was 1643.59538936615\n",
      "\n",
      "EPOCH 1984  (with max 8000), loss: 0.001355675864033401\n",
      "train time for 1984 epochs, was 1645.2282001972198\n",
      "\n",
      "EPOCH 1986  (with max 8000), loss: 0.0016146301059052348\n",
      "train time for 1986 epochs, was 1646.861029624939\n",
      "\n",
      "EPOCH 1988  (with max 8000), loss: 0.0011715904111042619\n",
      "train time for 1988 epochs, was 1648.4937388896942\n",
      "\n",
      "EPOCH 1990  (with max 8000), loss: 0.005521622486412525\n",
      "train time for 1990 epochs, was 1650.1267108917236\n",
      "\n",
      "EPOCH 1992  (with max 8000), loss: 0.0030697332695126534\n",
      "train time for 1992 epochs, was 1651.7594573497772\n",
      "\n",
      "EPOCH 1994  (with max 8000), loss: 0.003967038355767727\n",
      "train time for 1994 epochs, was 1653.3921778202057\n",
      "\n",
      "EPOCH 1996  (with max 8000), loss: 0.0010309298522770405\n",
      "train time for 1996 epochs, was 1655.033266544342\n",
      "\n",
      "EPOCH 1998  (with max 8000), loss: 0.004008002579212189\n",
      "train time for 1998 epochs, was 1656.6659750938416\n",
      "\n",
      "EPOCH 2000  (with max 8000), loss: 0.010149122215807438\n",
      "train time for 2000 epochs, was 1658.2987637519836\n",
      "\n",
      "EPOCH 2000 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_2000.pth\n",
      "\n",
      "EPOCH 2002  (with max 8000), loss: 0.00378564209677279\n",
      "train time for 2002 epochs, was 1659.9671790599823\n",
      "\n",
      "EPOCH 2004  (with max 8000), loss: 0.008720855228602886\n",
      "train time for 2004 epochs, was 1661.6019291877747\n",
      "\n",
      "EPOCH 2006  (with max 8000), loss: 0.0039270054548978806\n",
      "train time for 2006 epochs, was 1663.2345988750458\n",
      "\n",
      "EPOCH 2008  (with max 8000), loss: 0.00224301521666348\n",
      "train time for 2008 epochs, was 1664.8674309253693\n",
      "\n",
      "EPOCH 2010  (with max 8000), loss: 0.004507165867835283\n",
      "train time for 2010 epochs, was 1666.5001046657562\n",
      "\n",
      "EPOCH 2012  (with max 8000), loss: 0.0018358135130256414\n",
      "train time for 2012 epochs, was 1668.1350412368774\n",
      "\n",
      "EPOCH 2014  (with max 8000), loss: 0.0036133048124611378\n",
      "train time for 2014 epochs, was 1669.767958164215\n",
      "\n",
      "EPOCH 2016  (with max 8000), loss: 0.0021009212359786034\n",
      "train time for 2016 epochs, was 1671.4008424282074\n",
      "\n",
      "EPOCH 2018  (with max 8000), loss: 0.0029761299956589937\n",
      "train time for 2018 epochs, was 1673.0398833751678\n",
      "\n",
      "EPOCH 2020  (with max 8000), loss: 0.0009525284403935075\n",
      "train time for 2020 epochs, was 1674.6747303009033\n",
      "\n",
      "EPOCH 2022  (with max 8000), loss: 0.0033506848849356174\n",
      "train time for 2022 epochs, was 1676.309551000595\n",
      "\n",
      "EPOCH 2024  (with max 8000), loss: 0.0017340347403660417\n",
      "train time for 2024 epochs, was 1677.9506857395172\n",
      "\n",
      "EPOCH 2026  (with max 8000), loss: 0.0026259119622409344\n",
      "train time for 2026 epochs, was 1679.5899455547333\n",
      "\n",
      "EPOCH 2028  (with max 8000), loss: 0.001278941286727786\n",
      "train time for 2028 epochs, was 1681.224877357483\n",
      "\n",
      "EPOCH 2030  (with max 8000), loss: 0.003946478944271803\n",
      "train time for 2030 epochs, was 1682.8575751781464\n",
      "\n",
      "EPOCH 2032  (with max 8000), loss: 0.0035301432944834232\n",
      "train time for 2032 epochs, was 1684.4902336597443\n",
      "\n",
      "EPOCH 2034  (with max 8000), loss: 0.005687224678695202\n",
      "train time for 2034 epochs, was 1686.1253519058228\n",
      "\n",
      "EPOCH 2036  (with max 8000), loss: 0.002437255810946226\n",
      "train time for 2036 epochs, was 1687.7581408023834\n",
      "\n",
      "EPOCH 2038  (with max 8000), loss: 0.0013162161922082305\n",
      "train time for 2038 epochs, was 1689.3909301757812\n",
      "\n",
      "EPOCH 2040  (with max 8000), loss: 0.0021764556877315044\n",
      "train time for 2040 epochs, was 1691.0258944034576\n",
      "\n",
      "EPOCH 2042  (with max 8000), loss: 0.005118194501847029\n",
      "train time for 2042 epochs, was 1692.6796216964722\n",
      "\n",
      "EPOCH 2044  (with max 8000), loss: 0.001735536614432931\n",
      "train time for 2044 epochs, was 1694.314651966095\n",
      "\n",
      "EPOCH 2046  (with max 8000), loss: 0.003938915207982063\n",
      "train time for 2046 epochs, was 1695.94944190979\n",
      "\n",
      "EPOCH 2048  (with max 8000), loss: 0.002260553417727351\n",
      "train time for 2048 epochs, was 1697.5821924209595\n",
      "\n",
      "EPOCH 2050  (with max 8000), loss: 0.0028483616188168526\n",
      "train time for 2050 epochs, was 1699.2147965431213\n",
      "\n",
      "EPOCH 2052  (with max 8000), loss: 0.001855214941315353\n",
      "train time for 2052 epochs, was 1700.8476362228394\n",
      "\n",
      "EPOCH 2054  (with max 8000), loss: 0.004134288057684898\n",
      "train time for 2054 epochs, was 1702.4803953170776\n",
      "\n",
      "EPOCH 2056  (with max 8000), loss: 0.001972421770915389\n",
      "train time for 2056 epochs, was 1704.1131234169006\n",
      "\n",
      "EPOCH 2058  (with max 8000), loss: 0.0031604538671672344\n",
      "train time for 2058 epochs, was 1705.7459588050842\n",
      "\n",
      "EPOCH 2060  (with max 8000), loss: 0.006060902960598469\n",
      "train time for 2060 epochs, was 1707.3787972927094\n",
      "\n",
      "EPOCH 2062  (with max 8000), loss: 0.001633484149351716\n",
      "train time for 2062 epochs, was 1709.0115687847137\n",
      "\n",
      "EPOCH 2064  (with max 8000), loss: 0.001550228800624609\n",
      "train time for 2064 epochs, was 1710.644392490387\n",
      "\n",
      "EPOCH 2066  (with max 8000), loss: 0.009616043418645859\n",
      "train time for 2066 epochs, was 1712.2772042751312\n",
      "\n",
      "EPOCH 2068  (with max 8000), loss: 0.003989933989942074\n",
      "train time for 2068 epochs, was 1713.9099788665771\n",
      "\n",
      "EPOCH 2070  (with max 8000), loss: 0.006827046629041433\n",
      "train time for 2070 epochs, was 1715.5428972244263\n",
      "\n",
      "EPOCH 2072  (with max 8000), loss: 0.004589310381561518\n",
      "train time for 2072 epochs, was 1717.1756007671356\n",
      "\n",
      "EPOCH 2074  (with max 8000), loss: 0.0032771951518952847\n",
      "train time for 2074 epochs, was 1718.8083341121674\n",
      "\n",
      "EPOCH 2076  (with max 8000), loss: 0.0020332776475697756\n",
      "train time for 2076 epochs, was 1720.4411656856537\n",
      "\n",
      "EPOCH 2078  (with max 8000), loss: 0.004164788406342268\n",
      "train time for 2078 epochs, was 1722.074111700058\n",
      "\n",
      "EPOCH 2080  (with max 8000), loss: 0.0018891779473051429\n",
      "train time for 2080 epochs, was 1723.7068967819214\n",
      "\n",
      "EPOCH 2082  (with max 8000), loss: 0.004796802531927824\n",
      "train time for 2082 epochs, was 1725.3397662639618\n",
      "\n",
      "EPOCH 2084  (with max 8000), loss: 0.0033584744669497013\n",
      "train time for 2084 epochs, was 1726.9744741916656\n",
      "\n",
      "EPOCH 2086  (with max 8000), loss: 0.002459976589307189\n",
      "train time for 2086 epochs, was 1728.6365730762482\n",
      "\n",
      "EPOCH 2088  (with max 8000), loss: 0.001829972374252975\n",
      "train time for 2088 epochs, was 1730.2717471122742\n",
      "\n",
      "EPOCH 2090  (with max 8000), loss: 0.0019302333239465952\n",
      "train time for 2090 epochs, was 1731.9045226573944\n",
      "\n",
      "EPOCH 2092  (with max 8000), loss: 0.0020956892985850573\n",
      "train time for 2092 epochs, was 1733.5372455120087\n",
      "\n",
      "EPOCH 2094  (with max 8000), loss: 0.0021400339901447296\n",
      "train time for 2094 epochs, was 1735.1720352172852\n",
      "\n",
      "EPOCH 2096  (with max 8000), loss: 0.0012880569556728005\n",
      "train time for 2096 epochs, was 1736.8070948123932\n",
      "\n",
      "EPOCH 2098  (with max 8000), loss: 0.0012690949952229857\n",
      "train time for 2098 epochs, was 1738.4398431777954\n",
      "\n",
      "EPOCH 2100  (with max 8000), loss: 0.0036674689035862684\n",
      "train time for 2100 epochs, was 1740.0726091861725\n",
      "\n",
      "EPOCH 2102  (with max 8000), loss: 0.0033370237797498703\n",
      "train time for 2102 epochs, was 1741.705377817154\n",
      "\n",
      "EPOCH 2104  (with max 8000), loss: 0.2522618770599365\n",
      "train time for 2104 epochs, was 1743.340496301651\n",
      "\n",
      "EPOCH 2106  (with max 8000), loss: 0.018483245745301247\n",
      "train time for 2106 epochs, was 1744.9732682704926\n",
      "\n",
      "EPOCH 2108  (with max 8000), loss: 0.007896251045167446\n",
      "train time for 2108 epochs, was 1746.6079723834991\n",
      "\n",
      "EPOCH 2110  (with max 8000), loss: 0.006006912793964148\n",
      "train time for 2110 epochs, was 1748.2407765388489\n",
      "\n",
      "EPOCH 2112  (with max 8000), loss: 0.005457004066556692\n",
      "train time for 2112 epochs, was 1749.873521566391\n",
      "\n",
      "EPOCH 2114  (with max 8000), loss: 0.003207259578630328\n",
      "train time for 2114 epochs, was 1751.5085933208466\n",
      "\n",
      "EPOCH 2116  (with max 8000), loss: 0.004605433903634548\n",
      "train time for 2116 epochs, was 1753.1434621810913\n",
      "\n",
      "EPOCH 2118  (with max 8000), loss: 0.0012102595064789057\n",
      "train time for 2118 epochs, was 1754.7762243747711\n",
      "\n",
      "EPOCH 2120  (with max 8000), loss: 0.003983810544013977\n",
      "train time for 2120 epochs, was 1756.4088339805603\n",
      "\n",
      "EPOCH 2122  (with max 8000), loss: 0.00320821744389832\n",
      "train time for 2122 epochs, was 1758.0416362285614\n",
      "\n",
      "EPOCH 2124  (with max 8000), loss: 0.002274590777233243\n",
      "train time for 2124 epochs, was 1759.674295425415\n",
      "\n",
      "EPOCH 2126  (with max 8000), loss: 0.0016258101677522063\n",
      "train time for 2126 epochs, was 1761.3070085048676\n",
      "\n",
      "EPOCH 2128  (with max 8000), loss: 0.003199427155777812\n",
      "train time for 2128 epochs, was 1762.9398250579834\n",
      "\n",
      "EPOCH 2130  (with max 8000), loss: 0.0014679041923955083\n",
      "train time for 2130 epochs, was 1764.5957443714142\n",
      "\n",
      "EPOCH 2132  (with max 8000), loss: 0.0008776772883720696\n",
      "train time for 2132 epochs, was 1766.2284498214722\n",
      "\n",
      "EPOCH 2134  (with max 8000), loss: 0.0013949248241260648\n",
      "train time for 2134 epochs, was 1767.8611688613892\n",
      "\n",
      "EPOCH 2136  (with max 8000), loss: 0.002564145252108574\n",
      "train time for 2136 epochs, was 1769.4939367771149\n",
      "\n",
      "EPOCH 2138  (with max 8000), loss: 0.001921213697642088\n",
      "train time for 2138 epochs, was 1771.1267795562744\n",
      "\n",
      "EPOCH 2140  (with max 8000), loss: 0.001476110192015767\n",
      "train time for 2140 epochs, was 1772.7596397399902\n",
      "\n",
      "EPOCH 2142  (with max 8000), loss: 0.0026296554133296013\n",
      "train time for 2142 epochs, was 1774.3926227092743\n",
      "\n",
      "EPOCH 2144  (with max 8000), loss: 0.004647294525057077\n",
      "train time for 2144 epochs, was 1776.0252885818481\n",
      "\n",
      "EPOCH 2146  (with max 8000), loss: 0.0011268951930105686\n",
      "train time for 2146 epochs, was 1777.658063173294\n",
      "\n",
      "EPOCH 2148  (with max 8000), loss: 0.0003189851122442633\n",
      "train time for 2148 epochs, was 1779.2908709049225\n",
      "\n",
      "EPOCH 2150  (with max 8000), loss: 0.0006640151259489357\n",
      "train time for 2150 epochs, was 1780.9235644340515\n",
      "\n",
      "EPOCH 2152  (with max 8000), loss: 0.0018820154946297407\n",
      "train time for 2152 epochs, was 1782.5563247203827\n",
      "\n",
      "EPOCH 2154  (with max 8000), loss: 0.0012416678946465254\n",
      "train time for 2154 epochs, was 1784.1889774799347\n",
      "\n",
      "EPOCH 2156  (with max 8000), loss: 0.002297881757840514\n",
      "train time for 2156 epochs, was 1785.821692943573\n",
      "\n",
      "EPOCH 2158  (with max 8000), loss: 0.002768350765109062\n",
      "train time for 2158 epochs, was 1787.4546902179718\n",
      "\n",
      "EPOCH 2160  (with max 8000), loss: 0.0014217726420611143\n",
      "train time for 2160 epochs, was 1789.0895643234253\n",
      "\n",
      "EPOCH 2162  (with max 8000), loss: 0.0020919411908835173\n",
      "train time for 2162 epochs, was 1790.7222409248352\n",
      "\n",
      "EPOCH 2164  (with max 8000), loss: 0.0024248752743005753\n",
      "train time for 2164 epochs, was 1792.3552260398865\n",
      "\n",
      "EPOCH 2166  (with max 8000), loss: 0.0007959577487781644\n",
      "train time for 2166 epochs, was 1793.9882383346558\n",
      "\n",
      "EPOCH 2168  (with max 8000), loss: 0.0007372452528215945\n",
      "train time for 2168 epochs, was 1795.6208996772766\n",
      "\n",
      "EPOCH 2170  (with max 8000), loss: 0.003335061250254512\n",
      "train time for 2170 epochs, was 1797.2536940574646\n",
      "\n",
      "EPOCH 2172  (with max 8000), loss: 0.003854217939078808\n",
      "train time for 2172 epochs, was 1798.886340379715\n",
      "\n",
      "EPOCH 2174  (with max 8000), loss: 0.0022490841802209616\n",
      "train time for 2174 epochs, was 1800.5232377052307\n",
      "\n",
      "EPOCH 2176  (with max 8000), loss: 0.0011179711436852813\n",
      "train time for 2176 epochs, was 1802.1560173034668\n",
      "\n",
      "EPOCH 2178  (with max 8000), loss: 0.0023421423975378275\n",
      "train time for 2178 epochs, was 1803.788688659668\n",
      "\n",
      "EPOCH 2180  (with max 8000), loss: 0.002745431149378419\n",
      "train time for 2180 epochs, was 1805.4215037822723\n",
      "\n",
      "EPOCH 2182  (with max 8000), loss: 0.0008282049675472081\n",
      "train time for 2182 epochs, was 1807.054446220398\n",
      "\n",
      "EPOCH 2184  (with max 8000), loss: 0.0009992533596232533\n",
      "train time for 2184 epochs, was 1808.687339067459\n",
      "\n",
      "EPOCH 2186  (with max 8000), loss: 0.002623210661113262\n",
      "train time for 2186 epochs, was 1810.3202414512634\n",
      "\n",
      "EPOCH 2188  (with max 8000), loss: 0.012538752518594265\n",
      "train time for 2188 epochs, was 1811.9529995918274\n",
      "\n",
      "EPOCH 2190  (with max 8000), loss: 0.02387358620762825\n",
      "train time for 2190 epochs, was 1813.585713148117\n",
      "\n",
      "EPOCH 2192  (with max 8000), loss: 0.007295782677829266\n",
      "train time for 2192 epochs, was 1815.2185101509094\n",
      "\n",
      "EPOCH 2194  (with max 8000), loss: 0.004071040078997612\n",
      "train time for 2194 epochs, was 1816.8512501716614\n",
      "\n",
      "EPOCH 2196  (with max 8000), loss: 0.003782242303714156\n",
      "train time for 2196 epochs, was 1818.4860818386078\n",
      "\n",
      "EPOCH 2198  (with max 8000), loss: 0.0051587666384875774\n",
      "train time for 2198 epochs, was 1820.118768453598\n",
      "\n",
      "EPOCH 2200  (with max 8000), loss: 0.0030887234024703503\n",
      "train time for 2200 epochs, was 1821.7514338493347\n",
      "\n",
      "EPOCH 2200 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_2200.pth\n",
      "\n",
      "EPOCH 2202  (with max 8000), loss: 0.008310288190841675\n",
      "train time for 2202 epochs, was 1823.4200086593628\n",
      "\n",
      "EPOCH 2204  (with max 8000), loss: 0.0028446607757359743\n",
      "train time for 2204 epochs, was 1825.0527243614197\n",
      "\n",
      "EPOCH 2206  (with max 8000), loss: 0.00445621507242322\n",
      "train time for 2206 epochs, was 1826.6855618953705\n",
      "\n",
      "EPOCH 2208  (with max 8000), loss: 0.007433138322085142\n",
      "train time for 2208 epochs, was 1828.3183028697968\n",
      "\n",
      "EPOCH 2210  (with max 8000), loss: 0.004315183497965336\n",
      "train time for 2210 epochs, was 1829.953402042389\n",
      "\n",
      "EPOCH 2212  (with max 8000), loss: 0.0014319842448458076\n",
      "train time for 2212 epochs, was 1831.5861916542053\n",
      "\n",
      "EPOCH 2214  (with max 8000), loss: 0.0028937412425875664\n",
      "train time for 2214 epochs, was 1833.2209522724152\n",
      "\n",
      "EPOCH 2216  (with max 8000), loss: 0.0011329151457175612\n",
      "train time for 2216 epochs, was 1834.853627204895\n",
      "\n",
      "EPOCH 2218  (with max 8000), loss: 0.0024934588000178337\n",
      "train time for 2218 epochs, was 1836.4864301681519\n",
      "\n",
      "EPOCH 2220  (with max 8000), loss: 0.0013357752468436956\n",
      "train time for 2220 epochs, was 1838.13587641716\n",
      "\n",
      "EPOCH 2222  (with max 8000), loss: 0.0009086214122362435\n",
      "train time for 2222 epochs, was 1839.7686343193054\n",
      "\n",
      "EPOCH 2224  (with max 8000), loss: 0.00029631704092025757\n",
      "train time for 2224 epochs, was 1841.4012813568115\n",
      "\n",
      "EPOCH 2226  (with max 8000), loss: 0.0026249373331665993\n",
      "train time for 2226 epochs, was 1843.036295413971\n",
      "\n",
      "EPOCH 2228  (with max 8000), loss: 0.0023045537527650595\n",
      "train time for 2228 epochs, was 1844.6734380722046\n",
      "\n",
      "EPOCH 2230  (with max 8000), loss: 0.008188347332179546\n",
      "train time for 2230 epochs, was 1846.3062825202942\n",
      "\n",
      "EPOCH 2232  (with max 8000), loss: 0.0033052621874958277\n",
      "train time for 2232 epochs, was 1847.938931941986\n",
      "\n",
      "EPOCH 2234  (with max 8000), loss: 0.0023157941177487373\n",
      "train time for 2234 epochs, was 1849.5884339809418\n",
      "\n",
      "EPOCH 2236  (with max 8000), loss: 0.002527025993913412\n",
      "train time for 2236 epochs, was 1851.221135377884\n",
      "\n",
      "EPOCH 2238  (with max 8000), loss: 0.0013543212553486228\n",
      "train time for 2238 epochs, was 1852.8538138866425\n",
      "\n",
      "EPOCH 2240  (with max 8000), loss: 0.01217599492520094\n",
      "train time for 2240 epochs, was 1854.4908328056335\n",
      "\n",
      "EPOCH 2242  (with max 8000), loss: 0.002871172036975622\n",
      "train time for 2242 epochs, was 1856.1234955787659\n",
      "\n",
      "EPOCH 2244  (with max 8000), loss: 0.0029569061007350683\n",
      "train time for 2244 epochs, was 1857.7562704086304\n",
      "\n",
      "EPOCH 2246  (with max 8000), loss: 0.001364676863886416\n",
      "train time for 2246 epochs, was 1859.3889274597168\n",
      "\n",
      "EPOCH 2248  (with max 8000), loss: 0.004086358938366175\n",
      "train time for 2248 epochs, was 1861.0237519741058\n",
      "\n",
      "EPOCH 2250  (with max 8000), loss: 0.0037300894036889076\n",
      "train time for 2250 epochs, was 1862.6584961414337\n",
      "\n",
      "EPOCH 2252  (with max 8000), loss: 0.0038715407717972994\n",
      "train time for 2252 epochs, was 1864.2952933311462\n",
      "\n",
      "EPOCH 2254  (with max 8000), loss: 0.0005612110835500062\n",
      "train time for 2254 epochs, was 1865.930347442627\n",
      "\n",
      "EPOCH 2256  (with max 8000), loss: 0.0045203762128949165\n",
      "train time for 2256 epochs, was 1867.5632219314575\n",
      "\n",
      "EPOCH 2258  (with max 8000), loss: 0.006663308013230562\n",
      "train time for 2258 epochs, was 1869.1958267688751\n",
      "\n",
      "EPOCH 2260  (with max 8000), loss: 0.00519533921033144\n",
      "train time for 2260 epochs, was 1870.832647562027\n",
      "\n",
      "EPOCH 2262  (with max 8000), loss: 0.005304974503815174\n",
      "train time for 2262 epochs, was 1872.465428352356\n",
      "\n",
      "EPOCH 2264  (with max 8000), loss: 0.0012264681281521916\n",
      "train time for 2264 epochs, was 1874.1236221790314\n",
      "\n",
      "EPOCH 2266  (with max 8000), loss: 0.004255841951817274\n",
      "train time for 2266 epochs, was 1875.758458852768\n",
      "\n",
      "EPOCH 2268  (with max 8000), loss: 0.006928042508661747\n",
      "train time for 2268 epochs, was 1877.3911397457123\n",
      "\n",
      "EPOCH 2270  (with max 8000), loss: 0.004970930516719818\n",
      "train time for 2270 epochs, was 1879.0238482952118\n",
      "\n",
      "EPOCH 2272  (with max 8000), loss: 0.006837758235633373\n",
      "train time for 2272 epochs, was 1880.6567158699036\n",
      "\n",
      "EPOCH 2274  (with max 8000), loss: 0.0063672191463410854\n",
      "train time for 2274 epochs, was 1882.2895073890686\n",
      "\n",
      "EPOCH 2276  (with max 8000), loss: 0.0016623303527012467\n",
      "train time for 2276 epochs, was 1883.9222857952118\n",
      "\n",
      "EPOCH 2278  (with max 8000), loss: 0.003373080864548683\n",
      "train time for 2278 epochs, was 1885.5550298690796\n",
      "\n",
      "EPOCH 2280  (with max 8000), loss: 0.0010512301232665777\n",
      "train time for 2280 epochs, was 1887.1900007724762\n",
      "\n",
      "EPOCH 2282  (with max 8000), loss: 0.0035364385694265366\n",
      "train time for 2282 epochs, was 1888.8226635456085\n",
      "\n",
      "EPOCH 2284  (with max 8000), loss: 0.0034080941695719957\n",
      "train time for 2284 epochs, was 1890.4595804214478\n",
      "\n",
      "EPOCH 2286  (with max 8000), loss: 0.0003405278839636594\n",
      "train time for 2286 epochs, was 1892.0943083763123\n",
      "\n",
      "EPOCH 2288  (with max 8000), loss: 0.006361211184412241\n",
      "train time for 2288 epochs, was 1893.7272124290466\n",
      "\n",
      "EPOCH 2290  (with max 8000), loss: 0.004248343873769045\n",
      "train time for 2290 epochs, was 1895.3598799705505\n",
      "\n",
      "EPOCH 2292  (with max 8000), loss: 0.004556029569357634\n",
      "train time for 2292 epochs, was 1896.9925825595856\n",
      "\n",
      "EPOCH 2294  (with max 8000), loss: 0.0018452079966664314\n",
      "train time for 2294 epochs, was 1898.6315619945526\n",
      "\n",
      "EPOCH 2296  (with max 8000), loss: 0.005493178032338619\n",
      "train time for 2296 epochs, was 1900.2663269042969\n",
      "\n",
      "EPOCH 2298  (with max 8000), loss: 0.010028386488556862\n",
      "train time for 2298 epochs, was 1901.8991615772247\n",
      "\n",
      "EPOCH 2300  (with max 8000), loss: 0.007323873229324818\n",
      "train time for 2300 epochs, was 1903.533936738968\n",
      "\n",
      "EPOCH 2302  (with max 8000), loss: 0.0035094544291496277\n",
      "train time for 2302 epochs, was 1905.168710231781\n",
      "\n",
      "EPOCH 2304  (with max 8000), loss: 0.003858470357954502\n",
      "train time for 2304 epochs, was 1906.801344871521\n",
      "\n",
      "EPOCH 2306  (with max 8000), loss: 0.006345903966575861\n",
      "train time for 2306 epochs, was 1908.4341447353363\n",
      "\n",
      "EPOCH 2308  (with max 8000), loss: 0.004250648431479931\n",
      "train time for 2308 epochs, was 1910.0713925361633\n",
      "\n",
      "EPOCH 2310  (with max 8000), loss: 0.0020631796214729548\n",
      "train time for 2310 epochs, was 1911.7084319591522\n",
      "\n",
      "EPOCH 2312  (with max 8000), loss: 0.001714152516797185\n",
      "train time for 2312 epochs, was 1913.3411319255829\n",
      "\n",
      "EPOCH 2314  (with max 8000), loss: 0.00378026464022696\n",
      "train time for 2314 epochs, was 1914.97802400589\n",
      "\n",
      "EPOCH 2316  (with max 8000), loss: 0.0009065520716831088\n",
      "train time for 2316 epochs, was 1916.6254932880402\n",
      "\n",
      "EPOCH 2318  (with max 8000), loss: 0.00222253380343318\n",
      "train time for 2318 epochs, was 1918.2583420276642\n",
      "\n",
      "EPOCH 2320  (with max 8000), loss: 0.002359038684517145\n",
      "train time for 2320 epochs, was 1919.8911616802216\n",
      "\n",
      "EPOCH 2322  (with max 8000), loss: 0.014960741624236107\n",
      "train time for 2322 epochs, was 1921.523909330368\n",
      "\n",
      "EPOCH 2324  (with max 8000), loss: 0.003882747143507004\n",
      "train time for 2324 epochs, was 1923.1566271781921\n",
      "\n",
      "EPOCH 2326  (with max 8000), loss: 0.013364500366151333\n",
      "train time for 2326 epochs, was 1924.7892429828644\n",
      "\n",
      "EPOCH 2328  (with max 8000), loss: 0.0029772345442324877\n",
      "train time for 2328 epochs, was 1926.4219105243683\n",
      "\n",
      "EPOCH 2330  (with max 8000), loss: 0.0055694556795060635\n",
      "train time for 2330 epochs, was 1928.0545434951782\n",
      "\n",
      "EPOCH 2332  (with max 8000), loss: 0.0028549651615321636\n",
      "train time for 2332 epochs, was 1929.6873364448547\n",
      "\n",
      "EPOCH 2334  (with max 8000), loss: 0.04379933327436447\n",
      "train time for 2334 epochs, was 1931.319936990738\n",
      "\n",
      "EPOCH 2336  (with max 8000), loss: 0.03063878044486046\n",
      "train time for 2336 epochs, was 1932.95264005661\n",
      "\n",
      "EPOCH 2338  (with max 8000), loss: 0.01909804157912731\n",
      "train time for 2338 epochs, was 1934.5853083133698\n",
      "\n",
      "EPOCH 2340  (with max 8000), loss: 0.004643851425498724\n",
      "train time for 2340 epochs, was 1936.2180714607239\n",
      "\n",
      "EPOCH 2342  (with max 8000), loss: 0.003969969693571329\n",
      "train time for 2342 epochs, was 1937.8508071899414\n",
      "\n",
      "EPOCH 2344  (with max 8000), loss: 0.00548552256077528\n",
      "train time for 2344 epochs, was 1939.4834394454956\n",
      "\n",
      "EPOCH 2346  (with max 8000), loss: 0.0013907139655202627\n",
      "train time for 2346 epochs, was 1941.1161313056946\n",
      "\n",
      "EPOCH 2348  (with max 8000), loss: 0.003197085577994585\n",
      "train time for 2348 epochs, was 1942.7489476203918\n",
      "\n",
      "EPOCH 2350  (with max 8000), loss: 0.002386240055784583\n",
      "train time for 2350 epochs, was 1944.3817892074585\n",
      "\n",
      "EPOCH 2352  (with max 8000), loss: 0.0032360446639358997\n",
      "train time for 2352 epochs, was 1946.0396163463593\n",
      "\n",
      "EPOCH 2354  (with max 8000), loss: 0.0003936893481295556\n",
      "train time for 2354 epochs, was 1947.6722693443298\n",
      "\n",
      "EPOCH 2356  (with max 8000), loss: 0.0034778397530317307\n",
      "train time for 2356 epochs, was 1949.3047647476196\n",
      "\n",
      "EPOCH 2358  (with max 8000), loss: 0.0012796525843441486\n",
      "train time for 2358 epochs, was 1950.9374890327454\n",
      "\n",
      "EPOCH 2360  (with max 8000), loss: 0.0024656876921653748\n",
      "train time for 2360 epochs, was 1952.5702199935913\n",
      "\n",
      "EPOCH 2362  (with max 8000), loss: 0.002180967014282942\n",
      "train time for 2362 epochs, was 1954.2049095630646\n",
      "\n",
      "EPOCH 2364  (with max 8000), loss: 0.002655091928318143\n",
      "train time for 2364 epochs, was 1955.8375639915466\n",
      "\n",
      "EPOCH 2366  (with max 8000), loss: 0.0018587110098451376\n",
      "train time for 2366 epochs, was 1957.4701647758484\n",
      "\n",
      "EPOCH 2368  (with max 8000), loss: 0.0016831083921715617\n",
      "train time for 2368 epochs, was 1959.1050808429718\n",
      "\n",
      "EPOCH 2370  (with max 8000), loss: 0.0010821936884894967\n",
      "train time for 2370 epochs, was 1960.745967388153\n",
      "\n",
      "EPOCH 2372  (with max 8000), loss: 0.0008313256548717618\n",
      "train time for 2372 epochs, was 1962.3808181285858\n",
      "\n",
      "EPOCH 2374  (with max 8000), loss: 0.0015321626560762525\n",
      "train time for 2374 epochs, was 1964.0134465694427\n",
      "\n",
      "EPOCH 2376  (with max 8000), loss: 0.000705321435816586\n",
      "train time for 2376 epochs, was 1965.648355960846\n",
      "\n",
      "EPOCH 2378  (with max 8000), loss: 0.0028494333382695913\n",
      "train time for 2378 epochs, was 1967.2812144756317\n",
      "\n",
      "EPOCH 2380  (with max 8000), loss: 0.002693776274099946\n",
      "train time for 2380 epochs, was 1968.9140312671661\n",
      "\n",
      "EPOCH 2382  (with max 8000), loss: 0.010082254186272621\n",
      "train time for 2382 epochs, was 1970.546837091446\n",
      "\n",
      "EPOCH 2384  (with max 8000), loss: 0.0022619341034442186\n",
      "train time for 2384 epochs, was 1972.1794488430023\n",
      "\n",
      "EPOCH 2386  (with max 8000), loss: 0.001540825585834682\n",
      "train time for 2386 epochs, was 1973.8121418952942\n",
      "\n",
      "EPOCH 2388  (with max 8000), loss: 0.001692113815806806\n",
      "train time for 2388 epochs, was 1975.4447588920593\n",
      "\n",
      "EPOCH 2390  (with max 8000), loss: 0.0034171869046986103\n",
      "train time for 2390 epochs, was 1977.0774137973785\n",
      "\n",
      "EPOCH 2392  (with max 8000), loss: 0.0017141778953373432\n",
      "train time for 2392 epochs, was 1978.7121760845184\n",
      "\n",
      "EPOCH 2394  (with max 8000), loss: 0.0015773969935253263\n",
      "train time for 2394 epochs, was 1980.344962835312\n",
      "\n",
      "EPOCH 2396  (with max 8000), loss: 0.004114959854632616\n",
      "train time for 2396 epochs, was 1981.9775559902191\n",
      "\n",
      "EPOCH 2398  (with max 8000), loss: 0.006576519925147295\n",
      "train time for 2398 epochs, was 1983.6247324943542\n",
      "\n",
      "EPOCH 2400  (with max 8000), loss: 0.0161284189671278\n",
      "train time for 2400 epochs, was 1985.2573566436768\n",
      "\n",
      "EPOCH 2400 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_2400.pth\n",
      "\n",
      "EPOCH 2402  (with max 8000), loss: 0.004608905408531427\n",
      "train time for 2402 epochs, was 1986.9445576667786\n",
      "\n",
      "EPOCH 2404  (with max 8000), loss: 0.00815399456769228\n",
      "train time for 2404 epochs, was 1988.581348657608\n",
      "\n",
      "EPOCH 2406  (with max 8000), loss: 0.007957380264997482\n",
      "train time for 2406 epochs, was 1990.2141344547272\n",
      "\n",
      "EPOCH 2408  (with max 8000), loss: 0.006244736723601818\n",
      "train time for 2408 epochs, was 1991.8469099998474\n",
      "\n",
      "EPOCH 2410  (with max 8000), loss: 0.003606041893362999\n",
      "train time for 2410 epochs, was 1993.4817531108856\n",
      "\n",
      "EPOCH 2412  (with max 8000), loss: 0.0025424675550311804\n",
      "train time for 2412 epochs, was 1995.1187148094177\n",
      "\n",
      "EPOCH 2414  (with max 8000), loss: 0.008271037600934505\n",
      "train time for 2414 epochs, was 1996.7513666152954\n",
      "\n",
      "EPOCH 2416  (with max 8000), loss: 0.0020833779126405716\n",
      "train time for 2416 epochs, was 1998.384179353714\n",
      "\n",
      "EPOCH 2418  (with max 8000), loss: 0.0028479842003434896\n",
      "train time for 2418 epochs, was 2000.016922712326\n",
      "\n",
      "EPOCH 2420  (with max 8000), loss: 0.0017281078035011888\n",
      "train time for 2420 epochs, was 2001.6496176719666\n",
      "\n",
      "EPOCH 2422  (with max 8000), loss: 0.002267340896651149\n",
      "train time for 2422 epochs, was 2003.2822632789612\n",
      "\n",
      "EPOCH 2424  (with max 8000), loss: 0.0023053560871630907\n",
      "train time for 2424 epochs, was 2004.9147531986237\n",
      "\n",
      "EPOCH 2426  (with max 8000), loss: 0.0011884925188496709\n",
      "train time for 2426 epochs, was 2006.54731798172\n",
      "\n",
      "EPOCH 2428  (with max 8000), loss: 0.0017152022337540984\n",
      "train time for 2428 epochs, was 2008.179827451706\n",
      "\n",
      "EPOCH 2430  (with max 8000), loss: 0.0029461118392646313\n",
      "train time for 2430 epochs, was 2009.8125739097595\n",
      "\n",
      "EPOCH 2432  (with max 8000), loss: 0.0036419860552996397\n",
      "train time for 2432 epochs, was 2011.445142507553\n",
      "\n",
      "EPOCH 2434  (with max 8000), loss: 0.005261078476905823\n",
      "train time for 2434 epochs, was 2013.077630519867\n",
      "\n",
      "EPOCH 2436  (with max 8000), loss: 0.004427916835993528\n",
      "train time for 2436 epochs, was 2014.7124569416046\n",
      "\n",
      "EPOCH 2438  (with max 8000), loss: 0.0017343522049486637\n",
      "train time for 2438 epochs, was 2016.3452627658844\n",
      "\n",
      "EPOCH 2440  (with max 8000), loss: 0.002129823202267289\n",
      "train time for 2440 epochs, was 2017.9778516292572\n",
      "\n",
      "EPOCH 2442  (with max 8000), loss: 0.0016508790431544185\n",
      "train time for 2442 epochs, was 2019.6146693229675\n",
      "\n",
      "EPOCH 2444  (with max 8000), loss: 0.0015807992313057184\n",
      "train time for 2444 epochs, was 2021.2514081001282\n",
      "\n",
      "EPOCH 2446  (with max 8000), loss: 0.0028803644236177206\n",
      "train time for 2446 epochs, was 2022.8841359615326\n",
      "\n",
      "EPOCH 2448  (with max 8000), loss: 0.001392194302752614\n",
      "train time for 2448 epochs, was 2024.5167758464813\n",
      "\n",
      "EPOCH 2450  (with max 8000), loss: 0.0014349168632179499\n",
      "train time for 2450 epochs, was 2026.1516382694244\n",
      "\n",
      "EPOCH 2452  (with max 8000), loss: 0.002354790223762393\n",
      "train time for 2452 epochs, was 2027.7842359542847\n",
      "\n",
      "EPOCH 2454  (with max 8000), loss: 0.0010661898413673043\n",
      "train time for 2454 epochs, was 2029.4169647693634\n",
      "\n",
      "EPOCH 2456  (with max 8000), loss: 0.0007187684532254934\n",
      "train time for 2456 epochs, was 2031.049685716629\n",
      "\n",
      "EPOCH 2458  (with max 8000), loss: 0.0032279372680932283\n",
      "train time for 2458 epochs, was 2032.6822454929352\n",
      "\n",
      "EPOCH 2460  (with max 8000), loss: 0.0021406393498182297\n",
      "train time for 2460 epochs, was 2034.3147811889648\n",
      "\n",
      "EPOCH 2462  (with max 8000), loss: 0.0007428363314829767\n",
      "train time for 2462 epochs, was 2035.94731259346\n",
      "\n",
      "EPOCH 2464  (with max 8000), loss: 0.01293916441500187\n",
      "train time for 2464 epochs, was 2037.5799820423126\n",
      "\n",
      "EPOCH 2466  (with max 8000), loss: 0.019177839159965515\n",
      "train time for 2466 epochs, was 2039.214680671692\n",
      "\n",
      "EPOCH 2468  (with max 8000), loss: 0.005911347921937704\n",
      "train time for 2468 epochs, was 2040.8472843170166\n",
      "\n",
      "EPOCH 2470  (with max 8000), loss: 0.006066036410629749\n",
      "train time for 2470 epochs, was 2042.488195180893\n",
      "\n",
      "EPOCH 2472  (with max 8000), loss: 0.005026876460760832\n",
      "train time for 2472 epochs, was 2044.1230092048645\n",
      "\n",
      "EPOCH 2474  (with max 8000), loss: 0.0023276605643332005\n",
      "train time for 2474 epochs, was 2045.7556698322296\n",
      "\n",
      "EPOCH 2476  (with max 8000), loss: 0.0020757513120770454\n",
      "train time for 2476 epochs, was 2047.3944771289825\n",
      "\n",
      "EPOCH 2478  (with max 8000), loss: 0.0007512874435633421\n",
      "train time for 2478 epochs, was 2049.0271689891815\n",
      "\n",
      "EPOCH 2480  (with max 8000), loss: 0.0021648553665727377\n",
      "train time for 2480 epochs, was 2050.6619522571564\n",
      "\n",
      "EPOCH 2482  (with max 8000), loss: 0.0006289525772444904\n",
      "train time for 2482 epochs, was 2052.2988154888153\n",
      "\n",
      "EPOCH 2484  (with max 8000), loss: 0.001698876265436411\n",
      "train time for 2484 epochs, was 2053.9314522743225\n",
      "\n",
      "EPOCH 2486  (with max 8000), loss: 0.0030855140648782253\n",
      "train time for 2486 epochs, was 2055.5640029907227\n",
      "\n",
      "EPOCH 2488  (with max 8000), loss: 0.0010675069643184543\n",
      "train time for 2488 epochs, was 2057.196615457535\n",
      "\n",
      "EPOCH 2490  (with max 8000), loss: 0.0014214364346116781\n",
      "train time for 2490 epochs, was 2058.8314368724823\n",
      "\n",
      "EPOCH 2492  (with max 8000), loss: 0.0033147463109344244\n",
      "train time for 2492 epochs, was 2060.4639995098114\n",
      "\n",
      "EPOCH 2494  (with max 8000), loss: 0.004501532297581434\n",
      "train time for 2494 epochs, was 2062.1008594036102\n",
      "\n",
      "EPOCH 2496  (with max 8000), loss: 0.0065201688557863235\n",
      "train time for 2496 epochs, was 2063.7334609031677\n",
      "\n",
      "EPOCH 2498  (with max 8000), loss: 0.0023165850434452295\n",
      "train time for 2498 epochs, was 2065.3660683631897\n",
      "\n",
      "EPOCH 2500  (with max 8000), loss: 0.002753514563664794\n",
      "train time for 2500 epochs, was 2066.9987003803253\n",
      "\n",
      "EPOCH 2502  (with max 8000), loss: 0.0029921401292085648\n",
      "train time for 2502 epochs, was 2068.6333224773407\n",
      "\n",
      "EPOCH 2504  (with max 8000), loss: 0.018901390954852104\n",
      "train time for 2504 epochs, was 2070.2680802345276\n",
      "\n",
      "EPOCH 2506  (with max 8000), loss: 0.10610463470220566\n",
      "train time for 2506 epochs, was 2071.900605916977\n",
      "\n",
      "EPOCH 2508  (with max 8000), loss: 0.007815456949174404\n",
      "train time for 2508 epochs, was 2073.5353376865387\n",
      "\n",
      "EPOCH 2510  (with max 8000), loss: 0.006906838621944189\n",
      "train time for 2510 epochs, was 2075.1678743362427\n",
      "\n",
      "EPOCH 2512  (with max 8000), loss: 0.005061423406004906\n",
      "train time for 2512 epochs, was 2076.8004932403564\n",
      "\n",
      "EPOCH 2514  (with max 8000), loss: 0.003630434162914753\n",
      "train time for 2514 epochs, was 2078.435111284256\n",
      "\n",
      "EPOCH 2516  (with max 8000), loss: 0.0011126045137643814\n",
      "train time for 2516 epochs, was 2080.0678672790527\n",
      "\n",
      "EPOCH 2518  (with max 8000), loss: 0.009987440891563892\n",
      "train time for 2518 epochs, was 2081.7004165649414\n",
      "\n",
      "EPOCH 2520  (with max 8000), loss: 0.007739080581814051\n",
      "train time for 2520 epochs, was 2083.3329215049744\n",
      "\n",
      "EPOCH 2522  (with max 8000), loss: 0.0031440029852092266\n",
      "train time for 2522 epochs, was 2084.9655318260193\n",
      "\n",
      "EPOCH 2524  (with max 8000), loss: 0.003453805111348629\n",
      "train time for 2524 epochs, was 2086.5982632637024\n",
      "\n",
      "EPOCH 2526  (with max 8000), loss: 0.0011831650044769049\n",
      "train time for 2526 epochs, was 2088.2643628120422\n",
      "\n",
      "EPOCH 2528  (with max 8000), loss: 0.0018751266179606318\n",
      "train time for 2528 epochs, was 2089.8971350193024\n",
      "\n",
      "EPOCH 2530  (with max 8000), loss: 0.009602620266377926\n",
      "train time for 2530 epochs, was 2091.5298430919647\n",
      "\n",
      "EPOCH 2532  (with max 8000), loss: 0.0016506004612892866\n",
      "train time for 2532 epochs, was 2093.1623923778534\n",
      "\n",
      "EPOCH 2534  (with max 8000), loss: 0.00489804707467556\n",
      "train time for 2534 epochs, was 2094.7950551509857\n",
      "\n",
      "EPOCH 2536  (with max 8000), loss: 0.0010333306854590774\n",
      "train time for 2536 epochs, was 2096.4339406490326\n",
      "\n",
      "EPOCH 2538  (with max 8000), loss: 0.0010079107014462352\n",
      "train time for 2538 epochs, was 2098.066548347473\n",
      "\n",
      "EPOCH 2540  (with max 8000), loss: 0.002653946168720722\n",
      "train time for 2540 epochs, was 2099.699158668518\n",
      "\n",
      "EPOCH 2542  (with max 8000), loss: 0.0027995186392217875\n",
      "train time for 2542 epochs, was 2101.3338673114777\n",
      "\n",
      "EPOCH 2544  (with max 8000), loss: 0.0030491952784359455\n",
      "train time for 2544 epochs, was 2102.9749252796173\n",
      "\n",
      "EPOCH 2546  (with max 8000), loss: 0.001608797232620418\n",
      "train time for 2546 epochs, was 2104.609578371048\n",
      "\n",
      "EPOCH 2548  (with max 8000), loss: 0.0024750272277742624\n",
      "train time for 2548 epochs, was 2106.2421181201935\n",
      "\n",
      "EPOCH 2550  (with max 8000), loss: 0.003603735938668251\n",
      "train time for 2550 epochs, was 2107.8746480941772\n",
      "\n",
      "EPOCH 2552  (with max 8000), loss: 0.0010558122303336859\n",
      "train time for 2552 epochs, was 2109.509454011917\n",
      "\n",
      "EPOCH 2554  (with max 8000), loss: 0.0025194534100592136\n",
      "train time for 2554 epochs, was 2111.1421687602997\n",
      "\n",
      "EPOCH 2556  (with max 8000), loss: 0.0020190938375890255\n",
      "train time for 2556 epochs, was 2112.7768194675446\n",
      "\n",
      "EPOCH 2558  (with max 8000), loss: 0.004256557207554579\n",
      "train time for 2558 epochs, was 2114.411543369293\n",
      "\n",
      "EPOCH 2560  (with max 8000), loss: 0.004909250885248184\n",
      "train time for 2560 epochs, was 2116.0443086624146\n",
      "\n",
      "EPOCH 2562  (with max 8000), loss: 0.005315551999956369\n",
      "train time for 2562 epochs, was 2117.676834821701\n",
      "\n",
      "EPOCH 2564  (with max 8000), loss: 0.002990753622725606\n",
      "train time for 2564 epochs, was 2119.309475660324\n",
      "\n",
      "EPOCH 2566  (with max 8000), loss: 0.008423722349107265\n",
      "train time for 2566 epochs, was 2120.9423217773438\n",
      "\n",
      "EPOCH 2568  (with max 8000), loss: 0.003701298264786601\n",
      "train time for 2568 epochs, was 2122.5769789218903\n",
      "\n",
      "EPOCH 2570  (with max 8000), loss: 0.003493294818326831\n",
      "train time for 2570 epochs, was 2124.2536239624023\n",
      "\n",
      "EPOCH 2572  (with max 8000), loss: 0.003049255581572652\n",
      "train time for 2572 epochs, was 2125.890380859375\n",
      "\n",
      "EPOCH 2574  (with max 8000), loss: 0.003663429291918874\n",
      "train time for 2574 epochs, was 2127.525217294693\n",
      "\n",
      "EPOCH 2576  (with max 8000), loss: 0.002544181188568473\n",
      "train time for 2576 epochs, was 2129.157869577408\n",
      "\n",
      "EPOCH 2578  (with max 8000), loss: 0.003257333766669035\n",
      "train time for 2578 epochs, was 2130.8010671138763\n",
      "\n",
      "EPOCH 2580  (with max 8000), loss: 0.0031013621482998133\n",
      "train time for 2580 epochs, was 2132.433682203293\n",
      "\n",
      "EPOCH 2582  (with max 8000), loss: 0.0014392237644642591\n",
      "train time for 2582 epochs, was 2134.068363904953\n",
      "\n",
      "EPOCH 2584  (with max 8000), loss: 0.0013310270151123405\n",
      "train time for 2584 epochs, was 2135.7009036540985\n",
      "\n",
      "EPOCH 2586  (with max 8000), loss: 0.0006604080554097891\n",
      "train time for 2586 epochs, was 2137.33358836174\n",
      "\n",
      "EPOCH 2588  (with max 8000), loss: 0.002077833516523242\n",
      "train time for 2588 epochs, was 2138.966230869293\n",
      "\n",
      "EPOCH 2590  (with max 8000), loss: 0.003008520230650902\n",
      "train time for 2590 epochs, was 2140.600788831711\n",
      "\n",
      "EPOCH 2592  (with max 8000), loss: 0.005895490292459726\n",
      "train time for 2592 epochs, was 2142.233377933502\n",
      "\n",
      "EPOCH 2594  (with max 8000), loss: 0.0028083103243261576\n",
      "train time for 2594 epochs, was 2143.866020679474\n",
      "\n",
      "EPOCH 2596  (with max 8000), loss: 0.1602053940296173\n",
      "train time for 2596 epochs, was 2145.504889011383\n",
      "\n",
      "EPOCH 2598  (with max 8000), loss: 0.013523033820092678\n",
      "train time for 2598 epochs, was 2147.137467622757\n",
      "\n",
      "EPOCH 2600  (with max 8000), loss: 0.010116188786923885\n",
      "train time for 2600 epochs, was 2148.7721943855286\n",
      "\n",
      "EPOCH 2600 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_2600.pth\n",
      "\n",
      "EPOCH 2602  (with max 8000), loss: 0.004385944921523333\n",
      "train time for 2602 epochs, was 2150.442690372467\n",
      "\n",
      "EPOCH 2604  (with max 8000), loss: 0.0017448593862354755\n",
      "train time for 2604 epochs, was 2152.0774385929108\n",
      "\n",
      "EPOCH 2606  (with max 8000), loss: 0.0015478964196518064\n",
      "train time for 2606 epochs, was 2153.7099874019623\n",
      "\n",
      "EPOCH 2608  (with max 8000), loss: 0.0029254232067614794\n",
      "train time for 2608 epochs, was 2155.3488240242004\n",
      "\n",
      "EPOCH 2610  (with max 8000), loss: 0.0037436308339238167\n",
      "train time for 2610 epochs, was 2156.981325149536\n",
      "\n",
      "EPOCH 2612  (with max 8000), loss: 0.0015179092297330499\n",
      "train time for 2612 epochs, was 2158.615880012512\n",
      "\n",
      "EPOCH 2614  (with max 8000), loss: 0.0017244378104805946\n",
      "train time for 2614 epochs, was 2160.248548746109\n",
      "\n",
      "EPOCH 2616  (with max 8000), loss: 0.007608856074512005\n",
      "train time for 2616 epochs, was 2161.889494895935\n",
      "\n",
      "EPOCH 2618  (with max 8000), loss: 0.0017210287041962147\n",
      "train time for 2618 epochs, was 2163.524104118347\n",
      "\n",
      "EPOCH 2620  (with max 8000), loss: 0.0027719868812710047\n",
      "train time for 2620 epochs, was 2165.1566882133484\n",
      "\n",
      "EPOCH 2622  (with max 8000), loss: 0.001181594911031425\n",
      "train time for 2622 epochs, was 2166.789237499237\n",
      "\n",
      "EPOCH 2624  (with max 8000), loss: 0.0033115234691649675\n",
      "train time for 2624 epochs, was 2168.4217047691345\n",
      "\n",
      "EPOCH 2626  (with max 8000), loss: 0.006053544115275145\n",
      "train time for 2626 epochs, was 2170.05411028862\n",
      "\n",
      "EPOCH 2628  (with max 8000), loss: 3.21834122587461e-05\n",
      "train time for 2628 epochs, was 2171.686626434326\n",
      "\n",
      "EPOCH 2630  (with max 8000), loss: 0.0012370538897812366\n",
      "train time for 2630 epochs, was 2173.3192751407623\n",
      "\n",
      "EPOCH 2632  (with max 8000), loss: 0.0008631587261334062\n",
      "train time for 2632 epochs, was 2174.953994512558\n",
      "\n",
      "EPOCH 2634  (with max 8000), loss: 0.0029168028850108385\n",
      "train time for 2634 epochs, was 2176.588627099991\n",
      "\n",
      "EPOCH 2636  (with max 8000), loss: 0.0024535362608730793\n",
      "train time for 2636 epochs, was 2178.2213406562805\n",
      "\n",
      "EPOCH 2638  (with max 8000), loss: 0.0026347842067480087\n",
      "train time for 2638 epochs, was 2179.8560450077057\n",
      "\n",
      "EPOCH 2640  (with max 8000), loss: 0.0022263231221586466\n",
      "train time for 2640 epochs, was 2181.4908862113953\n",
      "\n",
      "EPOCH 2642  (with max 8000), loss: 0.012149067595601082\n",
      "train time for 2642 epochs, was 2183.123480319977\n",
      "\n",
      "EPOCH 2644  (with max 8000), loss: 0.00569096440449357\n",
      "train time for 2644 epochs, was 2184.7582533359528\n",
      "\n",
      "EPOCH 2646  (with max 8000), loss: 0.022301839664578438\n",
      "train time for 2646 epochs, was 2186.3907232284546\n",
      "\n",
      "EPOCH 2648  (with max 8000), loss: 0.013230443932116032\n",
      "train time for 2648 epochs, was 2188.0234191417694\n",
      "\n",
      "EPOCH 2650  (with max 8000), loss: 0.0022773491218686104\n",
      "train time for 2650 epochs, was 2189.6558849811554\n",
      "\n",
      "EPOCH 2652  (with max 8000), loss: 0.0021841172128915787\n",
      "train time for 2652 epochs, was 2191.2884023189545\n",
      "\n",
      "EPOCH 2654  (with max 8000), loss: 0.0011743094073608518\n",
      "train time for 2654 epochs, was 2192.920941591263\n",
      "\n",
      "EPOCH 2656  (with max 8000), loss: 0.0022947064135223627\n",
      "train time for 2656 epochs, was 2194.555715084076\n",
      "\n",
      "EPOCH 2658  (with max 8000), loss: 0.0011444761184975505\n",
      "train time for 2658 epochs, was 2196.188396215439\n",
      "\n",
      "EPOCH 2660  (with max 8000), loss: 0.0033582053147256374\n",
      "train time for 2660 epochs, was 2197.8523020744324\n",
      "\n",
      "EPOCH 2662  (with max 8000), loss: 0.0029694063123315573\n",
      "train time for 2662 epochs, was 2199.4869356155396\n",
      "\n",
      "EPOCH 2664  (with max 8000), loss: 0.0015555319841951132\n",
      "train time for 2664 epochs, was 2201.121574640274\n",
      "\n",
      "EPOCH 2666  (with max 8000), loss: 0.0015342357801273465\n",
      "train time for 2666 epochs, was 2202.754269838333\n",
      "\n",
      "EPOCH 2668  (with max 8000), loss: 0.0036763909738510847\n",
      "train time for 2668 epochs, was 2204.386761188507\n",
      "\n",
      "EPOCH 2670  (with max 8000), loss: 0.0012817131355404854\n",
      "train time for 2670 epochs, was 2206.0234830379486\n",
      "\n",
      "EPOCH 2672  (with max 8000), loss: 0.023023433983325958\n",
      "train time for 2672 epochs, was 2207.655993938446\n",
      "\n",
      "EPOCH 2674  (with max 8000), loss: 0.03438204899430275\n",
      "train time for 2674 epochs, was 2209.289740562439\n",
      "\n",
      "EPOCH 2676  (with max 8000), loss: 0.00656162342056632\n",
      "train time for 2676 epochs, was 2210.92232131958\n",
      "\n",
      "EPOCH 2678  (with max 8000), loss: 0.003824125276878476\n",
      "train time for 2678 epochs, was 2212.556988954544\n",
      "\n",
      "EPOCH 2680  (with max 8000), loss: 0.0013114622561261058\n",
      "train time for 2680 epochs, was 2214.189513206482\n",
      "\n",
      "EPOCH 2682  (with max 8000), loss: 0.002723388373851776\n",
      "train time for 2682 epochs, was 2215.822009563446\n",
      "\n",
      "EPOCH 2684  (with max 8000), loss: 0.0008399449288845062\n",
      "train time for 2684 epochs, was 2217.454876422882\n",
      "\n",
      "EPOCH 2686  (with max 8000), loss: 0.002354549476876855\n",
      "train time for 2686 epochs, was 2219.087489128113\n",
      "\n",
      "EPOCH 2688  (with max 8000), loss: 0.0032017200719565153\n",
      "train time for 2688 epochs, was 2220.7200140953064\n",
      "\n",
      "EPOCH 2690  (with max 8000), loss: 0.0030330989975482225\n",
      "train time for 2690 epochs, was 2222.3524849414825\n",
      "\n",
      "EPOCH 2692  (with max 8000), loss: 0.0014955896185711026\n",
      "train time for 2692 epochs, was 2223.9851257801056\n",
      "\n",
      "EPOCH 2694  (with max 8000), loss: 0.0008777491166256368\n",
      "train time for 2694 epochs, was 2225.617664337158\n",
      "\n",
      "EPOCH 2696  (with max 8000), loss: 0.006162930279970169\n",
      "train time for 2696 epochs, was 2227.25230884552\n",
      "\n",
      "EPOCH 2698  (with max 8000), loss: 0.04063705727458\n",
      "train time for 2698 epochs, was 2228.8847692012787\n",
      "\n",
      "EPOCH 2700  (with max 8000), loss: 0.024202508851885796\n",
      "train time for 2700 epochs, was 2230.5174083709717\n",
      "\n",
      "EPOCH 2702  (with max 8000), loss: 0.09380392730236053\n",
      "train time for 2702 epochs, was 2232.1500840187073\n",
      "\n",
      "EPOCH 2704  (with max 8000), loss: 0.010454865172505379\n",
      "train time for 2704 epochs, was 2233.788897752762\n",
      "\n",
      "EPOCH 2706  (with max 8000), loss: 0.01131388545036316\n",
      "train time for 2706 epochs, was 2235.4236676692963\n",
      "\n",
      "EPOCH 2708  (with max 8000), loss: 0.005421430338174105\n",
      "train time for 2708 epochs, was 2237.056341648102\n",
      "\n",
      "EPOCH 2710  (with max 8000), loss: 0.007981318980455399\n",
      "train time for 2710 epochs, was 2238.6889700889587\n",
      "\n",
      "EPOCH 2712  (with max 8000), loss: 0.010346464812755585\n",
      "train time for 2712 epochs, was 2240.3236298561096\n",
      "\n",
      "EPOCH 2714  (with max 8000), loss: 0.021158447489142418\n",
      "train time for 2714 epochs, was 2241.956082344055\n",
      "\n",
      "EPOCH 2716  (with max 8000), loss: 0.0009801621781662107\n",
      "train time for 2716 epochs, was 2243.5885603427887\n",
      "\n",
      "EPOCH 2718  (with max 8000), loss: 0.0014328203396871686\n",
      "train time for 2718 epochs, was 2245.221211671829\n",
      "\n",
      "EPOCH 2720  (with max 8000), loss: 0.012040089815855026\n",
      "train time for 2720 epochs, was 2246.8537471294403\n",
      "\n",
      "EPOCH 2722  (with max 8000), loss: 0.004375350195914507\n",
      "train time for 2722 epochs, was 2248.4862451553345\n",
      "\n",
      "EPOCH 2724  (with max 8000), loss: 0.0023408127017319202\n",
      "train time for 2724 epochs, was 2250.1188390254974\n",
      "\n",
      "EPOCH 2726  (with max 8000), loss: 0.005257402081042528\n",
      "train time for 2726 epochs, was 2251.7513275146484\n",
      "\n",
      "EPOCH 2728  (with max 8000), loss: 0.0010545440018177032\n",
      "train time for 2728 epochs, was 2253.3838918209076\n",
      "\n",
      "EPOCH 2730  (with max 8000), loss: 0.0017899397062137723\n",
      "train time for 2730 epochs, was 2255.0163400173187\n",
      "\n",
      "EPOCH 2732  (with max 8000), loss: 0.0029337068554013968\n",
      "train time for 2732 epochs, was 2256.6488647460938\n",
      "\n",
      "EPOCH 2734  (with max 8000), loss: 0.012056701816618443\n",
      "train time for 2734 epochs, was 2258.2814071178436\n",
      "\n",
      "EPOCH 2736  (with max 8000), loss: 0.002288387855514884\n",
      "train time for 2736 epochs, was 2259.9143176078796\n",
      "\n",
      "EPOCH 2738  (with max 8000), loss: 0.008196018636226654\n",
      "train time for 2738 epochs, was 2261.5467171669006\n",
      "\n",
      "EPOCH 2740  (with max 8000), loss: 0.005000809207558632\n",
      "train time for 2740 epochs, was 2263.1790976524353\n",
      "\n",
      "EPOCH 2742  (with max 8000), loss: 0.002306753769516945\n",
      "train time for 2742 epochs, was 2264.8136904239655\n",
      "\n",
      "EPOCH 2744  (with max 8000), loss: 0.006694269832223654\n",
      "train time for 2744 epochs, was 2266.446267604828\n",
      "\n",
      "EPOCH 2746  (with max 8000), loss: 0.0003990186960436404\n",
      "train time for 2746 epochs, was 2268.0809025764465\n",
      "\n",
      "EPOCH 2748  (with max 8000), loss: 0.0011087011080235243\n",
      "train time for 2748 epochs, was 2269.714034318924\n",
      "\n",
      "EPOCH 2750  (with max 8000), loss: 0.0017456497298553586\n",
      "train time for 2750 epochs, was 2271.385936021805\n",
      "\n",
      "EPOCH 2752  (with max 8000), loss: 0.0016996378544718027\n",
      "train time for 2752 epochs, was 2273.0187106132507\n",
      "\n",
      "EPOCH 2754  (with max 8000), loss: 0.000767278193961829\n",
      "train time for 2754 epochs, was 2274.6516485214233\n",
      "\n",
      "EPOCH 2756  (with max 8000), loss: 0.002374842995777726\n",
      "train time for 2756 epochs, was 2276.2841958999634\n",
      "\n",
      "EPOCH 2758  (with max 8000), loss: 0.002434945199638605\n",
      "train time for 2758 epochs, was 2277.9167211055756\n",
      "\n",
      "EPOCH 2760  (with max 8000), loss: 0.003902339842170477\n",
      "train time for 2760 epochs, was 2279.54931139946\n",
      "\n",
      "EPOCH 2762  (with max 8000), loss: 0.0023604510352015495\n",
      "train time for 2762 epochs, was 2281.182055711746\n",
      "\n",
      "EPOCH 2764  (with max 8000), loss: 0.0030483100563287735\n",
      "train time for 2764 epochs, was 2282.8146176338196\n",
      "\n",
      "EPOCH 2766  (with max 8000), loss: 0.0013152670580893755\n",
      "train time for 2766 epochs, was 2284.447209596634\n",
      "\n",
      "EPOCH 2768  (with max 8000), loss: 0.011383569799363613\n",
      "train time for 2768 epochs, was 2286.079685688019\n",
      "\n",
      "EPOCH 2770  (with max 8000), loss: 0.0018232448492199183\n",
      "train time for 2770 epochs, was 2287.7121505737305\n",
      "\n",
      "EPOCH 2772  (with max 8000), loss: 0.0016248524188995361\n",
      "train time for 2772 epochs, was 2289.3447782993317\n",
      "\n",
      "EPOCH 2774  (with max 8000), loss: 0.009927636943757534\n",
      "train time for 2774 epochs, was 2290.977531671524\n",
      "\n",
      "EPOCH 2776  (with max 8000), loss: 0.0019142607925459743\n",
      "train time for 2776 epochs, was 2292.6123127937317\n",
      "\n",
      "EPOCH 2778  (with max 8000), loss: 0.020086435601115227\n",
      "train time for 2778 epochs, was 2294.2447879314423\n",
      "\n",
      "EPOCH 2780  (with max 8000), loss: 0.0036688654217869043\n",
      "train time for 2780 epochs, was 2295.877452611923\n",
      "\n",
      "EPOCH 2782  (with max 8000), loss: 0.0014111626660451293\n",
      "train time for 2782 epochs, was 2297.5100576877594\n",
      "\n",
      "EPOCH 2784  (with max 8000), loss: 0.03850499540567398\n",
      "train time for 2784 epochs, was 2299.142693758011\n",
      "\n",
      "EPOCH 2786  (with max 8000), loss: 0.014191685244441032\n",
      "train time for 2786 epochs, was 2300.775280714035\n",
      "\n",
      "EPOCH 2788  (with max 8000), loss: 0.005383139941841364\n",
      "train time for 2788 epochs, was 2302.4079999923706\n",
      "\n",
      "EPOCH 2790  (with max 8000), loss: 0.006889136042445898\n",
      "train time for 2790 epochs, was 2304.0405564308167\n",
      "\n",
      "EPOCH 2792  (with max 8000), loss: 0.008015322498977184\n",
      "train time for 2792 epochs, was 2305.6729826927185\n",
      "\n",
      "EPOCH 2794  (with max 8000), loss: 0.0035301819443702698\n",
      "train time for 2794 epochs, was 2307.307625055313\n",
      "\n",
      "EPOCH 2796  (with max 8000), loss: 0.0025369422510266304\n",
      "train time for 2796 epochs, was 2308.940033197403\n",
      "\n",
      "EPOCH 2798  (with max 8000), loss: 0.0012447054032236338\n",
      "train time for 2798 epochs, was 2310.578807592392\n",
      "\n",
      "EPOCH 2800  (with max 8000), loss: 0.0020888724830001593\n",
      "train time for 2800 epochs, was 2312.211202144623\n",
      "\n",
      "EPOCH 2800 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_2800.pth\n",
      "\n",
      "EPOCH 2802  (with max 8000), loss: 0.00461936928331852\n",
      "train time for 2802 epochs, was 2313.8794305324554\n",
      "\n",
      "EPOCH 2804  (with max 8000), loss: 0.004605825990438461\n",
      "train time for 2804 epochs, was 2315.51407122612\n",
      "\n",
      "EPOCH 2806  (with max 8000), loss: 0.0054548694752156734\n",
      "train time for 2806 epochs, was 2317.1528759002686\n",
      "\n",
      "EPOCH 2808  (with max 8000), loss: 0.0029541889671236277\n",
      "train time for 2808 epochs, was 2318.785374879837\n",
      "\n",
      "EPOCH 2810  (with max 8000), loss: 0.0019468640675768256\n",
      "train time for 2810 epochs, was 2320.417865753174\n",
      "\n",
      "EPOCH 2812  (with max 8000), loss: 0.0015179384499788284\n",
      "train time for 2812 epochs, was 2322.050303697586\n",
      "\n",
      "EPOCH 2814  (with max 8000), loss: 0.0017510493053123355\n",
      "train time for 2814 epochs, was 2323.682934999466\n",
      "\n",
      "EPOCH 2816  (with max 8000), loss: 0.011033477261662483\n",
      "train time for 2816 epochs, was 2325.3174753189087\n",
      "\n",
      "EPOCH 2818  (with max 8000), loss: 0.0021069992799311876\n",
      "train time for 2818 epochs, was 2326.9646379947662\n",
      "\n",
      "EPOCH 2820  (with max 8000), loss: 0.0046261087991297245\n",
      "train time for 2820 epochs, was 2328.5993127822876\n",
      "\n",
      "EPOCH 2822  (with max 8000), loss: 0.014135731384158134\n",
      "train time for 2822 epochs, was 2330.2361254692078\n",
      "\n",
      "EPOCH 2824  (with max 8000), loss: 0.002397390780970454\n",
      "train time for 2824 epochs, was 2331.868694782257\n",
      "\n",
      "EPOCH 2826  (with max 8000), loss: 0.001516159507445991\n",
      "train time for 2826 epochs, was 2333.5011422634125\n",
      "\n",
      "EPOCH 2828  (with max 8000), loss: 0.001881412579677999\n",
      "train time for 2828 epochs, was 2335.1336488723755\n",
      "\n",
      "EPOCH 2830  (with max 8000), loss: 0.009314153343439102\n",
      "train time for 2830 epochs, was 2336.7662160396576\n",
      "\n",
      "EPOCH 2832  (with max 8000), loss: 0.003608043771237135\n",
      "train time for 2832 epochs, was 2338.3989675045013\n",
      "\n",
      "EPOCH 2834  (with max 8000), loss: 0.001788018154911697\n",
      "train time for 2834 epochs, was 2340.0314540863037\n",
      "\n",
      "EPOCH 2836  (with max 8000), loss: 0.0017006811685860157\n",
      "train time for 2836 epochs, was 2341.6638922691345\n",
      "\n",
      "EPOCH 2838  (with max 8000), loss: 0.0012207981199026108\n",
      "train time for 2838 epochs, was 2343.3172516822815\n",
      "\n",
      "EPOCH 2840  (with max 8000), loss: 0.0013310237554833293\n",
      "train time for 2840 epochs, was 2344.949775457382\n",
      "\n",
      "EPOCH 2842  (with max 8000), loss: 0.0013795442646369338\n",
      "train time for 2842 epochs, was 2346.582575082779\n",
      "\n",
      "EPOCH 2844  (with max 8000), loss: 0.0046679917722940445\n",
      "train time for 2844 epochs, was 2348.215156555176\n",
      "\n",
      "EPOCH 2846  (with max 8000), loss: 0.004463381599634886\n",
      "train time for 2846 epochs, was 2349.8497598171234\n",
      "\n",
      "EPOCH 2848  (with max 8000), loss: 0.01292876061052084\n",
      "train time for 2848 epochs, was 2351.4822216033936\n",
      "\n",
      "EPOCH 2850  (with max 8000), loss: 0.03230058401823044\n",
      "train time for 2850 epochs, was 2353.114904642105\n",
      "\n",
      "EPOCH 2852  (with max 8000), loss: 0.004098476842045784\n",
      "train time for 2852 epochs, was 2354.747298002243\n",
      "\n",
      "EPOCH 2854  (with max 8000), loss: 0.00657670060172677\n",
      "train time for 2854 epochs, was 2356.3797051906586\n",
      "\n",
      "EPOCH 2856  (with max 8000), loss: 0.060201194137334824\n",
      "train time for 2856 epochs, was 2358.0184881687164\n",
      "\n",
      "EPOCH 2858  (with max 8000), loss: 0.013659816235303879\n",
      "train time for 2858 epochs, was 2359.6510882377625\n",
      "\n",
      "EPOCH 2860  (with max 8000), loss: 0.01466463040560484\n",
      "train time for 2860 epochs, was 2361.2835261821747\n",
      "\n",
      "EPOCH 2862  (with max 8000), loss: 0.008744748309254646\n",
      "train time for 2862 epochs, was 2362.916096687317\n",
      "\n",
      "EPOCH 2864  (with max 8000), loss: 0.0045347148552536964\n",
      "train time for 2864 epochs, was 2364.550704240799\n",
      "\n",
      "EPOCH 2866  (with max 8000), loss: 0.0030149531085044146\n",
      "train time for 2866 epochs, was 2366.1853737831116\n",
      "\n",
      "EPOCH 2868  (with max 8000), loss: 0.004014994483441114\n",
      "train time for 2868 epochs, was 2367.8222646713257\n",
      "\n",
      "EPOCH 2870  (with max 8000), loss: 0.002877013059332967\n",
      "train time for 2870 epochs, was 2369.4547600746155\n",
      "\n",
      "EPOCH 2872  (with max 8000), loss: 0.00177659559994936\n",
      "train time for 2872 epochs, was 2371.087315559387\n",
      "\n",
      "EPOCH 2874  (with max 8000), loss: 0.0020705764181911945\n",
      "train time for 2874 epochs, was 2372.719886302948\n",
      "\n",
      "EPOCH 2876  (with max 8000), loss: 0.0012984347995370626\n",
      "train time for 2876 epochs, was 2374.3526492118835\n",
      "\n",
      "EPOCH 2878  (with max 8000), loss: 0.003239430021494627\n",
      "train time for 2878 epochs, was 2375.9851620197296\n",
      "\n",
      "EPOCH 2880  (with max 8000), loss: 0.0017489545280113816\n",
      "train time for 2880 epochs, was 2377.623997926712\n",
      "\n",
      "EPOCH 2882  (with max 8000), loss: 0.0015987881924957037\n",
      "train time for 2882 epochs, was 2379.271201133728\n",
      "\n",
      "EPOCH 2884  (with max 8000), loss: 0.002952172886580229\n",
      "train time for 2884 epochs, was 2380.903733730316\n",
      "\n",
      "EPOCH 2886  (with max 8000), loss: 0.0004680745187215507\n",
      "train time for 2886 epochs, was 2382.5385241508484\n",
      "\n",
      "EPOCH 2888  (with max 8000), loss: 0.001227891887538135\n",
      "train time for 2888 epochs, was 2384.171005487442\n",
      "\n",
      "EPOCH 2890  (with max 8000), loss: 0.002188220852985978\n",
      "train time for 2890 epochs, was 2385.803504228592\n",
      "\n",
      "EPOCH 2892  (with max 8000), loss: 0.001087347511202097\n",
      "train time for 2892 epochs, was 2387.4362914562225\n",
      "\n",
      "EPOCH 2894  (with max 8000), loss: 0.0031670918688178062\n",
      "train time for 2894 epochs, was 2389.0691137313843\n",
      "\n",
      "EPOCH 2896  (with max 8000), loss: 0.005449399817734957\n",
      "train time for 2896 epochs, was 2390.7015511989594\n",
      "\n",
      "EPOCH 2898  (with max 8000), loss: 0.00036064974847249687\n",
      "train time for 2898 epochs, was 2392.3340866565704\n",
      "\n",
      "EPOCH 2900  (with max 8000), loss: 0.0007627480663359165\n",
      "train time for 2900 epochs, was 2393.968726158142\n",
      "\n",
      "EPOCH 2902  (with max 8000), loss: 0.0010125841945409775\n",
      "train time for 2902 epochs, was 2395.6013209819794\n",
      "\n",
      "EPOCH 2904  (with max 8000), loss: 0.002865066286176443\n",
      "train time for 2904 epochs, was 2397.2338738441467\n",
      "\n",
      "EPOCH 2906  (with max 8000), loss: 0.003914377186447382\n",
      "train time for 2906 epochs, was 2398.8663375377655\n",
      "\n",
      "EPOCH 2908  (with max 8000), loss: 0.003119360189884901\n",
      "train time for 2908 epochs, was 2400.5491905212402\n",
      "\n",
      "EPOCH 2910  (with max 8000), loss: 0.0025388712529093027\n",
      "train time for 2910 epochs, was 2402.181665420532\n",
      "\n",
      "EPOCH 2912  (with max 8000), loss: 0.0023961905390024185\n",
      "train time for 2912 epochs, was 2403.81423330307\n",
      "\n",
      "EPOCH 2914  (with max 8000), loss: 0.0014354471350088716\n",
      "train time for 2914 epochs, was 2405.4467027187347\n",
      "\n",
      "EPOCH 2916  (with max 8000), loss: 0.002895592711865902\n",
      "train time for 2916 epochs, was 2407.0811252593994\n",
      "\n",
      "EPOCH 2918  (with max 8000), loss: 0.003830122761428356\n",
      "train time for 2918 epochs, was 2408.7135479450226\n",
      "\n",
      "EPOCH 2920  (with max 8000), loss: 0.002848814008757472\n",
      "train time for 2920 epochs, was 2410.3463122844696\n",
      "\n",
      "EPOCH 2922  (with max 8000), loss: 0.0052018677815794945\n",
      "train time for 2922 epochs, was 2411.9787170886993\n",
      "\n",
      "EPOCH 2924  (with max 8000), loss: 0.007276310585439205\n",
      "train time for 2924 epochs, was 2413.611256122589\n",
      "\n",
      "EPOCH 2926  (with max 8000), loss: 0.0023879418149590492\n",
      "train time for 2926 epochs, was 2415.260599374771\n",
      "\n",
      "EPOCH 2928  (with max 8000), loss: 0.003273126669228077\n",
      "train time for 2928 epochs, was 2416.8954224586487\n",
      "\n",
      "EPOCH 2930  (with max 8000), loss: 0.026085898280143738\n",
      "train time for 2930 epochs, was 2418.5279421806335\n",
      "\n",
      "EPOCH 2932  (with max 8000), loss: 0.09400542825460434\n",
      "train time for 2932 epochs, was 2420.1603705883026\n",
      "\n",
      "EPOCH 2934  (with max 8000), loss: 0.007051046472042799\n",
      "train time for 2934 epochs, was 2421.7949476242065\n",
      "\n",
      "EPOCH 2936  (with max 8000), loss: 0.011911353096365929\n",
      "train time for 2936 epochs, was 2423.4274094104767\n",
      "\n",
      "EPOCH 2938  (with max 8000), loss: 0.0016649265307933092\n",
      "train time for 2938 epochs, was 2425.0601518154144\n",
      "\n",
      "EPOCH 2940  (with max 8000), loss: 0.002577743958681822\n",
      "train time for 2940 epochs, was 2426.692712545395\n",
      "\n",
      "EPOCH 2942  (with max 8000), loss: 0.002720187185332179\n",
      "train time for 2942 epochs, was 2428.325371980667\n",
      "\n",
      "EPOCH 2944  (with max 8000), loss: 0.002552647143602371\n",
      "train time for 2944 epochs, was 2429.9580569267273\n",
      "\n",
      "EPOCH 2946  (with max 8000), loss: 0.00648139463737607\n",
      "train time for 2946 epochs, was 2431.5908432006836\n",
      "\n",
      "EPOCH 2948  (with max 8000), loss: 0.0017707571387290955\n",
      "train time for 2948 epochs, was 2433.2254226207733\n",
      "\n",
      "EPOCH 2950  (with max 8000), loss: 0.0028420891612768173\n",
      "train time for 2950 epochs, was 2434.8580338954926\n",
      "\n",
      "EPOCH 2952  (with max 8000), loss: 0.0034001823514699936\n",
      "train time for 2952 epochs, was 2436.490667819977\n",
      "\n",
      "EPOCH 2954  (with max 8000), loss: 0.004145363811403513\n",
      "train time for 2954 epochs, was 2438.1231184005737\n",
      "\n",
      "EPOCH 2956  (with max 8000), loss: 0.0034250367898494005\n",
      "train time for 2956 epochs, was 2439.7579231262207\n",
      "\n",
      "EPOCH 2958  (with max 8000), loss: 0.006966148968786001\n",
      "train time for 2958 epochs, was 2441.396692752838\n",
      "\n",
      "EPOCH 2960  (with max 8000), loss: 0.00138166977558285\n",
      "train time for 2960 epochs, was 2443.0292026996613\n",
      "\n",
      "EPOCH 2962  (with max 8000), loss: 0.001065482385456562\n",
      "train time for 2962 epochs, was 2444.665913581848\n",
      "\n",
      "EPOCH 2964  (with max 8000), loss: 0.006791220512241125\n",
      "train time for 2964 epochs, was 2446.298702955246\n",
      "\n",
      "EPOCH 2966  (with max 8000), loss: 0.001773184398189187\n",
      "train time for 2966 epochs, was 2447.9312465190887\n",
      "\n",
      "EPOCH 2968  (with max 8000), loss: 0.0009478815481998026\n",
      "train time for 2968 epochs, was 2449.563801765442\n",
      "\n",
      "EPOCH 2970  (with max 8000), loss: 0.0015436535468325019\n",
      "train time for 2970 epochs, was 2451.206831932068\n",
      "\n",
      "EPOCH 2972  (with max 8000), loss: 0.001049707760103047\n",
      "train time for 2972 epochs, was 2452.8394672870636\n",
      "\n",
      "EPOCH 2974  (with max 8000), loss: 0.003539247903972864\n",
      "train time for 2974 epochs, was 2454.4802889823914\n",
      "\n",
      "EPOCH 2976  (with max 8000), loss: 0.009440714493393898\n",
      "train time for 2976 epochs, was 2456.1127948760986\n",
      "\n",
      "EPOCH 2978  (with max 8000), loss: 0.0018240377539768815\n",
      "train time for 2978 epochs, was 2457.7473669052124\n",
      "\n",
      "EPOCH 2980  (with max 8000), loss: 0.0032954614143818617\n",
      "train time for 2980 epochs, was 2459.3797953128815\n",
      "\n",
      "EPOCH 2982  (with max 8000), loss: 0.005041761789470911\n",
      "train time for 2982 epochs, was 2461.012370824814\n",
      "\n",
      "EPOCH 2984  (with max 8000), loss: 0.004115677904337645\n",
      "train time for 2984 epochs, was 2462.646931409836\n",
      "\n",
      "EPOCH 2986  (with max 8000), loss: 0.002574328100308776\n",
      "train time for 2986 epochs, was 2464.279454231262\n",
      "\n",
      "EPOCH 2988  (with max 8000), loss: 0.5051150918006897\n",
      "train time for 2988 epochs, was 2465.911908388138\n",
      "\n",
      "EPOCH 2990  (with max 8000), loss: 0.012757145799696445\n",
      "train time for 2990 epochs, was 2467.544657468796\n",
      "\n",
      "EPOCH 2992  (with max 8000), loss: 0.010844413191080093\n",
      "train time for 2992 epochs, was 2469.177066087723\n",
      "\n",
      "EPOCH 2994  (with max 8000), loss: 0.0075682951137423515\n",
      "train time for 2994 epochs, was 2470.8095660209656\n",
      "\n",
      "EPOCH 2996  (with max 8000), loss: 0.008070103824138641\n",
      "train time for 2996 epochs, was 2472.444277524948\n",
      "\n",
      "EPOCH 2998  (with max 8000), loss: 0.00873926468193531\n",
      "train time for 2998 epochs, was 2474.076853990555\n",
      "\n",
      "EPOCH 3000  (with max 8000), loss: 0.00965531263500452\n",
      "train time for 3000 epochs, was 2475.7116684913635\n",
      "\n",
      "EPOCH 3000 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_3000.pth\n",
      "\n",
      "EPOCH 3002  (with max 8000), loss: 0.004418535623699427\n",
      "train time for 3002 epochs, was 2477.3800258636475\n",
      "\n",
      "EPOCH 3004  (with max 8000), loss: 0.0017902220133692026\n",
      "train time for 3004 epochs, was 2479.012774705887\n",
      "\n",
      "EPOCH 3006  (with max 8000), loss: 0.005804434884339571\n",
      "train time for 3006 epochs, was 2480.6455063819885\n",
      "\n",
      "EPOCH 3008  (with max 8000), loss: 0.0013460932532325387\n",
      "train time for 3008 epochs, was 2482.2784049510956\n",
      "\n",
      "EPOCH 3010  (with max 8000), loss: 0.004980102647095919\n",
      "train time for 3010 epochs, was 2483.9111614227295\n",
      "\n",
      "EPOCH 3012  (with max 8000), loss: 0.006320335902273655\n",
      "train time for 3012 epochs, was 2485.5458476543427\n",
      "\n",
      "EPOCH 3014  (with max 8000), loss: 0.0025662919506430626\n",
      "train time for 3014 epochs, was 2487.180764913559\n",
      "\n",
      "EPOCH 3016  (with max 8000), loss: 0.002041818108409643\n",
      "train time for 3016 epochs, was 2488.8261580467224\n",
      "\n",
      "EPOCH 3018  (with max 8000), loss: 0.004549821373075247\n",
      "train time for 3018 epochs, was 2490.4589047431946\n",
      "\n",
      "EPOCH 3020  (with max 8000), loss: 0.0021379892714321613\n",
      "train time for 3020 epochs, was 2492.1022839546204\n",
      "\n",
      "EPOCH 3022  (with max 8000), loss: 0.0009246785193681717\n",
      "train time for 3022 epochs, was 2493.737005710602\n",
      "\n",
      "EPOCH 3024  (with max 8000), loss: 0.0011804220266640186\n",
      "train time for 3024 epochs, was 2495.3718631267548\n",
      "\n",
      "EPOCH 3026  (with max 8000), loss: 0.004799877293407917\n",
      "train time for 3026 epochs, was 2497.004526615143\n",
      "\n",
      "EPOCH 3028  (with max 8000), loss: 0.0035725408233702183\n",
      "train time for 3028 epochs, was 2498.6370301246643\n",
      "\n",
      "EPOCH 3030  (with max 8000), loss: 0.0031215413473546505\n",
      "train time for 3030 epochs, was 2500.269517660141\n",
      "\n",
      "EPOCH 3032  (with max 8000), loss: 0.001943620853126049\n",
      "train time for 3032 epochs, was 2501.902142047882\n",
      "\n",
      "EPOCH 3034  (with max 8000), loss: 0.003548314329236746\n",
      "train time for 3034 epochs, was 2503.5367641448975\n",
      "\n",
      "EPOCH 3036  (with max 8000), loss: 0.004607039969414473\n",
      "train time for 3036 epochs, was 2505.1693415641785\n",
      "\n",
      "EPOCH 3038  (with max 8000), loss: 0.004750087857246399\n",
      "train time for 3038 epochs, was 2506.802095413208\n",
      "\n",
      "EPOCH 3040  (with max 8000), loss: 0.0011577935656532645\n",
      "train time for 3040 epochs, was 2508.4347202777863\n",
      "\n",
      "EPOCH 3042  (with max 8000), loss: 0.003488467074930668\n",
      "train time for 3042 epochs, was 2510.0738887786865\n",
      "\n",
      "EPOCH 3044  (with max 8000), loss: 0.002903052605688572\n",
      "train time for 3044 epochs, was 2511.712649822235\n",
      "\n",
      "EPOCH 3046  (with max 8000), loss: 0.0005615982809104025\n",
      "train time for 3046 epochs, was 2513.349254131317\n",
      "\n",
      "EPOCH 3048  (with max 8000), loss: 0.0007174196653068066\n",
      "train time for 3048 epochs, was 2514.985983610153\n",
      "\n",
      "EPOCH 3050  (with max 8000), loss: 0.0144953653216362\n",
      "train time for 3050 epochs, was 2516.618566274643\n",
      "\n",
      "EPOCH 3052  (with max 8000), loss: 0.004270616453140974\n",
      "train time for 3052 epochs, was 2518.251415014267\n",
      "\n",
      "EPOCH 3054  (with max 8000), loss: 0.002276400802657008\n",
      "train time for 3054 epochs, was 2519.8903439044952\n",
      "\n",
      "EPOCH 3056  (with max 8000), loss: 0.004383624065667391\n",
      "train time for 3056 epochs, was 2521.5229918956757\n",
      "\n",
      "EPOCH 3058  (with max 8000), loss: 0.003289503278210759\n",
      "train time for 3058 epochs, was 2523.1598687171936\n",
      "\n",
      "EPOCH 3060  (with max 8000), loss: 0.0039566210471093655\n",
      "train time for 3060 epochs, was 2524.792722940445\n",
      "\n",
      "EPOCH 3062  (with max 8000), loss: 0.010776564478874207\n",
      "train time for 3062 epochs, was 2526.4256117343903\n",
      "\n",
      "EPOCH 3064  (with max 8000), loss: 0.0022346756886690855\n",
      "train time for 3064 epochs, was 2528.058435678482\n",
      "\n",
      "EPOCH 3066  (with max 8000), loss: 0.0014962423592805862\n",
      "train time for 3066 epochs, was 2529.691347837448\n",
      "\n",
      "EPOCH 3068  (with max 8000), loss: 0.006099533289670944\n",
      "train time for 3068 epochs, was 2531.3241941928864\n",
      "\n",
      "EPOCH 3070  (with max 8000), loss: 0.002074225340038538\n",
      "train time for 3070 epochs, was 2532.957020044327\n",
      "\n",
      "EPOCH 3072  (with max 8000), loss: 0.004011189099401236\n",
      "train time for 3072 epochs, was 2534.5917155742645\n",
      "\n",
      "EPOCH 3074  (with max 8000), loss: 0.0022946789395064116\n",
      "train time for 3074 epochs, was 2536.2244403362274\n",
      "\n",
      "EPOCH 3076  (with max 8000), loss: 0.003028028877452016\n",
      "train time for 3076 epochs, was 2537.867601633072\n",
      "\n",
      "EPOCH 3078  (with max 8000), loss: 0.00969256367534399\n",
      "train time for 3078 epochs, was 2539.506744146347\n",
      "\n",
      "EPOCH 3080  (with max 8000), loss: 0.004350974690169096\n",
      "train time for 3080 epochs, was 2541.1393723487854\n",
      "\n",
      "EPOCH 3082  (with max 8000), loss: 0.0012804409489035606\n",
      "train time for 3082 epochs, was 2542.77613902092\n",
      "\n",
      "EPOCH 3084  (with max 8000), loss: 0.0023782760836184025\n",
      "train time for 3084 epochs, was 2544.4086129665375\n",
      "\n",
      "EPOCH 3086  (with max 8000), loss: 0.0028207479044795036\n",
      "train time for 3086 epochs, was 2546.0412380695343\n",
      "\n",
      "EPOCH 3088  (with max 8000), loss: 0.0033961620647460222\n",
      "train time for 3088 epochs, was 2547.673754930496\n",
      "\n",
      "EPOCH 3090  (with max 8000), loss: 0.001885820529423654\n",
      "train time for 3090 epochs, was 2549.3063304424286\n",
      "\n",
      "EPOCH 3092  (with max 8000), loss: 0.00227338052354753\n",
      "train time for 3092 epochs, was 2550.938902616501\n",
      "\n",
      "EPOCH 3094  (with max 8000), loss: 0.002767154946923256\n",
      "train time for 3094 epochs, was 2552.5715613365173\n",
      "\n",
      "EPOCH 3096  (with max 8000), loss: 0.00204381812363863\n",
      "train time for 3096 epochs, was 2554.206583738327\n",
      "\n",
      "EPOCH 3098  (with max 8000), loss: 0.0483219139277935\n",
      "train time for 3098 epochs, was 2555.83927154541\n",
      "\n",
      "EPOCH 3100  (with max 8000), loss: 0.016576793044805527\n",
      "train time for 3100 epochs, was 2557.4739701747894\n",
      "\n",
      "EPOCH 3102  (with max 8000), loss: 0.01624205894768238\n",
      "train time for 3102 epochs, was 2559.112893342972\n",
      "\n",
      "EPOCH 3104  (with max 8000), loss: 0.007930580526590347\n",
      "train time for 3104 epochs, was 2560.760451555252\n",
      "\n",
      "EPOCH 3106  (with max 8000), loss: 0.01361360028386116\n",
      "train time for 3106 epochs, was 2562.3994019031525\n",
      "\n",
      "EPOCH 3108  (with max 8000), loss: 0.00388336181640625\n",
      "train time for 3108 epochs, was 2564.0426993370056\n",
      "\n",
      "EPOCH 3110  (with max 8000), loss: 0.0032984204590320587\n",
      "train time for 3110 epochs, was 2565.67737364769\n",
      "\n",
      "EPOCH 3112  (with max 8000), loss: 0.003042824100703001\n",
      "train time for 3112 epochs, was 2567.3097157478333\n",
      "\n",
      "EPOCH 3114  (with max 8000), loss: 0.0026268765795975924\n",
      "train time for 3114 epochs, was 2568.942322254181\n",
      "\n",
      "EPOCH 3116  (with max 8000), loss: 0.0009689173311926425\n",
      "train time for 3116 epochs, was 2570.5747718811035\n",
      "\n",
      "EPOCH 3118  (with max 8000), loss: 0.00481564411893487\n",
      "train time for 3118 epochs, was 2572.2073481082916\n",
      "\n",
      "EPOCH 3120  (with max 8000), loss: 0.0015663669910281897\n",
      "train time for 3120 epochs, was 2573.8417568206787\n",
      "\n",
      "EPOCH 3122  (with max 8000), loss: 0.005039507988840342\n",
      "train time for 3122 epochs, was 2575.4805493354797\n",
      "\n",
      "EPOCH 3124  (with max 8000), loss: 0.0012888419441878796\n",
      "train time for 3124 epochs, was 2577.112926721573\n",
      "\n",
      "EPOCH 3126  (with max 8000), loss: 0.013952266424894333\n",
      "train time for 3126 epochs, was 2578.745225906372\n",
      "\n",
      "EPOCH 3128  (with max 8000), loss: 0.04473074898123741\n",
      "train time for 3128 epochs, was 2580.3776774406433\n",
      "\n",
      "EPOCH 3130  (with max 8000), loss: 0.014840190298855305\n",
      "train time for 3130 epochs, was 2582.0102832317352\n",
      "\n",
      "EPOCH 3132  (with max 8000), loss: 0.013056796044111252\n",
      "train time for 3132 epochs, was 2583.6424996852875\n",
      "\n",
      "EPOCH 3134  (with max 8000), loss: 0.0019938067998737097\n",
      "train time for 3134 epochs, was 2585.2750067710876\n",
      "\n",
      "EPOCH 3136  (with max 8000), loss: 0.00528758717700839\n",
      "train time for 3136 epochs, was 2586.9074692726135\n",
      "\n",
      "EPOCH 3138  (with max 8000), loss: 0.0013439090689644217\n",
      "train time for 3138 epochs, was 2588.5399944782257\n",
      "\n",
      "EPOCH 3140  (with max 8000), loss: 0.0010049125412479043\n",
      "train time for 3140 epochs, was 2590.1724729537964\n",
      "\n",
      "EPOCH 3142  (with max 8000), loss: 0.04038653150200844\n",
      "train time for 3142 epochs, was 2591.806930065155\n",
      "\n",
      "EPOCH 3144  (with max 8000), loss: 0.01546555571258068\n",
      "train time for 3144 epochs, was 2593.439556837082\n",
      "\n",
      "EPOCH 3146  (with max 8000), loss: 0.006781694013625383\n",
      "train time for 3146 epochs, was 2595.071918487549\n",
      "\n",
      "EPOCH 3148  (with max 8000), loss: 0.01193575281649828\n",
      "train time for 3148 epochs, was 2596.706575870514\n",
      "\n",
      "EPOCH 3150  (with max 8000), loss: 0.0036131886299699545\n",
      "train time for 3150 epochs, was 2598.341233253479\n",
      "\n",
      "EPOCH 3152  (with max 8000), loss: 0.005972164683043957\n",
      "train time for 3152 epochs, was 2600.0113983154297\n",
      "\n",
      "EPOCH 3154  (with max 8000), loss: 0.0020832575391978025\n",
      "train time for 3154 epochs, was 2601.644182920456\n",
      "\n",
      "EPOCH 3156  (with max 8000), loss: 0.004564506001770496\n",
      "train time for 3156 epochs, was 2603.277004957199\n",
      "\n",
      "EPOCH 3158  (with max 8000), loss: 0.005699952598661184\n",
      "train time for 3158 epochs, was 2604.9096677303314\n",
      "\n",
      "EPOCH 3160  (with max 8000), loss: 0.0030105910263955593\n",
      "train time for 3160 epochs, was 2606.542295694351\n",
      "\n",
      "EPOCH 3162  (with max 8000), loss: 0.006300445646047592\n",
      "train time for 3162 epochs, was 2608.174782037735\n",
      "\n",
      "EPOCH 3164  (with max 8000), loss: 0.004263003822416067\n",
      "train time for 3164 epochs, was 2609.807207584381\n",
      "\n",
      "EPOCH 3166  (with max 8000), loss: 0.004121970385313034\n",
      "train time for 3166 epochs, was 2611.4398758411407\n",
      "\n",
      "EPOCH 3168  (with max 8000), loss: 0.012257428839802742\n",
      "train time for 3168 epochs, was 2613.0743918418884\n",
      "\n",
      "EPOCH 3170  (with max 8000), loss: 0.002005114685744047\n",
      "train time for 3170 epochs, was 2614.7088487148285\n",
      "\n",
      "EPOCH 3172  (with max 8000), loss: 0.007678857073187828\n",
      "train time for 3172 epochs, was 2616.3415002822876\n",
      "\n",
      "EPOCH 3174  (with max 8000), loss: 0.0050210352055728436\n",
      "train time for 3174 epochs, was 2617.9743237495422\n",
      "\n",
      "EPOCH 3176  (with max 8000), loss: 0.0034845047630369663\n",
      "train time for 3176 epochs, was 2619.6069304943085\n",
      "\n",
      "EPOCH 3178  (with max 8000), loss: 0.0031600540969520807\n",
      "train time for 3178 epochs, was 2621.2394223213196\n",
      "\n",
      "EPOCH 3180  (with max 8000), loss: 0.0015587634406983852\n",
      "train time for 3180 epochs, was 2622.871804714203\n",
      "\n",
      "EPOCH 3182  (with max 8000), loss: 0.0009916825219988823\n",
      "train time for 3182 epochs, was 2624.504133462906\n",
      "\n",
      "EPOCH 3184  (with max 8000), loss: 0.0019556547049432993\n",
      "train time for 3184 epochs, was 2626.1366391181946\n",
      "\n",
      "EPOCH 3186  (with max 8000), loss: 0.0020189497154206038\n",
      "train time for 3186 epochs, was 2627.7711520195007\n",
      "\n",
      "EPOCH 3188  (with max 8000), loss: 0.0037772769574075937\n",
      "train time for 3188 epochs, was 2629.403906583786\n",
      "\n",
      "EPOCH 3190  (with max 8000), loss: 0.0005980362184345722\n",
      "train time for 3190 epochs, was 2631.044817209244\n",
      "\n",
      "EPOCH 3192  (with max 8000), loss: 0.0006653880700469017\n",
      "train time for 3192 epochs, was 2632.679587125778\n",
      "\n",
      "EPOCH 3194  (with max 8000), loss: 0.0067841229028999805\n",
      "train time for 3194 epochs, was 2634.3122510910034\n",
      "\n",
      "EPOCH 3196  (with max 8000), loss: 0.006773277651518583\n",
      "train time for 3196 epochs, was 2635.9449203014374\n",
      "\n",
      "EPOCH 3198  (with max 8000), loss: 0.014170500449836254\n",
      "train time for 3198 epochs, was 2637.577526807785\n",
      "\n",
      "EPOCH 3200  (with max 8000), loss: 0.016829662024974823\n",
      "train time for 3200 epochs, was 2639.210219860077\n",
      "\n",
      "EPOCH 3200 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_3200.pth\n",
      "\n",
      "EPOCH 3202  (with max 8000), loss: 0.02929692342877388\n",
      "train time for 3202 epochs, was 2640.876396894455\n",
      "\n",
      "EPOCH 3204  (with max 8000), loss: 0.012979012914001942\n",
      "train time for 3204 epochs, was 2642.5088760852814\n",
      "\n",
      "EPOCH 3206  (with max 8000), loss: 0.0035627575125545263\n",
      "train time for 3206 epochs, was 2644.141457080841\n",
      "\n",
      "EPOCH 3208  (with max 8000), loss: 0.012982442043721676\n",
      "train time for 3208 epochs, was 2645.7744200229645\n",
      "\n",
      "EPOCH 3210  (with max 8000), loss: 0.005753152538090944\n",
      "train time for 3210 epochs, was 2647.407263994217\n",
      "\n",
      "EPOCH 3212  (with max 8000), loss: 0.003851525718346238\n",
      "train time for 3212 epochs, was 2649.0400910377502\n",
      "\n",
      "EPOCH 3214  (with max 8000), loss: 0.003300340613350272\n",
      "train time for 3214 epochs, was 2650.6726627349854\n",
      "\n",
      "EPOCH 3216  (with max 8000), loss: 0.0038476609624922276\n",
      "train time for 3216 epochs, was 2652.3050768375397\n",
      "\n",
      "EPOCH 3218  (with max 8000), loss: 0.0027065579779446125\n",
      "train time for 3218 epochs, was 2653.94185090065\n",
      "\n",
      "EPOCH 3220  (with max 8000), loss: 0.008306153118610382\n",
      "train time for 3220 epochs, was 2655.5766129493713\n",
      "\n",
      "EPOCH 3222  (with max 8000), loss: 0.004378359764814377\n",
      "train time for 3222 epochs, was 2657.2094044685364\n",
      "\n",
      "EPOCH 3224  (with max 8000), loss: 0.0026253315154463053\n",
      "train time for 3224 epochs, was 2658.841826438904\n",
      "\n",
      "EPOCH 3226  (with max 8000), loss: 0.006124428939074278\n",
      "train time for 3226 epochs, was 2660.4743032455444\n",
      "\n",
      "EPOCH 3228  (with max 8000), loss: 0.006356149446219206\n",
      "train time for 3228 epochs, was 2662.106870174408\n",
      "\n",
      "EPOCH 3230  (with max 8000), loss: 0.01274947915226221\n",
      "train time for 3230 epochs, was 2663.7393288612366\n",
      "\n",
      "EPOCH 3232  (with max 8000), loss: 0.021487034857273102\n",
      "train time for 3232 epochs, was 2665.371833562851\n",
      "\n",
      "EPOCH 3234  (with max 8000), loss: 0.002939794445410371\n",
      "train time for 3234 epochs, was 2667.006509542465\n",
      "\n",
      "EPOCH 3236  (with max 8000), loss: 0.0036567985080182552\n",
      "train time for 3236 epochs, was 2668.670623779297\n",
      "\n",
      "EPOCH 3238  (with max 8000), loss: 0.02183591201901436\n",
      "train time for 3238 epochs, was 2670.3031554222107\n",
      "\n",
      "EPOCH 3240  (with max 8000), loss: 0.011181761510670185\n",
      "train time for 3240 epochs, was 2671.937733888626\n",
      "\n",
      "EPOCH 3242  (with max 8000), loss: 0.004099612589925528\n",
      "train time for 3242 epochs, was 2673.570230960846\n",
      "\n",
      "EPOCH 3244  (with max 8000), loss: 0.0042284587398171425\n",
      "train time for 3244 epochs, was 2675.203162908554\n",
      "\n",
      "EPOCH 3246  (with max 8000), loss: 0.0032059894874691963\n",
      "train time for 3246 epochs, was 2676.841954469681\n",
      "\n",
      "EPOCH 3248  (with max 8000), loss: 0.003600941738113761\n",
      "train time for 3248 epochs, was 2678.4810152053833\n",
      "\n",
      "EPOCH 3250  (with max 8000), loss: 0.013396148569881916\n",
      "train time for 3250 epochs, was 2680.1201543807983\n",
      "\n",
      "EPOCH 3252  (with max 8000), loss: 0.01739778183400631\n",
      "train time for 3252 epochs, was 2681.753034353256\n",
      "\n",
      "EPOCH 3254  (with max 8000), loss: 0.012533425353467464\n",
      "train time for 3254 epochs, was 2683.385763168335\n",
      "\n",
      "EPOCH 3256  (with max 8000), loss: 0.00877568032592535\n",
      "train time for 3256 epochs, was 2685.0205359458923\n",
      "\n",
      "EPOCH 3258  (with max 8000), loss: 0.005208831746131182\n",
      "train time for 3258 epochs, was 2686.6531744003296\n",
      "\n",
      "EPOCH 3260  (with max 8000), loss: 0.0032648807391524315\n",
      "train time for 3260 epochs, was 2688.286160469055\n",
      "\n",
      "EPOCH 3262  (with max 8000), loss: 0.0033688198309391737\n",
      "train time for 3262 epochs, was 2689.9214890003204\n",
      "\n",
      "EPOCH 3264  (with max 8000), loss: 0.00543855270370841\n",
      "train time for 3264 epochs, was 2691.5566062927246\n",
      "\n",
      "EPOCH 3266  (with max 8000), loss: 0.0010094578610733151\n",
      "train time for 3266 epochs, was 2693.1959607601166\n",
      "\n",
      "EPOCH 3268  (with max 8000), loss: 0.0017175546381622553\n",
      "train time for 3268 epochs, was 2694.8289756774902\n",
      "\n",
      "EPOCH 3270  (with max 8000), loss: 0.0011901527177542448\n",
      "train time for 3270 epochs, was 2696.462192296982\n",
      "\n",
      "EPOCH 3272  (with max 8000), loss: 0.000982619938440621\n",
      "train time for 3272 epochs, was 2698.0952961444855\n",
      "\n",
      "EPOCH 3274  (with max 8000), loss: 0.0016599266091361642\n",
      "train time for 3274 epochs, was 2699.7285676002502\n",
      "\n",
      "EPOCH 3276  (with max 8000), loss: 0.0029987606685608625\n",
      "train time for 3276 epochs, was 2701.361743450165\n",
      "\n",
      "EPOCH 3278  (with max 8000), loss: 0.0015520225279033184\n",
      "train time for 3278 epochs, was 2703.0074944496155\n",
      "\n",
      "EPOCH 3280  (with max 8000), loss: 0.0023249390069395304\n",
      "train time for 3280 epochs, was 2704.661843061447\n",
      "\n",
      "EPOCH 3282  (with max 8000), loss: 0.0005307389656081796\n",
      "train time for 3282 epochs, was 2706.2951622009277\n",
      "\n",
      "EPOCH 3284  (with max 8000), loss: 0.0012891145888715982\n",
      "train time for 3284 epochs, was 2707.928412437439\n",
      "\n",
      "EPOCH 3286  (with max 8000), loss: 0.00985906831920147\n",
      "train time for 3286 epochs, was 2709.563686132431\n",
      "\n",
      "EPOCH 3288  (with max 8000), loss: 0.0033463938161730766\n",
      "train time for 3288 epochs, was 2711.1969821453094\n",
      "\n",
      "EPOCH 3290  (with max 8000), loss: 0.003239727346226573\n",
      "train time for 3290 epochs, was 2712.830231666565\n",
      "\n",
      "EPOCH 3292  (with max 8000), loss: 0.002158536808565259\n",
      "train time for 3292 epochs, was 2714.4717514514923\n",
      "\n",
      "EPOCH 3294  (with max 8000), loss: 0.14518870413303375\n",
      "train time for 3294 epochs, was 2716.1154429912567\n",
      "\n",
      "EPOCH 3296  (with max 8000), loss: 0.021362753584980965\n",
      "train time for 3296 epochs, was 2717.7487437725067\n",
      "\n",
      "EPOCH 3298  (with max 8000), loss: 0.004543686285614967\n",
      "train time for 3298 epochs, was 2719.384234905243\n",
      "\n",
      "EPOCH 3300  (with max 8000), loss: 0.004048225935548544\n",
      "train time for 3300 epochs, was 2721.0218760967255\n",
      "\n",
      "EPOCH 3302  (with max 8000), loss: 0.0013620303943753242\n",
      "train time for 3302 epochs, was 2722.6551694869995\n",
      "\n",
      "EPOCH 3304  (with max 8000), loss: 0.004975848365575075\n",
      "train time for 3304 epochs, was 2724.2884182929993\n",
      "\n",
      "EPOCH 3306  (with max 8000), loss: 0.00665453914552927\n",
      "train time for 3306 epochs, was 2725.9217143058777\n",
      "\n",
      "EPOCH 3308  (with max 8000), loss: 0.0012894992250949144\n",
      "train time for 3308 epochs, was 2727.554891347885\n",
      "\n",
      "EPOCH 3310  (with max 8000), loss: 0.009483300149440765\n",
      "train time for 3310 epochs, was 2729.188201189041\n",
      "\n",
      "EPOCH 3312  (with max 8000), loss: 0.01492203027009964\n",
      "train time for 3312 epochs, was 2730.8215625286102\n",
      "\n",
      "EPOCH 3314  (with max 8000), loss: 0.010108434595167637\n",
      "train time for 3314 epochs, was 2732.457052707672\n",
      "\n",
      "EPOCH 3316  (with max 8000), loss: 0.021178560331463814\n",
      "train time for 3316 epochs, was 2734.092693567276\n",
      "\n",
      "EPOCH 3318  (with max 8000), loss: 0.006916460115462542\n",
      "train time for 3318 epochs, was 2735.732445001602\n",
      "\n",
      "EPOCH 3320  (with max 8000), loss: 0.001188935013487935\n",
      "train time for 3320 epochs, was 2737.3701679706573\n",
      "\n",
      "EPOCH 3322  (with max 8000), loss: 0.0057758125476539135\n",
      "train time for 3322 epochs, was 2739.003787755966\n",
      "\n",
      "EPOCH 3324  (with max 8000), loss: 0.004258233588188887\n",
      "train time for 3324 epochs, was 2740.6373710632324\n",
      "\n",
      "EPOCH 3326  (with max 8000), loss: 0.002883963054046035\n",
      "train time for 3326 epochs, was 2742.2833545207977\n",
      "\n",
      "EPOCH 3328  (with max 8000), loss: 0.0015854021767154336\n",
      "train time for 3328 epochs, was 2743.916768312454\n",
      "\n",
      "EPOCH 3330  (with max 8000), loss: 0.0012292108731344342\n",
      "train time for 3330 epochs, was 2745.552173137665\n",
      "\n",
      "EPOCH 3332  (with max 8000), loss: 0.00447005545720458\n",
      "train time for 3332 epochs, was 2747.1855943202972\n",
      "\n",
      "EPOCH 3334  (with max 8000), loss: 0.003240574151277542\n",
      "train time for 3334 epochs, was 2748.81880736351\n",
      "\n",
      "EPOCH 3336  (with max 8000), loss: 0.005246245767921209\n",
      "train time for 3336 epochs, was 2750.4521939754486\n",
      "\n",
      "EPOCH 3338  (with max 8000), loss: 0.0027339658699929714\n",
      "train time for 3338 epochs, was 2752.0853435993195\n",
      "\n",
      "EPOCH 3340  (with max 8000), loss: 0.006874440237879753\n",
      "train time for 3340 epochs, was 2753.718721151352\n",
      "\n",
      "EPOCH 3342  (with max 8000), loss: 0.0070873103104531765\n",
      "train time for 3342 epochs, was 2755.3519592285156\n",
      "\n",
      "EPOCH 3344  (with max 8000), loss: 0.0036382062826305628\n",
      "train time for 3344 epochs, was 2756.985185623169\n",
      "\n",
      "EPOCH 3346  (with max 8000), loss: 0.0014168479247018695\n",
      "train time for 3346 epochs, was 2758.6184961795807\n",
      "\n",
      "EPOCH 3348  (with max 8000), loss: 0.003550085471943021\n",
      "train time for 3348 epochs, was 2760.2519574165344\n",
      "\n",
      "EPOCH 3350  (with max 8000), loss: 0.0014771715505048633\n",
      "train time for 3350 epochs, was 2761.88560628891\n",
      "\n",
      "EPOCH 3352  (with max 8000), loss: 0.004432846326380968\n",
      "train time for 3352 epochs, was 2763.518998861313\n",
      "\n",
      "EPOCH 3354  (with max 8000), loss: 0.0015650707064196467\n",
      "train time for 3354 epochs, was 2765.1523604393005\n",
      "\n",
      "EPOCH 3356  (with max 8000), loss: 0.001175452722236514\n",
      "train time for 3356 epochs, was 2766.785898923874\n",
      "\n",
      "EPOCH 3358  (with max 8000), loss: 0.0007928089471533895\n",
      "train time for 3358 epochs, was 2768.41947889328\n",
      "\n",
      "EPOCH 3360  (with max 8000), loss: 0.0051633636467158794\n",
      "train time for 3360 epochs, was 2770.0739312171936\n",
      "\n",
      "EPOCH 3362  (with max 8000), loss: 0.0039393166080117226\n",
      "train time for 3362 epochs, was 2771.7074258327484\n",
      "\n",
      "EPOCH 3364  (with max 8000), loss: 0.00881612952798605\n",
      "train time for 3364 epochs, was 2773.340763568878\n",
      "\n",
      "EPOCH 3366  (with max 8000), loss: 0.20298901200294495\n",
      "train time for 3366 epochs, was 2774.974407672882\n",
      "\n",
      "EPOCH 3368  (with max 8000), loss: 0.024916283786296844\n",
      "train time for 3368 epochs, was 2776.6081647872925\n",
      "\n",
      "EPOCH 3370  (with max 8000), loss: 0.06521732360124588\n",
      "train time for 3370 epochs, was 2778.241699695587\n",
      "\n",
      "EPOCH 3372  (with max 8000), loss: 0.01623009704053402\n",
      "train time for 3372 epochs, was 2779.8979897499084\n",
      "\n",
      "EPOCH 3374  (with max 8000), loss: 0.00469811400398612\n",
      "train time for 3374 epochs, was 2781.5334804058075\n",
      "\n",
      "EPOCH 3376  (with max 8000), loss: 0.011378210969269276\n",
      "train time for 3376 epochs, was 2783.1671874523163\n",
      "\n",
      "EPOCH 3378  (with max 8000), loss: 0.0052306558936834335\n",
      "train time for 3378 epochs, was 2784.8007383346558\n",
      "\n",
      "EPOCH 3380  (with max 8000), loss: 0.004552760627120733\n",
      "train time for 3380 epochs, was 2786.4343779087067\n",
      "\n",
      "EPOCH 3382  (with max 8000), loss: 0.0010493608424440026\n",
      "train time for 3382 epochs, was 2788.06800031662\n",
      "\n",
      "EPOCH 3384  (with max 8000), loss: 0.00889697764068842\n",
      "train time for 3384 epochs, was 2789.7016241550446\n",
      "\n",
      "EPOCH 3386  (with max 8000), loss: 0.014239138923585415\n",
      "train time for 3386 epochs, was 2791.3395190238953\n",
      "\n",
      "EPOCH 3388  (with max 8000), loss: 0.006291080266237259\n",
      "train time for 3388 epochs, was 2792.9776158332825\n",
      "\n",
      "EPOCH 3390  (with max 8000), loss: 0.00650442810729146\n",
      "train time for 3390 epochs, was 2794.613405942917\n",
      "\n",
      "EPOCH 3392  (with max 8000), loss: 0.001975112361833453\n",
      "train time for 3392 epochs, was 2796.2470932006836\n",
      "\n",
      "EPOCH 3394  (with max 8000), loss: 0.004253171384334564\n",
      "train time for 3394 epochs, was 2797.8810818195343\n",
      "\n",
      "EPOCH 3396  (with max 8000), loss: 0.003554873401299119\n",
      "train time for 3396 epochs, was 2799.5147907733917\n",
      "\n",
      "EPOCH 3398  (with max 8000), loss: 0.004941832274198532\n",
      "train time for 3398 epochs, was 2801.148402452469\n",
      "\n",
      "EPOCH 3400  (with max 8000), loss: 0.003151779994368553\n",
      "train time for 3400 epochs, was 2802.784045934677\n",
      "\n",
      "EPOCH 3400 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_3400.pth\n",
      "\n",
      "EPOCH 3402  (with max 8000), loss: 0.0019692431669682264\n",
      "train time for 3402 epochs, was 2804.4554493427277\n",
      "\n",
      "EPOCH 3404  (with max 8000), loss: 0.0030905562452971935\n",
      "train time for 3404 epochs, was 2806.0910954475403\n",
      "\n",
      "EPOCH 3406  (with max 8000), loss: 0.0022540835198014975\n",
      "train time for 3406 epochs, was 2807.7268555164337\n",
      "\n",
      "EPOCH 3408  (with max 8000), loss: 0.0020994048099964857\n",
      "train time for 3408 epochs, was 2809.360761642456\n",
      "\n",
      "EPOCH 3410  (with max 8000), loss: 0.00232400419190526\n",
      "train time for 3410 epochs, was 2810.9963636398315\n",
      "\n",
      "EPOCH 3412  (with max 8000), loss: 0.0017354285810142756\n",
      "train time for 3412 epochs, was 2812.6425788402557\n",
      "\n",
      "EPOCH 3414  (with max 8000), loss: 0.0019411275861784816\n",
      "train time for 3414 epochs, was 2814.278213262558\n",
      "\n",
      "EPOCH 3416  (with max 8000), loss: 0.0018880284624174237\n",
      "train time for 3416 epochs, was 2815.939049720764\n",
      "\n",
      "EPOCH 3418  (with max 8000), loss: 0.002434415277093649\n",
      "train time for 3418 epochs, was 2817.5768842697144\n",
      "\n",
      "EPOCH 3420  (with max 8000), loss: 0.0013860538601875305\n",
      "train time for 3420 epochs, was 2819.2128303050995\n",
      "\n",
      "EPOCH 3422  (with max 8000), loss: 0.0037400706205517054\n",
      "train time for 3422 epochs, was 2820.846425294876\n",
      "\n",
      "EPOCH 3424  (with max 8000), loss: 0.0048059686087071896\n",
      "train time for 3424 epochs, was 2822.4801416397095\n",
      "\n",
      "EPOCH 3426  (with max 8000), loss: 0.02885361760854721\n",
      "train time for 3426 epochs, was 2824.1158323287964\n",
      "\n",
      "EPOCH 3428  (with max 8000), loss: 0.0763133317232132\n",
      "train time for 3428 epochs, was 2825.7496461868286\n",
      "\n",
      "EPOCH 3430  (with max 8000), loss: 0.012305897660553455\n",
      "train time for 3430 epochs, was 2827.3832199573517\n",
      "\n",
      "EPOCH 3432  (with max 8000), loss: 0.00437250267714262\n",
      "train time for 3432 epochs, was 2829.0168821811676\n",
      "\n",
      "EPOCH 3434  (with max 8000), loss: 0.009619440883398056\n",
      "train time for 3434 epochs, was 2830.6509618759155\n",
      "\n",
      "EPOCH 3436  (with max 8000), loss: 0.010504273697733879\n",
      "train time for 3436 epochs, was 2832.285118818283\n",
      "\n",
      "EPOCH 3438  (with max 8000), loss: 0.009247963316738605\n",
      "train time for 3438 epochs, was 2833.919290781021\n",
      "\n",
      "EPOCH 3440  (with max 8000), loss: 0.00240649888291955\n",
      "train time for 3440 epochs, was 2835.5529370307922\n",
      "\n",
      "EPOCH 3442  (with max 8000), loss: 0.005027030594646931\n",
      "train time for 3442 epochs, was 2837.1866834163666\n",
      "\n",
      "EPOCH 3444  (with max 8000), loss: 0.0032977478113025427\n",
      "train time for 3444 epochs, was 2838.8205738067627\n",
      "\n",
      "EPOCH 3446  (with max 8000), loss: 0.0101997135207057\n",
      "train time for 3446 epochs, was 2840.454529285431\n",
      "\n",
      "EPOCH 3448  (with max 8000), loss: 0.004670718684792519\n",
      "train time for 3448 epochs, was 2842.088476419449\n",
      "\n",
      "EPOCH 3450  (with max 8000), loss: 0.002385369734838605\n",
      "train time for 3450 epochs, was 2843.7266223430634\n",
      "\n",
      "EPOCH 3452  (with max 8000), loss: 0.008940664120018482\n",
      "train time for 3452 epochs, was 2845.3602867126465\n",
      "\n",
      "EPOCH 3454  (with max 8000), loss: 0.0036526645999401808\n",
      "train time for 3454 epochs, was 2847.0089960098267\n",
      "\n",
      "EPOCH 3456  (with max 8000), loss: 0.008659055456519127\n",
      "train time for 3456 epochs, was 2848.6428372859955\n",
      "\n",
      "EPOCH 3458  (with max 8000), loss: 0.004050013143569231\n",
      "train time for 3458 epochs, was 2850.2765851020813\n",
      "\n",
      "EPOCH 3460  (with max 8000), loss: 0.008251146413385868\n",
      "train time for 3460 epochs, was 2851.9123163223267\n",
      "\n",
      "EPOCH 3462  (with max 8000), loss: 0.003459927858784795\n",
      "train time for 3462 epochs, was 2853.5461082458496\n",
      "\n",
      "EPOCH 3464  (with max 8000), loss: 0.0011034891940653324\n",
      "train time for 3464 epochs, was 2855.1967549324036\n",
      "\n",
      "EPOCH 3466  (with max 8000), loss: 0.005949152167886496\n",
      "train time for 3466 epochs, was 2856.8305809497833\n",
      "\n",
      "EPOCH 3468  (with max 8000), loss: 0.0040420652367174625\n",
      "train time for 3468 epochs, was 2858.4663286209106\n",
      "\n",
      "EPOCH 3470  (with max 8000), loss: 0.007132715079933405\n",
      "train time for 3470 epochs, was 2860.1104941368103\n",
      "\n",
      "EPOCH 3472  (with max 8000), loss: 0.0008649974479340017\n",
      "train time for 3472 epochs, was 2861.744313955307\n",
      "\n",
      "EPOCH 3474  (with max 8000), loss: 0.002867979696020484\n",
      "train time for 3474 epochs, was 2863.3802785873413\n",
      "\n",
      "EPOCH 3476  (with max 8000), loss: 0.0036427045706659555\n",
      "train time for 3476 epochs, was 2865.0201971530914\n",
      "\n",
      "EPOCH 3478  (with max 8000), loss: 0.00910914782434702\n",
      "train time for 3478 epochs, was 2866.6538784503937\n",
      "\n",
      "EPOCH 3480  (with max 8000), loss: 0.0004816571599803865\n",
      "train time for 3480 epochs, was 2868.28759431839\n",
      "\n",
      "EPOCH 3482  (with max 8000), loss: 0.0015827170573174953\n",
      "train time for 3482 epochs, was 2869.923823595047\n",
      "\n",
      "EPOCH 3484  (with max 8000), loss: 0.003117159940302372\n",
      "train time for 3484 epochs, was 2871.559632539749\n",
      "\n",
      "EPOCH 3486  (with max 8000), loss: 0.0012482599122449756\n",
      "train time for 3486 epochs, was 2873.193424463272\n",
      "\n",
      "EPOCH 3488  (with max 8000), loss: 0.005096449051052332\n",
      "train time for 3488 epochs, was 2874.829551935196\n",
      "\n",
      "EPOCH 3490  (with max 8000), loss: 0.0053091193549335\n",
      "train time for 3490 epochs, was 2876.4633457660675\n",
      "\n",
      "EPOCH 3492  (with max 8000), loss: 0.09408258646726608\n",
      "train time for 3492 epochs, was 2878.099088907242\n",
      "\n",
      "EPOCH 3494  (with max 8000), loss: 0.01670386642217636\n",
      "train time for 3494 epochs, was 2879.7329547405243\n",
      "\n",
      "EPOCH 3496  (with max 8000), loss: 0.010852040722966194\n",
      "train time for 3496 epochs, was 2881.373105764389\n",
      "\n",
      "EPOCH 3498  (with max 8000), loss: 0.005189800169318914\n",
      "train time for 3498 epochs, was 2883.0070176124573\n",
      "\n",
      "EPOCH 3500  (with max 8000), loss: 0.004325880203396082\n",
      "train time for 3500 epochs, was 2884.6451756954193\n",
      "\n",
      "EPOCH 3502  (with max 8000), loss: 0.0030429556500166655\n",
      "train time for 3502 epochs, was 2886.279037952423\n",
      "\n",
      "EPOCH 3504  (with max 8000), loss: 0.003553125774487853\n",
      "train time for 3504 epochs, was 2887.912738800049\n",
      "\n",
      "EPOCH 3506  (with max 8000), loss: 0.001839722623117268\n",
      "train time for 3506 epochs, was 2889.567368745804\n",
      "\n",
      "EPOCH 3508  (with max 8000), loss: 0.007493695709854364\n",
      "train time for 3508 epochs, was 2891.203409910202\n",
      "\n",
      "EPOCH 3510  (with max 8000), loss: 0.004839742090553045\n",
      "train time for 3510 epochs, was 2892.8412642478943\n",
      "\n",
      "EPOCH 3512  (with max 8000), loss: 0.00361252436414361\n",
      "train time for 3512 epochs, was 2894.477259874344\n",
      "\n",
      "EPOCH 3514  (with max 8000), loss: 0.0019228613236919045\n",
      "train time for 3514 epochs, was 2896.1109726428986\n",
      "\n",
      "EPOCH 3516  (with max 8000), loss: 0.0034522898495197296\n",
      "train time for 3516 epochs, was 2897.7449119091034\n",
      "\n",
      "EPOCH 3518  (with max 8000), loss: 0.003909730818122625\n",
      "train time for 3518 epochs, was 2899.3869202136993\n",
      "\n",
      "EPOCH 3520  (with max 8000), loss: 0.0011933826608583331\n",
      "train time for 3520 epochs, was 2901.0246510505676\n",
      "\n",
      "EPOCH 3522  (with max 8000), loss: 0.004450060427188873\n",
      "train time for 3522 epochs, was 2902.658271551132\n",
      "\n",
      "EPOCH 3524  (with max 8000), loss: 0.003820559475570917\n",
      "train time for 3524 epochs, was 2904.2920184135437\n",
      "\n",
      "EPOCH 3526  (with max 8000), loss: 0.005632302723824978\n",
      "train time for 3526 epochs, was 2905.9257156848907\n",
      "\n",
      "EPOCH 3528  (with max 8000), loss: 0.01722853071987629\n",
      "train time for 3528 epochs, was 2907.559434890747\n",
      "\n",
      "EPOCH 3530  (with max 8000), loss: 0.030690476298332214\n",
      "train time for 3530 epochs, was 2909.193131685257\n",
      "\n",
      "EPOCH 3532  (with max 8000), loss: 0.032595500349998474\n",
      "train time for 3532 epochs, was 2910.8268568515778\n",
      "\n",
      "EPOCH 3534  (with max 8000), loss: 0.01231625396758318\n",
      "train time for 3534 epochs, was 2912.46080994606\n",
      "\n",
      "EPOCH 3536  (with max 8000), loss: 0.010209064930677414\n",
      "train time for 3536 epochs, was 2914.0946605205536\n",
      "\n",
      "EPOCH 3538  (with max 8000), loss: 0.010713860392570496\n",
      "train time for 3538 epochs, was 2915.728397130966\n",
      "\n",
      "EPOCH 3540  (with max 8000), loss: 0.0036959650460630655\n",
      "train time for 3540 epochs, was 2917.362235546112\n",
      "\n",
      "EPOCH 3542  (with max 8000), loss: 0.0011204114416614175\n",
      "train time for 3542 epochs, was 2918.996273756027\n",
      "\n",
      "EPOCH 3544  (with max 8000), loss: 0.004421279765665531\n",
      "train time for 3544 epochs, was 2920.630103111267\n",
      "\n",
      "EPOCH 3546  (with max 8000), loss: 0.0016491767019033432\n",
      "train time for 3546 epochs, was 2922.2639558315277\n",
      "\n",
      "EPOCH 3548  (with max 8000), loss: 0.00425719516351819\n",
      "train time for 3548 epochs, was 2923.903892993927\n",
      "\n",
      "EPOCH 3550  (with max 8000), loss: 0.0067889504134655\n",
      "train time for 3550 epochs, was 2925.537492990494\n",
      "\n",
      "EPOCH 3552  (with max 8000), loss: 0.003947395831346512\n",
      "train time for 3552 epochs, was 2927.171643972397\n",
      "\n",
      "EPOCH 3554  (with max 8000), loss: 0.00284536462277174\n",
      "train time for 3554 epochs, was 2928.815828561783\n",
      "\n",
      "EPOCH 3556  (with max 8000), loss: 0.002453896449878812\n",
      "train time for 3556 epochs, was 2930.4498286247253\n",
      "\n",
      "EPOCH 3558  (with max 8000), loss: 0.002694838447496295\n",
      "train time for 3558 epochs, was 2932.0835134983063\n",
      "\n",
      "EPOCH 3560  (with max 8000), loss: 0.001534012844786048\n",
      "train time for 3560 epochs, was 2933.7175517082214\n",
      "\n",
      "EPOCH 3562  (with max 8000), loss: 0.0020658462308347225\n",
      "train time for 3562 epochs, was 2935.351407766342\n",
      "\n",
      "EPOCH 3564  (with max 8000), loss: 0.0023901318199932575\n",
      "train time for 3564 epochs, was 2936.9853065013885\n",
      "\n",
      "EPOCH 3566  (with max 8000), loss: 0.00266836560331285\n",
      "train time for 3566 epochs, was 2938.619081735611\n",
      "\n",
      "EPOCH 3568  (with max 8000), loss: 0.0016013476997613907\n",
      "train time for 3568 epochs, was 2940.252945661545\n",
      "\n",
      "EPOCH 3570  (with max 8000), loss: 0.0017299172468483448\n",
      "train time for 3570 epochs, was 2941.88668012619\n",
      "\n",
      "EPOCH 3572  (with max 8000), loss: 0.0010452175047248602\n",
      "train time for 3572 epochs, was 2943.520426750183\n",
      "\n",
      "EPOCH 3574  (with max 8000), loss: 0.001685731578618288\n",
      "train time for 3574 epochs, was 2945.1562762260437\n",
      "\n",
      "EPOCH 3576  (with max 8000), loss: 0.0017645492916926742\n",
      "train time for 3576 epochs, was 2946.792200565338\n",
      "\n",
      "EPOCH 3578  (with max 8000), loss: 0.001517486060038209\n",
      "train time for 3578 epochs, was 2948.426301240921\n",
      "\n",
      "EPOCH 3580  (with max 8000), loss: 0.004496220499277115\n",
      "train time for 3580 epochs, was 2950.060163974762\n",
      "\n",
      "EPOCH 3582  (with max 8000), loss: 0.003924657125025988\n",
      "train time for 3582 epochs, was 2951.6959478855133\n",
      "\n",
      "EPOCH 3584  (with max 8000), loss: 0.002823601011186838\n",
      "train time for 3584 epochs, was 2953.336211204529\n",
      "\n",
      "EPOCH 3586  (with max 8000), loss: 0.0022684235591441393\n",
      "train time for 3586 epochs, was 2954.972130060196\n",
      "\n",
      "EPOCH 3588  (with max 8000), loss: 0.14922094345092773\n",
      "train time for 3588 epochs, was 2956.6143181324005\n",
      "\n",
      "EPOCH 3590  (with max 8000), loss: 0.35345661640167236\n",
      "train time for 3590 epochs, was 2958.2504363059998\n",
      "\n",
      "EPOCH 3592  (with max 8000), loss: 0.09691010415554047\n",
      "train time for 3592 epochs, was 2959.917958021164\n",
      "\n",
      "EPOCH 3594  (with max 8000), loss: 0.0742977038025856\n",
      "train time for 3594 epochs, was 2961.5518684387207\n",
      "\n",
      "EPOCH 3596  (with max 8000), loss: 0.03212502971291542\n",
      "train time for 3596 epochs, was 2963.1884639263153\n",
      "\n",
      "EPOCH 3598  (with max 8000), loss: 0.06512176245450974\n",
      "train time for 3598 epochs, was 2964.8248443603516\n",
      "\n",
      "EPOCH 3600  (with max 8000), loss: 0.015398312360048294\n",
      "train time for 3600 epochs, was 2966.458766222\n",
      "\n",
      "EPOCH 3600 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_3600.pth\n",
      "\n",
      "EPOCH 3602  (with max 8000), loss: 0.023731393739581108\n",
      "train time for 3602 epochs, was 2968.128420829773\n",
      "\n",
      "EPOCH 3604  (with max 8000), loss: 0.01343246828764677\n",
      "train time for 3604 epochs, was 2969.762540102005\n",
      "\n",
      "EPOCH 3606  (with max 8000), loss: 0.011724610812962055\n",
      "train time for 3606 epochs, was 2971.398468732834\n",
      "\n",
      "EPOCH 3608  (with max 8000), loss: 0.014942982234060764\n",
      "train time for 3608 epochs, was 2973.0324404239655\n",
      "\n",
      "EPOCH 3610  (with max 8000), loss: 0.013348482549190521\n",
      "train time for 3610 epochs, was 2974.666469812393\n",
      "\n",
      "EPOCH 3612  (with max 8000), loss: 0.013835756108164787\n",
      "train time for 3612 epochs, was 2976.3004717826843\n",
      "\n",
      "EPOCH 3614  (with max 8000), loss: 0.010955804027616978\n",
      "train time for 3614 epochs, was 2977.9344618320465\n",
      "\n",
      "EPOCH 3616  (with max 8000), loss: 0.0055148545652627945\n",
      "train time for 3616 epochs, was 2979.568392276764\n",
      "\n",
      "EPOCH 3618  (with max 8000), loss: 0.004602185916155577\n",
      "train time for 3618 epochs, was 2981.20654296875\n",
      "\n",
      "EPOCH 3620  (with max 8000), loss: 0.0077821239829063416\n",
      "train time for 3620 epochs, was 2982.840463399887\n",
      "\n",
      "EPOCH 3622  (with max 8000), loss: 0.002492244355380535\n",
      "train time for 3622 epochs, was 2984.4765446186066\n",
      "\n",
      "EPOCH 3624  (with max 8000), loss: 0.004959279205650091\n",
      "train time for 3624 epochs, was 2986.1187386512756\n",
      "\n",
      "EPOCH 3626  (with max 8000), loss: 0.003106640186160803\n",
      "train time for 3626 epochs, was 2987.7525799274445\n",
      "\n",
      "EPOCH 3628  (with max 8000), loss: 0.003979925066232681\n",
      "train time for 3628 epochs, was 2989.4075672626495\n",
      "\n",
      "EPOCH 3630  (with max 8000), loss: 0.00524710351601243\n",
      "train time for 3630 epochs, was 2991.0416600704193\n",
      "\n",
      "EPOCH 3632  (with max 8000), loss: 0.002984188264235854\n",
      "train time for 3632 epochs, was 2992.6774487495422\n",
      "\n",
      "EPOCH 3634  (with max 8000), loss: 0.031908366829156876\n",
      "train time for 3634 epochs, was 2994.327951669693\n",
      "\n",
      "EPOCH 3636  (with max 8000), loss: 0.08077751100063324\n",
      "train time for 3636 epochs, was 2995.9660217761993\n",
      "\n",
      "EPOCH 3638  (with max 8000), loss: 0.01192405167967081\n",
      "train time for 3638 epochs, was 2997.5999574661255\n",
      "\n",
      "EPOCH 3640  (with max 8000), loss: 0.014357196167111397\n",
      "train time for 3640 epochs, was 2999.233889102936\n",
      "\n",
      "EPOCH 3642  (with max 8000), loss: 0.00983231421560049\n",
      "train time for 3642 epochs, was 3000.8679871559143\n",
      "\n",
      "EPOCH 3644  (with max 8000), loss: 0.004371978808194399\n",
      "train time for 3644 epochs, was 3002.503981113434\n",
      "\n",
      "EPOCH 3646  (with max 8000), loss: 0.005140257533639669\n",
      "train time for 3646 epochs, was 3004.1377997398376\n",
      "\n",
      "EPOCH 3648  (with max 8000), loss: 0.006626445334404707\n",
      "train time for 3648 epochs, was 3005.7717480659485\n",
      "\n",
      "EPOCH 3650  (with max 8000), loss: 0.0016137323109433055\n",
      "train time for 3650 epochs, was 3007.4055206775665\n",
      "\n",
      "EPOCH 3652  (with max 8000), loss: 0.00832102820277214\n",
      "train time for 3652 epochs, was 3009.039485692978\n",
      "\n",
      "EPOCH 3654  (with max 8000), loss: 0.007030103355646133\n",
      "train time for 3654 epochs, was 3010.6734294891357\n",
      "\n",
      "EPOCH 3656  (with max 8000), loss: 0.004312281962484121\n",
      "train time for 3656 epochs, was 3012.307644844055\n",
      "\n",
      "EPOCH 3658  (with max 8000), loss: 0.004314198158681393\n",
      "train time for 3658 epochs, was 3013.9416296482086\n",
      "\n",
      "EPOCH 3660  (with max 8000), loss: 0.005344117060303688\n",
      "train time for 3660 epochs, was 3015.5755105018616\n",
      "\n",
      "EPOCH 3662  (with max 8000), loss: 0.001055048662237823\n",
      "train time for 3662 epochs, was 3017.2093756198883\n",
      "\n",
      "EPOCH 3664  (with max 8000), loss: 0.0019752918742597103\n",
      "train time for 3664 epochs, was 3018.8472583293915\n",
      "\n",
      "EPOCH 3666  (with max 8000), loss: 0.00639576418325305\n",
      "train time for 3666 epochs, was 3020.4832108020782\n",
      "\n",
      "EPOCH 3668  (with max 8000), loss: 0.0027747792191803455\n",
      "train time for 3668 epochs, was 3022.1212306022644\n",
      "\n",
      "EPOCH 3670  (with max 8000), loss: 0.0032445574179291725\n",
      "train time for 3670 epochs, was 3023.7550599575043\n",
      "\n",
      "EPOCH 3672  (with max 8000), loss: 0.00404316047206521\n",
      "train time for 3672 epochs, was 3025.3888459205627\n",
      "\n",
      "EPOCH 3674  (with max 8000), loss: 0.0011634661350399256\n",
      "train time for 3674 epochs, was 3027.0228655338287\n",
      "\n",
      "EPOCH 3676  (with max 8000), loss: 0.0010056428145617247\n",
      "train time for 3676 epochs, was 3028.6568036079407\n",
      "\n",
      "EPOCH 3678  (with max 8000), loss: 0.001369952573440969\n",
      "train time for 3678 epochs, was 3030.290776491165\n",
      "\n",
      "EPOCH 3680  (with max 8000), loss: 0.003914498258382082\n",
      "train time for 3680 epochs, was 3031.9412569999695\n",
      "\n",
      "EPOCH 3682  (with max 8000), loss: 0.002333118114620447\n",
      "train time for 3682 epochs, was 3033.575152873993\n",
      "\n",
      "EPOCH 3684  (with max 8000), loss: 0.003416350344195962\n",
      "train time for 3684 epochs, was 3035.2090187072754\n",
      "\n",
      "EPOCH 3686  (with max 8000), loss: 0.0005109073827043176\n",
      "train time for 3686 epochs, was 3036.8491203784943\n",
      "\n",
      "EPOCH 3688  (with max 8000), loss: 0.0027073773089796305\n",
      "train time for 3688 epochs, was 3038.4829971790314\n",
      "\n",
      "EPOCH 3690  (with max 8000), loss: 0.04800217226147652\n",
      "train time for 3690 epochs, was 3040.1168859004974\n",
      "\n",
      "EPOCH 3692  (with max 8000), loss: 0.04012665897607803\n",
      "train time for 3692 epochs, was 3041.75306224823\n",
      "\n",
      "EPOCH 3694  (with max 8000), loss: 0.06925538927316666\n",
      "train time for 3694 epochs, was 3043.386942625046\n",
      "\n",
      "EPOCH 3696  (with max 8000), loss: 0.005682496819645166\n",
      "train time for 3696 epochs, was 3045.0208044052124\n",
      "\n",
      "EPOCH 3698  (with max 8000), loss: 0.0075367521494627\n",
      "train time for 3698 epochs, was 3046.658993959427\n",
      "\n",
      "EPOCH 3700  (with max 8000), loss: 0.005418416578322649\n",
      "train time for 3700 epochs, was 3048.2930886745453\n",
      "\n",
      "EPOCH 3702  (with max 8000), loss: 0.017952941358089447\n",
      "train time for 3702 epochs, was 3049.9293422698975\n",
      "\n",
      "EPOCH 3704  (with max 8000), loss: 0.0022672766353935003\n",
      "train time for 3704 epochs, was 3051.5633869171143\n",
      "\n",
      "EPOCH 3706  (with max 8000), loss: 0.007092521991580725\n",
      "train time for 3706 epochs, was 3053.1973671913147\n",
      "\n",
      "EPOCH 3708  (with max 8000), loss: 0.0101825762540102\n",
      "train time for 3708 epochs, was 3054.8313372135162\n",
      "\n",
      "EPOCH 3710  (with max 8000), loss: 0.0046113054268062115\n",
      "train time for 3710 epochs, was 3056.46529173851\n",
      "\n",
      "EPOCH 3712  (with max 8000), loss: 0.003115844912827015\n",
      "train time for 3712 epochs, was 3058.0992028713226\n",
      "\n",
      "EPOCH 3714  (with max 8000), loss: 0.005158158019185066\n",
      "train time for 3714 epochs, was 3059.735277414322\n",
      "\n",
      "EPOCH 3716  (with max 8000), loss: 0.0044313049875199795\n",
      "train time for 3716 epochs, was 3061.369364500046\n",
      "\n",
      "EPOCH 3718  (with max 8000), loss: 0.005014386959373951\n",
      "train time for 3718 epochs, was 3063.003562450409\n",
      "\n",
      "EPOCH 3720  (with max 8000), loss: 0.0010424909414723516\n",
      "train time for 3720 epochs, was 3064.637498855591\n",
      "\n",
      "EPOCH 3722  (with max 8000), loss: 0.005083439871668816\n",
      "train time for 3722 epochs, was 3066.2713494300842\n",
      "\n",
      "EPOCH 3724  (with max 8000), loss: 0.004998556338250637\n",
      "train time for 3724 epochs, was 3067.905418395996\n",
      "\n",
      "EPOCH 3726  (with max 8000), loss: 0.0035201816353946924\n",
      "train time for 3726 epochs, was 3069.5393748283386\n",
      "\n",
      "EPOCH 3728  (with max 8000), loss: 0.0014110311167314649\n",
      "train time for 3728 epochs, was 3071.2023911476135\n",
      "\n",
      "EPOCH 3730  (with max 8000), loss: 0.0027998420409858227\n",
      "train time for 3730 epochs, was 3072.8405678272247\n",
      "\n",
      "EPOCH 3732  (with max 8000), loss: 0.006867946125566959\n",
      "train time for 3732 epochs, was 3074.4745857715607\n",
      "\n",
      "EPOCH 3734  (with max 8000), loss: 0.003093296429142356\n",
      "train time for 3734 epochs, was 3076.1084401607513\n",
      "\n",
      "EPOCH 3736  (with max 8000), loss: 0.0019896426238119602\n",
      "train time for 3736 epochs, was 3077.7424511909485\n",
      "\n",
      "EPOCH 3738  (with max 8000), loss: 0.0029887023847550154\n",
      "train time for 3738 epochs, was 3079.37632894516\n",
      "\n",
      "EPOCH 3740  (with max 8000), loss: 0.0015204587252810597\n",
      "train time for 3740 epochs, was 3081.0102298259735\n",
      "\n",
      "EPOCH 3742  (with max 8000), loss: 0.0014218136202543974\n",
      "train time for 3742 epochs, was 3082.6441445350647\n",
      "\n",
      "EPOCH 3744  (with max 8000), loss: 0.004701525438576937\n",
      "train time for 3744 epochs, was 3084.2782747745514\n",
      "\n",
      "EPOCH 3746  (with max 8000), loss: 0.003486217465251684\n",
      "train time for 3746 epochs, was 3085.912315607071\n",
      "\n",
      "EPOCH 3748  (with max 8000), loss: 0.002175566740334034\n",
      "train time for 3748 epochs, was 3087.5461616516113\n",
      "\n",
      "EPOCH 3750  (with max 8000), loss: 0.0013114301254972816\n",
      "train time for 3750 epochs, was 3089.180088996887\n",
      "\n",
      "EPOCH 3752  (with max 8000), loss: 0.0031097359023988247\n",
      "train time for 3752 epochs, was 3090.8139305114746\n",
      "\n",
      "EPOCH 3754  (with max 8000), loss: 0.0023914040066301823\n",
      "train time for 3754 epochs, was 3092.4478199481964\n",
      "\n",
      "EPOCH 3756  (with max 8000), loss: 0.0031461617909371853\n",
      "train time for 3756 epochs, was 3094.081737756729\n",
      "\n",
      "EPOCH 3758  (with max 8000), loss: 0.0041629173792898655\n",
      "train time for 3758 epochs, was 3095.7158784866333\n",
      "\n",
      "EPOCH 3760  (with max 8000), loss: 0.010650675743818283\n",
      "train time for 3760 epochs, was 3097.3497178554535\n",
      "\n",
      "EPOCH 3762  (with max 8000), loss: 0.008435753174126148\n",
      "train time for 3762 epochs, was 3098.9835262298584\n",
      "\n",
      "EPOCH 3764  (with max 8000), loss: 0.00295341107994318\n",
      "train time for 3764 epochs, was 3100.6174988746643\n",
      "\n",
      "EPOCH 3766  (with max 8000), loss: 0.0040277354419231415\n",
      "train time for 3766 epochs, was 3102.25133061409\n",
      "\n",
      "EPOCH 3768  (with max 8000), loss: 0.1907084584236145\n",
      "train time for 3768 epochs, was 3103.8854365348816\n",
      "\n",
      "EPOCH 3770  (with max 8000), loss: 0.03948897868394852\n",
      "train time for 3770 epochs, was 3105.5362734794617\n",
      "\n",
      "EPOCH 3772  (with max 8000), loss: 0.007939450442790985\n",
      "train time for 3772 epochs, was 3107.1702728271484\n",
      "\n",
      "EPOCH 3774  (with max 8000), loss: 0.00951122771948576\n",
      "train time for 3774 epochs, was 3108.8042962551117\n",
      "\n",
      "EPOCH 3776  (with max 8000), loss: 0.005214642267674208\n",
      "train time for 3776 epochs, was 3110.4384305477142\n",
      "\n",
      "EPOCH 3778  (with max 8000), loss: 0.0036042905412614346\n",
      "train time for 3778 epochs, was 3112.072609901428\n",
      "\n",
      "EPOCH 3780  (with max 8000), loss: 0.07178564369678497\n",
      "train time for 3780 epochs, was 3113.706731081009\n",
      "\n",
      "EPOCH 3782  (with max 8000), loss: 0.046373508870601654\n",
      "train time for 3782 epochs, was 3115.3406224250793\n",
      "\n",
      "EPOCH 3784  (with max 8000), loss: 0.044745657593011856\n",
      "train time for 3784 epochs, was 3116.9745473861694\n",
      "\n",
      "EPOCH 3786  (with max 8000), loss: 0.034097909927368164\n",
      "train time for 3786 epochs, was 3118.608641386032\n",
      "\n",
      "EPOCH 3788  (with max 8000), loss: 0.00920779537409544\n",
      "train time for 3788 epochs, was 3120.2428679466248\n",
      "\n",
      "EPOCH 3790  (with max 8000), loss: 0.005388045683503151\n",
      "train time for 3790 epochs, was 3121.8771154880524\n",
      "\n",
      "EPOCH 3792  (with max 8000), loss: 0.005644869990646839\n",
      "train time for 3792 epochs, was 3123.517547607422\n",
      "\n",
      "EPOCH 3794  (with max 8000), loss: 0.0036191910039633512\n",
      "train time for 3794 epochs, was 3125.153573513031\n",
      "\n",
      "EPOCH 3796  (with max 8000), loss: 0.006567604374140501\n",
      "train time for 3796 epochs, was 3126.789873123169\n",
      "\n",
      "EPOCH 3798  (with max 8000), loss: 0.002764476230368018\n",
      "train time for 3798 epochs, was 3128.4258284568787\n",
      "\n",
      "EPOCH 3800  (with max 8000), loss: 0.002874106867238879\n",
      "train time for 3800 epochs, was 3130.0599677562714\n",
      "\n",
      "EPOCH 3800 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_3800.pth\n",
      "\n",
      "EPOCH 3802  (with max 8000), loss: 0.000753805332351476\n",
      "train time for 3802 epochs, was 3131.7316052913666\n",
      "\n",
      "EPOCH 3804  (with max 8000), loss: 0.004344401881098747\n",
      "train time for 3804 epochs, was 3133.3699526786804\n",
      "\n",
      "EPOCH 3806  (with max 8000), loss: 0.0033899990376085043\n",
      "train time for 3806 epochs, was 3135.0185465812683\n",
      "\n",
      "EPOCH 3808  (with max 8000), loss: 0.00249212677590549\n",
      "train time for 3808 epochs, was 3136.652366399765\n",
      "\n",
      "EPOCH 3810  (with max 8000), loss: 0.014948464930057526\n",
      "train time for 3810 epochs, was 3138.2863342761993\n",
      "\n",
      "EPOCH 3812  (with max 8000), loss: 0.0034748432226479053\n",
      "train time for 3812 epochs, was 3139.920312166214\n",
      "\n",
      "EPOCH 3814  (with max 8000), loss: 0.00363759882748127\n",
      "train time for 3814 epochs, was 3141.554131746292\n",
      "\n",
      "EPOCH 3816  (with max 8000), loss: 0.008073884062469006\n",
      "train time for 3816 epochs, was 3143.2004363536835\n",
      "\n",
      "EPOCH 3818  (with max 8000), loss: 0.0019838048610836267\n",
      "train time for 3818 epochs, was 3144.8342683315277\n",
      "\n",
      "EPOCH 3820  (with max 8000), loss: 0.0021403594873845577\n",
      "train time for 3820 epochs, was 3146.4682698249817\n",
      "\n",
      "EPOCH 3822  (with max 8000), loss: 0.0015952209942042828\n",
      "train time for 3822 epochs, was 3148.102208375931\n",
      "\n",
      "EPOCH 3824  (with max 8000), loss: 0.0007837614393793046\n",
      "train time for 3824 epochs, was 3149.7361011505127\n",
      "\n",
      "EPOCH 3826  (with max 8000), loss: 0.0027270594146102667\n",
      "train time for 3826 epochs, was 3151.3741488456726\n",
      "\n",
      "EPOCH 3828  (with max 8000), loss: 0.004180632997304201\n",
      "train time for 3828 epochs, was 3153.010117292404\n",
      "\n",
      "EPOCH 3830  (with max 8000), loss: 0.00281185912899673\n",
      "train time for 3830 epochs, was 3154.6439847946167\n",
      "\n",
      "EPOCH 3832  (with max 8000), loss: 0.002799292793497443\n",
      "train time for 3832 epochs, was 3156.282176733017\n",
      "\n",
      "EPOCH 3834  (with max 8000), loss: 0.002505925251170993\n",
      "train time for 3834 epochs, was 3157.9180154800415\n",
      "\n",
      "EPOCH 3836  (with max 8000), loss: 0.0045901392586529255\n",
      "train time for 3836 epochs, was 3159.5518929958344\n",
      "\n",
      "EPOCH 3838  (with max 8000), loss: 0.007868348620831966\n",
      "train time for 3838 epochs, was 3161.1876969337463\n",
      "\n",
      "EPOCH 3840  (with max 8000), loss: 0.010031265206634998\n",
      "train time for 3840 epochs, was 3162.821710586548\n",
      "\n",
      "EPOCH 3842  (with max 8000), loss: 0.0035719822626560926\n",
      "train time for 3842 epochs, was 3164.45982837677\n",
      "\n",
      "EPOCH 3844  (with max 8000), loss: 0.0012454226380214095\n",
      "train time for 3844 epochs, was 3166.104227542877\n",
      "\n",
      "EPOCH 3846  (with max 8000), loss: 0.0050615244545042515\n",
      "train time for 3846 epochs, was 3167.7382278442383\n",
      "\n",
      "EPOCH 3848  (with max 8000), loss: 0.0032751583494246006\n",
      "train time for 3848 epochs, was 3169.37224817276\n",
      "\n",
      "EPOCH 3850  (with max 8000), loss: 0.003430294804275036\n",
      "train time for 3850 epochs, was 3171.0062730312347\n",
      "\n",
      "EPOCH 3852  (with max 8000), loss: 0.0023724259808659554\n",
      "train time for 3852 epochs, was 3172.6401419639587\n",
      "\n",
      "EPOCH 3854  (with max 8000), loss: 0.006211656611412764\n",
      "train time for 3854 epochs, was 3174.27423453331\n",
      "\n",
      "EPOCH 3856  (with max 8000), loss: 0.0920712947845459\n",
      "train time for 3856 epochs, was 3175.908132314682\n",
      "\n",
      "EPOCH 3858  (with max 8000), loss: 0.018810054287314415\n",
      "train time for 3858 epochs, was 3177.5422039031982\n",
      "\n",
      "EPOCH 3860  (with max 8000), loss: 0.007785945665091276\n",
      "train time for 3860 epochs, was 3179.1761384010315\n",
      "\n",
      "EPOCH 3862  (with max 8000), loss: 0.11519384384155273\n",
      "train time for 3862 epochs, was 3180.8267221450806\n",
      "\n",
      "EPOCH 3864  (with max 8000), loss: 0.019399285316467285\n",
      "train time for 3864 epochs, was 3182.4607605934143\n",
      "\n",
      "EPOCH 3866  (with max 8000), loss: 0.11126687377691269\n",
      "train time for 3866 epochs, was 3184.0947575569153\n",
      "\n",
      "EPOCH 3868  (with max 8000), loss: 0.027606002986431122\n",
      "train time for 3868 epochs, was 3185.728665113449\n",
      "\n",
      "EPOCH 3870  (with max 8000), loss: 0.016630833968520164\n",
      "train time for 3870 epochs, was 3187.3646874427795\n",
      "\n",
      "EPOCH 3872  (with max 8000), loss: 0.0073894355446100235\n",
      "train time for 3872 epochs, was 3188.9984595775604\n",
      "\n",
      "EPOCH 3874  (with max 8000), loss: 0.003642989555373788\n",
      "train time for 3874 epochs, was 3190.6324474811554\n",
      "\n",
      "EPOCH 3876  (with max 8000), loss: 0.006944150663912296\n",
      "train time for 3876 epochs, was 3192.272719860077\n",
      "\n",
      "EPOCH 3878  (with max 8000), loss: 0.005349419079720974\n",
      "train time for 3878 epochs, was 3193.9066689014435\n",
      "\n",
      "EPOCH 3880  (with max 8000), loss: 0.006061091553419828\n",
      "train time for 3880 epochs, was 3195.5448389053345\n",
      "\n",
      "EPOCH 3882  (with max 8000), loss: 0.00353195215575397\n",
      "train time for 3882 epochs, was 3197.1912713050842\n",
      "\n",
      "EPOCH 3884  (with max 8000), loss: 0.006809531711041927\n",
      "train time for 3884 epochs, was 3198.8253121376038\n",
      "\n",
      "EPOCH 3886  (with max 8000), loss: 0.008129431866109371\n",
      "train time for 3886 epochs, was 3200.459132671356\n",
      "\n",
      "EPOCH 3888  (with max 8000), loss: 0.01101784035563469\n",
      "train time for 3888 epochs, was 3202.093029499054\n",
      "\n",
      "EPOCH 3890  (with max 8000), loss: 0.004541731905192137\n",
      "train time for 3890 epochs, was 3203.727093219757\n",
      "\n",
      "EPOCH 3892  (with max 8000), loss: 0.003483507549390197\n",
      "train time for 3892 epochs, was 3205.361319541931\n",
      "\n",
      "EPOCH 3894  (with max 8000), loss: 0.00791282020509243\n",
      "train time for 3894 epochs, was 3206.9973318576813\n",
      "\n",
      "EPOCH 3896  (with max 8000), loss: 0.0032627067994326353\n",
      "train time for 3896 epochs, was 3208.6311531066895\n",
      "\n",
      "EPOCH 3898  (with max 8000), loss: 0.002010837197303772\n",
      "train time for 3898 epochs, was 3210.271377325058\n",
      "\n",
      "EPOCH 3900  (with max 8000), loss: 0.014923077076673508\n",
      "train time for 3900 epochs, was 3211.907374858856\n",
      "\n",
      "EPOCH 3902  (with max 8000), loss: 0.011801189742982388\n",
      "train time for 3902 epochs, was 3213.54350566864\n",
      "\n",
      "EPOCH 3904  (with max 8000), loss: 0.004558028187602758\n",
      "train time for 3904 epochs, was 3215.179538965225\n",
      "\n",
      "EPOCH 3906  (with max 8000), loss: 0.015408273786306381\n",
      "train time for 3906 epochs, was 3216.8447840213776\n",
      "\n",
      "EPOCH 3908  (with max 8000), loss: 0.011787925846874714\n",
      "train time for 3908 epochs, was 3218.478828191757\n",
      "\n",
      "EPOCH 3910  (with max 8000), loss: 0.003334257286041975\n",
      "train time for 3910 epochs, was 3220.115108728409\n",
      "\n",
      "EPOCH 3912  (with max 8000), loss: 0.001984386006370187\n",
      "train time for 3912 epochs, was 3221.7489721775055\n",
      "\n",
      "EPOCH 3914  (with max 8000), loss: 0.002048893366008997\n",
      "train time for 3914 epochs, was 3223.3848853111267\n",
      "\n",
      "EPOCH 3916  (with max 8000), loss: 0.004934150259941816\n",
      "train time for 3916 epochs, was 3225.029153108597\n",
      "\n",
      "EPOCH 3918  (with max 8000), loss: 0.001667219796217978\n",
      "train time for 3918 epochs, was 3226.6652715206146\n",
      "\n",
      "EPOCH 3920  (with max 8000), loss: 0.0019522891379892826\n",
      "train time for 3920 epochs, was 3228.3100440502167\n",
      "\n",
      "EPOCH 3922  (with max 8000), loss: 0.0024419960100203753\n",
      "train time for 3922 epochs, was 3229.9460854530334\n",
      "\n",
      "EPOCH 3924  (with max 8000), loss: 0.0018116369610652328\n",
      "train time for 3924 epochs, was 3231.5882709026337\n",
      "\n",
      "EPOCH 3926  (with max 8000), loss: 0.004588447045534849\n",
      "train time for 3926 epochs, was 3233.222084760666\n",
      "\n",
      "EPOCH 3928  (with max 8000), loss: 0.003037875983864069\n",
      "train time for 3928 epochs, was 3234.856073141098\n",
      "\n",
      "EPOCH 3930  (with max 8000), loss: 0.004716434981673956\n",
      "train time for 3930 epochs, was 3236.490115880966\n",
      "\n",
      "EPOCH 3932  (with max 8000), loss: 0.007163948379456997\n",
      "train time for 3932 epochs, was 3238.1240248680115\n",
      "\n",
      "EPOCH 3934  (with max 8000), loss: 0.00022345248726196587\n",
      "train time for 3934 epochs, was 3239.757809638977\n",
      "\n",
      "EPOCH 3936  (with max 8000), loss: 0.0034090180415660143\n",
      "train time for 3936 epochs, was 3241.391967535019\n",
      "\n",
      "EPOCH 3938  (with max 8000), loss: 0.00831632036715746\n",
      "train time for 3938 epochs, was 3243.0260009765625\n",
      "\n",
      "EPOCH 3940  (with max 8000), loss: 0.8399257063865662\n",
      "train time for 3940 epochs, was 3244.6620366573334\n",
      "\n",
      "EPOCH 3942  (with max 8000), loss: 0.02254362963140011\n",
      "train time for 3942 epochs, was 3246.2960212230682\n",
      "\n",
      "EPOCH 3944  (with max 8000), loss: 0.06002182513475418\n",
      "train time for 3944 epochs, was 3247.929988384247\n",
      "\n",
      "EPOCH 3946  (with max 8000), loss: 0.030476361513137817\n",
      "train time for 3946 epochs, was 3249.564223051071\n",
      "\n",
      "EPOCH 3948  (with max 8000), loss: 0.028292575851082802\n",
      "train time for 3948 epochs, was 3251.1985070705414\n",
      "\n",
      "EPOCH 3950  (with max 8000), loss: 0.004773997236043215\n",
      "train time for 3950 epochs, was 3252.861763715744\n",
      "\n",
      "EPOCH 3952  (with max 8000), loss: 0.0059525975957512856\n",
      "train time for 3952 epochs, was 3254.4957268238068\n",
      "\n",
      "EPOCH 3954  (with max 8000), loss: 0.006477587390691042\n",
      "train time for 3954 epochs, was 3256.1298809051514\n",
      "\n",
      "EPOCH 3956  (with max 8000), loss: 0.0032927775755524635\n",
      "train time for 3956 epochs, was 3257.7659442424774\n",
      "\n",
      "EPOCH 3958  (with max 8000), loss: 0.00548121752217412\n",
      "train time for 3958 epochs, was 3259.4000425338745\n",
      "\n",
      "EPOCH 3960  (with max 8000), loss: 0.007062040269374847\n",
      "train time for 3960 epochs, was 3261.034138441086\n",
      "\n",
      "EPOCH 3962  (with max 8000), loss: 0.003530824091285467\n",
      "train time for 3962 epochs, was 3262.66828083992\n",
      "\n",
      "EPOCH 3964  (with max 8000), loss: 0.1769895702600479\n",
      "train time for 3964 epochs, was 3264.3022451400757\n",
      "\n",
      "EPOCH 3966  (with max 8000), loss: 0.02049732394516468\n",
      "train time for 3966 epochs, was 3265.94256067276\n",
      "\n",
      "EPOCH 3968  (with max 8000), loss: 0.010351702570915222\n",
      "train time for 3968 epochs, was 3267.5789411067963\n",
      "\n",
      "EPOCH 3970  (with max 8000), loss: 0.0018717602360993624\n",
      "train time for 3970 epochs, was 3269.225875854492\n",
      "\n",
      "EPOCH 3972  (with max 8000), loss: 0.009651429951190948\n",
      "train time for 3972 epochs, was 3270.862199306488\n",
      "\n",
      "EPOCH 3974  (with max 8000), loss: 0.019542448222637177\n",
      "train time for 3974 epochs, was 3272.4963793754578\n",
      "\n",
      "EPOCH 3976  (with max 8000), loss: 0.013689283281564713\n",
      "train time for 3976 epochs, was 3274.130607366562\n",
      "\n",
      "EPOCH 3978  (with max 8000), loss: 0.06092080473899841\n",
      "train time for 3978 epochs, was 3275.7647297382355\n",
      "\n",
      "EPOCH 3980  (with max 8000), loss: 0.023661237210035324\n",
      "train time for 3980 epochs, was 3277.3990383148193\n",
      "\n",
      "EPOCH 3982  (with max 8000), loss: 0.013537555932998657\n",
      "train time for 3982 epochs, was 3279.033315896988\n",
      "\n",
      "EPOCH 3984  (with max 8000), loss: 0.008922487497329712\n",
      "train time for 3984 epochs, was 3280.667798757553\n",
      "\n",
      "EPOCH 3986  (with max 8000), loss: 0.006047865841537714\n",
      "train time for 3986 epochs, was 3282.302210330963\n",
      "\n",
      "EPOCH 3988  (with max 8000), loss: 0.00834705587476492\n",
      "train time for 3988 epochs, was 3283.9363918304443\n",
      "\n",
      "EPOCH 3990  (with max 8000), loss: 0.007642545737326145\n",
      "train time for 3990 epochs, was 3285.5708196163177\n",
      "\n",
      "EPOCH 3992  (with max 8000), loss: 0.004105160478502512\n",
      "train time for 3992 epochs, was 3287.2114613056183\n",
      "\n",
      "EPOCH 3994  (with max 8000), loss: 0.0076032294891774654\n",
      "train time for 3994 epochs, was 3288.8518764972687\n",
      "\n",
      "EPOCH 3996  (with max 8000), loss: 0.008126038126647472\n",
      "train time for 3996 epochs, was 3290.4863958358765\n",
      "\n",
      "EPOCH 3998  (with max 8000), loss: 0.005695453379303217\n",
      "train time for 3998 epochs, was 3292.120838403702\n",
      "\n",
      "EPOCH 4000  (with max 8000), loss: 0.007403584197163582\n",
      "train time for 4000 epochs, was 3293.7550394535065\n",
      "\n",
      "EPOCH 4000 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_4000.pth\n",
      "\n",
      "EPOCH 4002  (with max 8000), loss: 0.0012510416563600302\n",
      "train time for 4002 epochs, was 3295.4228789806366\n",
      "\n",
      "EPOCH 4004  (with max 8000), loss: 0.003878321498632431\n",
      "train time for 4004 epochs, was 3297.0571258068085\n",
      "\n",
      "EPOCH 4006  (with max 8000), loss: 0.003608137834817171\n",
      "train time for 4006 epochs, was 3298.6975531578064\n",
      "\n",
      "EPOCH 4008  (with max 8000), loss: 0.001957519445568323\n",
      "train time for 4008 epochs, was 3300.3337695598602\n",
      "\n",
      "EPOCH 4010  (with max 8000), loss: 0.0051012043841183186\n",
      "train time for 4010 epochs, was 3301.9762053489685\n",
      "\n",
      "EPOCH 4012  (with max 8000), loss: 0.007486867252737284\n",
      "train time for 4012 epochs, was 3303.610307455063\n",
      "\n",
      "EPOCH 4014  (with max 8000), loss: 0.00279901921749115\n",
      "train time for 4014 epochs, was 3305.24449801445\n",
      "\n",
      "EPOCH 4016  (with max 8000), loss: 0.005085613112896681\n",
      "train time for 4016 epochs, was 3306.8787693977356\n",
      "\n",
      "EPOCH 4018  (with max 8000), loss: 0.05359438806772232\n",
      "train time for 4018 epochs, was 3308.5128564834595\n",
      "\n",
      "EPOCH 4020  (with max 8000), loss: 0.03599608317017555\n",
      "train time for 4020 epochs, was 3310.146968603134\n",
      "\n",
      "EPOCH 4022  (with max 8000), loss: 0.00754128210246563\n",
      "train time for 4022 epochs, was 3311.7813692092896\n",
      "\n",
      "EPOCH 4024  (with max 8000), loss: 0.0074506280943751335\n",
      "train time for 4024 epochs, was 3313.415924549103\n",
      "\n",
      "EPOCH 4026  (with max 8000), loss: 0.010586203075945377\n",
      "train time for 4026 epochs, was 3315.052265882492\n",
      "\n",
      "EPOCH 4028  (with max 8000), loss: 0.009171967394649982\n",
      "train time for 4028 epochs, was 3316.6885240077972\n",
      "\n",
      "EPOCH 4030  (with max 8000), loss: 0.008133115246891975\n",
      "train time for 4030 epochs, was 3318.3229444026947\n",
      "\n",
      "EPOCH 4032  (with max 8000), loss: 0.003826605388894677\n",
      "train time for 4032 epochs, was 3319.961587667465\n",
      "\n",
      "EPOCH 4034  (with max 8000), loss: 0.008352376520633698\n",
      "train time for 4034 epochs, was 3321.596004009247\n",
      "\n",
      "EPOCH 4036  (with max 8000), loss: 0.003709913929924369\n",
      "train time for 4036 epochs, was 3323.230302095413\n",
      "\n",
      "EPOCH 4038  (with max 8000), loss: 0.004557842388749123\n",
      "train time for 4038 epochs, was 3324.8791964054108\n",
      "\n",
      "EPOCH 4040  (with max 8000), loss: 0.003401209833100438\n",
      "train time for 4040 epochs, was 3326.5135459899902\n",
      "\n",
      "EPOCH 4042  (with max 8000), loss: 0.0033336409833282232\n",
      "train time for 4042 epochs, was 3328.1480576992035\n",
      "\n",
      "EPOCH 4044  (with max 8000), loss: 0.004654940217733383\n",
      "train time for 4044 epochs, was 3329.7823667526245\n",
      "\n",
      "EPOCH 4046  (with max 8000), loss: 0.004369967617094517\n",
      "train time for 4046 epochs, was 3331.427062034607\n",
      "\n",
      "EPOCH 4048  (with max 8000), loss: 0.0035193937364965677\n",
      "train time for 4048 epochs, was 3333.0614895820618\n",
      "\n",
      "EPOCH 4050  (with max 8000), loss: 0.0012054928811267018\n",
      "train time for 4050 epochs, was 3334.6960122585297\n",
      "\n",
      "EPOCH 4052  (with max 8000), loss: 0.0018390872282907367\n",
      "train time for 4052 epochs, was 3336.3303887844086\n",
      "\n",
      "EPOCH 4054  (with max 8000), loss: 0.00550105981528759\n",
      "train time for 4054 epochs, was 3337.964862346649\n",
      "\n",
      "EPOCH 4056  (with max 8000), loss: 0.0012423255247995257\n",
      "train time for 4056 epochs, was 3339.599051475525\n",
      "\n",
      "EPOCH 4058  (with max 8000), loss: 0.007220368832349777\n",
      "train time for 4058 epochs, was 3341.2333619594574\n",
      "\n",
      "EPOCH 4060  (with max 8000), loss: 0.004070660565048456\n",
      "train time for 4060 epochs, was 3342.867834329605\n",
      "\n",
      "EPOCH 4062  (with max 8000), loss: 0.004000188782811165\n",
      "train time for 4062 epochs, was 3344.5021317005157\n",
      "\n",
      "EPOCH 4064  (with max 8000), loss: 0.00434098532423377\n",
      "train time for 4064 epochs, was 3346.138531446457\n",
      "\n",
      "EPOCH 4066  (with max 8000), loss: 0.0009088744409382343\n",
      "train time for 4066 epochs, was 3347.7748692035675\n",
      "\n",
      "EPOCH 4068  (with max 8000), loss: 0.0018064320320263505\n",
      "train time for 4068 epochs, was 3349.409478187561\n",
      "\n",
      "EPOCH 4070  (with max 8000), loss: 0.0016806472558528185\n",
      "train time for 4070 epochs, was 3351.043834924698\n",
      "\n",
      "EPOCH 4072  (with max 8000), loss: 0.0026098936796188354\n",
      "train time for 4072 epochs, was 3352.678023338318\n",
      "\n",
      "EPOCH 4074  (with max 8000), loss: 0.004082202445715666\n",
      "train time for 4074 epochs, was 3354.3145525455475\n",
      "\n",
      "EPOCH 4076  (with max 8000), loss: 0.0025186161510646343\n",
      "train time for 4076 epochs, was 3355.9488377571106\n",
      "\n",
      "EPOCH 4078  (with max 8000), loss: 0.03265384957194328\n",
      "train time for 4078 epochs, was 3357.58309006691\n",
      "\n",
      "EPOCH 4080  (with max 8000), loss: 0.015100352466106415\n",
      "train time for 4080 epochs, was 3359.2195835113525\n",
      "\n",
      "EPOCH 4082  (with max 8000), loss: 0.010496883653104305\n",
      "train time for 4082 epochs, was 3360.8558599948883\n",
      "\n",
      "EPOCH 4084  (with max 8000), loss: 0.0037438797298818827\n",
      "train time for 4084 epochs, was 3362.4965693950653\n",
      "\n",
      "EPOCH 4086  (with max 8000), loss: 0.0032560648396611214\n",
      "train time for 4086 epochs, was 3364.131098508835\n",
      "\n",
      "EPOCH 4088  (with max 8000), loss: 0.13828341662883759\n",
      "train time for 4088 epochs, was 3365.765514612198\n",
      "\n",
      "EPOCH 4090  (with max 8000), loss: 0.1760176122188568\n",
      "train time for 4090 epochs, was 3367.399754047394\n",
      "\n",
      "EPOCH 4092  (with max 8000), loss: 0.04941663146018982\n",
      "train time for 4092 epochs, was 3369.034002304077\n",
      "\n",
      "EPOCH 4094  (with max 8000), loss: 0.03584212064743042\n",
      "train time for 4094 epochs, was 3370.672745704651\n",
      "\n",
      "EPOCH 4096  (with max 8000), loss: 0.046211738139390945\n",
      "train time for 4096 epochs, was 3372.3096599578857\n",
      "\n",
      "EPOCH 4098  (with max 8000), loss: 0.009832348674535751\n",
      "train time for 4098 epochs, was 3373.9443469047546\n",
      "\n",
      "EPOCH 4100  (with max 8000), loss: 0.009209033101797104\n",
      "train time for 4100 epochs, was 3375.578820705414\n",
      "\n",
      "EPOCH 4102  (with max 8000), loss: 0.00865891668945551\n",
      "train time for 4102 epochs, was 3377.2133243083954\n",
      "\n",
      "EPOCH 4104  (with max 8000), loss: 0.006547562312334776\n",
      "train time for 4104 epochs, was 3378.8497717380524\n",
      "\n",
      "EPOCH 4106  (with max 8000), loss: 0.0071336315013468266\n",
      "train time for 4106 epochs, was 3380.484051465988\n",
      "\n",
      "EPOCH 4108  (with max 8000), loss: 0.004841586574912071\n",
      "train time for 4108 epochs, was 3382.1183478832245\n",
      "\n",
      "EPOCH 4110  (with max 8000), loss: 0.011646414175629616\n",
      "train time for 4110 epochs, was 3383.7526936531067\n",
      "\n",
      "EPOCH 4112  (with max 8000), loss: 0.0063906945288181305\n",
      "train time for 4112 epochs, was 3385.3891780376434\n",
      "\n",
      "EPOCH 4114  (with max 8000), loss: 0.00416302727535367\n",
      "train time for 4114 epochs, was 3387.0255217552185\n",
      "\n",
      "EPOCH 4116  (with max 8000), loss: 0.0037633893080055714\n",
      "train time for 4116 epochs, was 3388.6597435474396\n",
      "\n",
      "EPOCH 4118  (with max 8000), loss: 0.010195459239184856\n",
      "train time for 4118 epochs, was 3390.2939128875732\n",
      "\n",
      "EPOCH 4120  (with max 8000), loss: 0.003511236747726798\n",
      "train time for 4120 epochs, was 3391.92835187912\n",
      "\n",
      "EPOCH 4122  (with max 8000), loss: 0.008764640428125858\n",
      "train time for 4122 epochs, was 3393.562467813492\n",
      "\n",
      "EPOCH 4124  (with max 8000), loss: 0.0010129105066880584\n",
      "train time for 4124 epochs, was 3395.1964864730835\n",
      "\n",
      "EPOCH 4126  (with max 8000), loss: 0.0036204142961651087\n",
      "train time for 4126 epochs, was 3396.8578383922577\n",
      "\n",
      "EPOCH 4128  (with max 8000), loss: 0.009092843160033226\n",
      "train time for 4128 epochs, was 3398.4920847415924\n",
      "\n",
      "EPOCH 4130  (with max 8000), loss: 0.003522810060530901\n",
      "train time for 4130 epochs, was 3400.1263790130615\n",
      "\n",
      "EPOCH 4132  (with max 8000), loss: 0.002714174799621105\n",
      "train time for 4132 epochs, was 3401.760596513748\n",
      "\n",
      "EPOCH 4134  (with max 8000), loss: 0.004273082595318556\n",
      "train time for 4134 epochs, was 3403.3948216438293\n",
      "\n",
      "EPOCH 4136  (with max 8000), loss: 0.0036481607239693403\n",
      "train time for 4136 epochs, was 3405.0292468070984\n",
      "\n",
      "EPOCH 4138  (with max 8000), loss: 0.0017065820284187794\n",
      "train time for 4138 epochs, was 3406.6636669635773\n",
      "\n",
      "EPOCH 4140  (with max 8000), loss: 0.0024152046535164118\n",
      "train time for 4140 epochs, was 3408.300240278244\n",
      "\n",
      "EPOCH 4142  (with max 8000), loss: 0.006520316936075687\n",
      "train time for 4142 epochs, was 3409.940988302231\n",
      "\n",
      "EPOCH 4144  (with max 8000), loss: 0.009999541565775871\n",
      "train time for 4144 epochs, was 3411.5752923488617\n",
      "\n",
      "EPOCH 4146  (with max 8000), loss: 0.025085099041461945\n",
      "train time for 4146 epochs, was 3413.2118005752563\n",
      "\n",
      "EPOCH 4148  (with max 8000), loss: 0.012974713928997517\n",
      "train time for 4148 epochs, was 3414.845905303955\n",
      "\n",
      "EPOCH 4150  (with max 8000), loss: 0.005416407249867916\n",
      "train time for 4150 epochs, was 3416.4822821617126\n",
      "\n",
      "EPOCH 4152  (with max 8000), loss: 0.007722389418631792\n",
      "train time for 4152 epochs, was 3418.118673324585\n",
      "\n",
      "EPOCH 4154  (with max 8000), loss: 0.007316935807466507\n",
      "train time for 4154 epochs, was 3419.7530629634857\n",
      "\n",
      "EPOCH 4156  (with max 8000), loss: 0.003935713786631823\n",
      "train time for 4156 epochs, was 3421.4044604301453\n",
      "\n",
      "EPOCH 4158  (with max 8000), loss: 0.08325138688087463\n",
      "train time for 4158 epochs, was 3423.0426008701324\n",
      "\n",
      "EPOCH 4160  (with max 8000), loss: 0.011980289593338966\n",
      "train time for 4160 epochs, was 3424.679020166397\n",
      "\n",
      "EPOCH 4162  (with max 8000), loss: 0.03320375457406044\n",
      "train time for 4162 epochs, was 3426.3131396770477\n",
      "\n",
      "EPOCH 4164  (with max 8000), loss: 0.007687362842261791\n",
      "train time for 4164 epochs, was 3427.9515013694763\n",
      "\n",
      "EPOCH 4166  (with max 8000), loss: 0.008952622301876545\n",
      "train time for 4166 epochs, was 3429.587767601013\n",
      "\n",
      "EPOCH 4168  (with max 8000), loss: 0.00892859511077404\n",
      "train time for 4168 epochs, was 3431.2241847515106\n",
      "\n",
      "EPOCH 4170  (with max 8000), loss: 0.004272552207112312\n",
      "train time for 4170 epochs, was 3432.858402490616\n",
      "\n",
      "EPOCH 4172  (with max 8000), loss: 0.010905521921813488\n",
      "train time for 4172 epochs, was 3434.513738155365\n",
      "\n",
      "EPOCH 4174  (with max 8000), loss: 0.0019248288590461016\n",
      "train time for 4174 epochs, was 3436.148170232773\n",
      "\n",
      "EPOCH 4176  (with max 8000), loss: 0.004659159574657679\n",
      "train time for 4176 epochs, was 3437.786631822586\n",
      "\n",
      "EPOCH 4178  (with max 8000), loss: 0.006131540983915329\n",
      "train time for 4178 epochs, was 3439.4232296943665\n",
      "\n",
      "EPOCH 4180  (with max 8000), loss: 0.005184714216738939\n",
      "train time for 4180 epochs, was 3441.057547569275\n",
      "\n",
      "EPOCH 4182  (with max 8000), loss: 0.022038530558347702\n",
      "train time for 4182 epochs, was 3442.692037343979\n",
      "\n",
      "EPOCH 4184  (with max 8000), loss: 0.010651485994458199\n",
      "train time for 4184 epochs, was 3444.3283383846283\n",
      "\n",
      "EPOCH 4186  (with max 8000), loss: 0.010446477681398392\n",
      "train time for 4186 epochs, was 3445.962589740753\n",
      "\n",
      "EPOCH 4188  (with max 8000), loss: 0.010614815168082714\n",
      "train time for 4188 epochs, was 3447.609549999237\n",
      "\n",
      "EPOCH 4190  (with max 8000), loss: 0.003959870431572199\n",
      "train time for 4190 epochs, was 3449.2461144924164\n",
      "\n",
      "EPOCH 4192  (with max 8000), loss: 0.0018388287862762809\n",
      "train time for 4192 epochs, was 3450.880441904068\n",
      "\n",
      "EPOCH 4194  (with max 8000), loss: 0.010426702909171581\n",
      "train time for 4194 epochs, was 3452.5147337913513\n",
      "\n",
      "EPOCH 4196  (with max 8000), loss: 0.0042225816287100315\n",
      "train time for 4196 epochs, was 3454.148927927017\n",
      "\n",
      "EPOCH 4198  (with max 8000), loss: 0.0029536387883126736\n",
      "train time for 4198 epochs, was 3455.782992362976\n",
      "\n",
      "EPOCH 4200  (with max 8000), loss: 0.002724198391661048\n",
      "train time for 4200 epochs, was 3457.4173645973206\n",
      "\n",
      "EPOCH 4200 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_4200.pth\n",
      "\n",
      "EPOCH 4202  (with max 8000), loss: 0.0022648628801107407\n",
      "train time for 4202 epochs, was 3459.0873215198517\n",
      "\n",
      "EPOCH 4204  (with max 8000), loss: 0.0014314072905108333\n",
      "train time for 4204 epochs, was 3460.7341768741608\n",
      "\n",
      "EPOCH 4206  (with max 8000), loss: 0.003960037603974342\n",
      "train time for 4206 epochs, was 3462.3809492588043\n",
      "\n",
      "EPOCH 4208  (with max 8000), loss: 0.0017725761281326413\n",
      "train time for 4208 epochs, was 3464.0173251628876\n",
      "\n",
      "EPOCH 4210  (with max 8000), loss: 0.0033933466766029596\n",
      "train time for 4210 epochs, was 3465.6557013988495\n",
      "\n",
      "EPOCH 4212  (with max 8000), loss: 0.008836462162435055\n",
      "train time for 4212 epochs, was 3467.2899780273438\n",
      "\n",
      "EPOCH 4214  (with max 8000), loss: 0.006082996726036072\n",
      "train time for 4214 epochs, was 3468.926359653473\n",
      "\n",
      "EPOCH 4216  (with max 8000), loss: 0.00650784932076931\n",
      "train time for 4216 epochs, was 3470.562942504883\n",
      "\n",
      "EPOCH 4218  (with max 8000), loss: 0.0015716477064415812\n",
      "train time for 4218 epochs, was 3472.2076966762543\n",
      "\n",
      "EPOCH 4220  (with max 8000), loss: 0.05263560265302658\n",
      "train time for 4220 epochs, was 3473.843986749649\n",
      "\n",
      "EPOCH 4222  (with max 8000), loss: 0.020736372098326683\n",
      "train time for 4222 epochs, was 3475.482458591461\n",
      "\n",
      "EPOCH 4224  (with max 8000), loss: 0.005224942229688168\n",
      "train time for 4224 epochs, was 3477.121105194092\n",
      "\n",
      "EPOCH 4226  (with max 8000), loss: 0.001912803971208632\n",
      "train time for 4226 epochs, was 3478.7638018131256\n",
      "\n",
      "EPOCH 4228  (with max 8000), loss: 0.0074788969941437244\n",
      "train time for 4228 epochs, was 3480.404355287552\n",
      "\n",
      "EPOCH 4230  (with max 8000), loss: 0.004165503662079573\n",
      "train time for 4230 epochs, was 3482.0470321178436\n",
      "\n",
      "EPOCH 4232  (with max 8000), loss: 0.004095887765288353\n",
      "train time for 4232 epochs, was 3483.68115067482\n",
      "\n",
      "EPOCH 4234  (with max 8000), loss: 0.0035413065925240517\n",
      "train time for 4234 epochs, was 3485.3154606819153\n",
      "\n",
      "EPOCH 4236  (with max 8000), loss: 0.005049905274063349\n",
      "train time for 4236 epochs, was 3486.9559996128082\n",
      "\n",
      "EPOCH 4238  (with max 8000), loss: 0.015140973031520844\n",
      "train time for 4238 epochs, was 3488.5900886058807\n",
      "\n",
      "EPOCH 4240  (with max 8000), loss: 0.017442090436816216\n",
      "train time for 4240 epochs, was 3490.2245144844055\n",
      "\n",
      "EPOCH 4242  (with max 8000), loss: 0.011268297210335732\n",
      "train time for 4242 epochs, was 3491.858674287796\n",
      "\n",
      "EPOCH 4244  (with max 8000), loss: 0.008220743387937546\n",
      "train time for 4244 epochs, was 3493.4930930137634\n",
      "\n",
      "EPOCH 4246  (with max 8000), loss: 0.006981265731155872\n",
      "train time for 4246 epochs, was 3495.127243757248\n",
      "\n",
      "EPOCH 4248  (with max 8000), loss: 0.012148206122219563\n",
      "train time for 4248 epochs, was 3496.761494398117\n",
      "\n",
      "EPOCH 4250  (with max 8000), loss: 0.0058791846968233585\n",
      "train time for 4250 epochs, was 3498.395842552185\n",
      "\n",
      "EPOCH 4252  (with max 8000), loss: 0.0036833579652011395\n",
      "train time for 4252 epochs, was 3500.0302877426147\n",
      "\n",
      "EPOCH 4254  (with max 8000), loss: 0.002018313156440854\n",
      "train time for 4254 epochs, was 3501.664738178253\n",
      "\n",
      "EPOCH 4256  (with max 8000), loss: 0.0007745503098703921\n",
      "train time for 4256 epochs, was 3503.299195289612\n",
      "\n",
      "EPOCH 4258  (with max 8000), loss: 0.0020975011866539717\n",
      "train time for 4258 epochs, was 3504.9357693195343\n",
      "\n",
      "EPOCH 4260  (with max 8000), loss: 0.0026825941167771816\n",
      "train time for 4260 epochs, was 3506.5721905231476\n",
      "\n",
      "EPOCH 4262  (with max 8000), loss: 0.002705854596570134\n",
      "train time for 4262 epochs, was 3508.208463191986\n",
      "\n",
      "EPOCH 4264  (with max 8000), loss: 0.004221223294734955\n",
      "train time for 4264 epochs, was 3509.842681646347\n",
      "\n",
      "EPOCH 4266  (with max 8000), loss: 0.0033214413560926914\n",
      "train time for 4266 epochs, was 3511.476904153824\n",
      "\n",
      "EPOCH 4268  (with max 8000), loss: 0.002919398946687579\n",
      "train time for 4268 epochs, was 3513.111397266388\n",
      "\n",
      "EPOCH 4270  (with max 8000), loss: 0.00401658657938242\n",
      "train time for 4270 epochs, was 3514.7459647655487\n",
      "\n",
      "EPOCH 4272  (with max 8000), loss: 0.009132668375968933\n",
      "train time for 4272 epochs, was 3516.380250930786\n",
      "\n",
      "EPOCH 4274  (with max 8000), loss: 0.006633593700826168\n",
      "train time for 4274 epochs, was 3518.0145242214203\n",
      "\n",
      "EPOCH 4276  (with max 8000), loss: 0.002916559809818864\n",
      "train time for 4276 epochs, was 3519.6530878543854\n",
      "\n",
      "EPOCH 4278  (with max 8000), loss: 0.007507894653826952\n",
      "train time for 4278 epochs, was 3521.287628173828\n",
      "\n",
      "EPOCH 4280  (with max 8000), loss: 0.004385191015899181\n",
      "train time for 4280 epochs, was 3522.9220354557037\n",
      "\n",
      "EPOCH 4282  (with max 8000), loss: 0.00907483696937561\n",
      "train time for 4282 epochs, was 3524.556421279907\n",
      "\n",
      "EPOCH 4284  (with max 8000), loss: 0.02115466631948948\n",
      "train time for 4284 epochs, was 3526.1910243034363\n",
      "\n",
      "EPOCH 4286  (with max 8000), loss: 0.029344717040657997\n",
      "train time for 4286 epochs, was 3527.82528591156\n",
      "\n",
      "EPOCH 4288  (with max 8000), loss: 0.013222208246588707\n",
      "train time for 4288 epochs, was 3529.4598228931427\n",
      "\n",
      "EPOCH 4290  (with max 8000), loss: 0.0038295781705528498\n",
      "train time for 4290 epochs, was 3531.0940878391266\n",
      "\n",
      "EPOCH 4292  (with max 8000), loss: 0.005366320256143808\n",
      "train time for 4292 epochs, was 3532.7283358573914\n",
      "\n",
      "EPOCH 4294  (with max 8000), loss: 0.0026940961834043264\n",
      "train time for 4294 epochs, was 3534.3624308109283\n",
      "\n",
      "EPOCH 4296  (with max 8000), loss: 0.0004635921504814178\n",
      "train time for 4296 epochs, was 3535.996703863144\n",
      "\n",
      "EPOCH 4298  (with max 8000), loss: 0.0045218439772725105\n",
      "train time for 4298 epochs, was 3537.6309876441956\n",
      "\n",
      "EPOCH 4300  (with max 8000), loss: 0.004904130008071661\n",
      "train time for 4300 epochs, was 3539.267349720001\n",
      "\n",
      "EPOCH 4302  (with max 8000), loss: 0.228525310754776\n",
      "train time for 4302 epochs, was 3540.90159368515\n",
      "\n",
      "EPOCH 4304  (with max 8000), loss: 0.09061839431524277\n",
      "train time for 4304 epochs, was 3542.536081314087\n",
      "\n",
      "EPOCH 4306  (with max 8000), loss: 0.015126978978514671\n",
      "train time for 4306 epochs, was 3544.1995391845703\n",
      "\n",
      "EPOCH 4308  (with max 8000), loss: 0.021490423008799553\n",
      "train time for 4308 epochs, was 3545.836277246475\n",
      "\n",
      "EPOCH 4310  (with max 8000), loss: 0.019114647060632706\n",
      "train time for 4310 epochs, was 3547.4710466861725\n",
      "\n",
      "EPOCH 4312  (with max 8000), loss: 0.00839309487491846\n",
      "train time for 4312 epochs, was 3549.1052815914154\n",
      "\n",
      "EPOCH 4314  (with max 8000), loss: 0.01520007848739624\n",
      "train time for 4314 epochs, was 3550.7396697998047\n",
      "\n",
      "EPOCH 4316  (with max 8000), loss: 0.01743416301906109\n",
      "train time for 4316 epochs, was 3552.3737530708313\n",
      "\n",
      "EPOCH 4318  (with max 8000), loss: 0.009485176764428616\n",
      "train time for 4318 epochs, was 3554.0079865455627\n",
      "\n",
      "EPOCH 4320  (with max 8000), loss: 0.01573004759848118\n",
      "train time for 4320 epochs, was 3555.6484529972076\n",
      "\n",
      "EPOCH 4322  (with max 8000), loss: 0.022786496207118034\n",
      "train time for 4322 epochs, was 3557.284883260727\n",
      "\n",
      "EPOCH 4324  (with max 8000), loss: 0.009724977426230907\n",
      "train time for 4324 epochs, was 3558.9189648628235\n",
      "\n",
      "EPOCH 4326  (with max 8000), loss: 0.018387529999017715\n",
      "train time for 4326 epochs, was 3560.552880048752\n",
      "\n",
      "EPOCH 4328  (with max 8000), loss: 0.005358465481549501\n",
      "train time for 4328 epochs, was 3562.1891198158264\n",
      "\n",
      "EPOCH 4330  (with max 8000), loss: 0.0020558766555041075\n",
      "train time for 4330 epochs, was 3563.8254539966583\n",
      "\n",
      "EPOCH 4332  (with max 8000), loss: 0.01307867094874382\n",
      "train time for 4332 epochs, was 3565.4617881774902\n",
      "\n",
      "EPOCH 4334  (with max 8000), loss: 0.005541086662560701\n",
      "train time for 4334 epochs, was 3567.097902774811\n",
      "\n",
      "EPOCH 4336  (with max 8000), loss: 0.007626253645867109\n",
      "train time for 4336 epochs, was 3568.734114408493\n",
      "\n",
      "EPOCH 4338  (with max 8000), loss: 0.005853686016052961\n",
      "train time for 4338 epochs, was 3570.3681688308716\n",
      "\n",
      "EPOCH 4340  (with max 8000), loss: 0.002187885344028473\n",
      "train time for 4340 epochs, was 3572.0023517608643\n",
      "\n",
      "EPOCH 4342  (with max 8000), loss: 0.011354324407875538\n",
      "train time for 4342 epochs, was 3573.6428582668304\n",
      "\n",
      "EPOCH 4344  (with max 8000), loss: 0.006727681029587984\n",
      "train time for 4344 epochs, was 3575.277015686035\n",
      "\n",
      "EPOCH 4346  (with max 8000), loss: 0.0041545964777469635\n",
      "train time for 4346 epochs, was 3576.911167860031\n",
      "\n",
      "EPOCH 4348  (with max 8000), loss: 0.007816597819328308\n",
      "train time for 4348 epochs, was 3578.555835723877\n",
      "\n",
      "EPOCH 4350  (with max 8000), loss: 0.005487698595970869\n",
      "train time for 4350 epochs, was 3580.1898081302643\n",
      "\n",
      "EPOCH 4352  (with max 8000), loss: 0.0070771388709545135\n",
      "train time for 4352 epochs, was 3581.8260848522186\n",
      "\n",
      "EPOCH 4354  (with max 8000), loss: 0.002045650500804186\n",
      "train time for 4354 epochs, was 3583.4623997211456\n",
      "\n",
      "EPOCH 4356  (with max 8000), loss: 0.007778100669384003\n",
      "train time for 4356 epochs, was 3585.0964648723602\n",
      "\n",
      "EPOCH 4358  (with max 8000), loss: 0.008013306185603142\n",
      "train time for 4358 epochs, was 3586.732816696167\n",
      "\n",
      "EPOCH 4360  (with max 8000), loss: 0.005809629335999489\n",
      "train time for 4360 epochs, was 3588.369088411331\n",
      "\n",
      "EPOCH 4362  (with max 8000), loss: 0.004298598039895296\n",
      "train time for 4362 epochs, was 3590.003435611725\n",
      "\n",
      "EPOCH 4364  (with max 8000), loss: 0.004564642906188965\n",
      "train time for 4364 epochs, was 3591.6376535892487\n",
      "\n",
      "EPOCH 4366  (with max 8000), loss: 0.014896251261234283\n",
      "train time for 4366 epochs, was 3593.2803807258606\n",
      "\n",
      "EPOCH 4368  (with max 8000), loss: 0.002166702412068844\n",
      "train time for 4368 epochs, was 3594.9144961833954\n",
      "\n",
      "EPOCH 4370  (with max 8000), loss: 0.003548190463334322\n",
      "train time for 4370 epochs, was 3596.5529119968414\n",
      "\n",
      "EPOCH 4372  (with max 8000), loss: 0.0095200901851058\n",
      "train time for 4372 epochs, was 3598.1870741844177\n",
      "\n",
      "EPOCH 4374  (with max 8000), loss: 0.00270283711142838\n",
      "train time for 4374 epochs, was 3599.8256447315216\n",
      "\n",
      "EPOCH 4376  (with max 8000), loss: 0.010047510266304016\n",
      "train time for 4376 epochs, was 3601.4598524570465\n",
      "\n",
      "EPOCH 4378  (with max 8000), loss: 0.0034182497765868902\n",
      "train time for 4378 epochs, was 3603.096349477768\n",
      "\n",
      "EPOCH 4380  (with max 8000), loss: 0.0028290990740060806\n",
      "train time for 4380 epochs, was 3604.730395555496\n",
      "\n",
      "EPOCH 4382  (with max 8000), loss: 0.0049789841286838055\n",
      "train time for 4382 epochs, was 3606.3666954040527\n",
      "\n",
      "EPOCH 4384  (with max 8000), loss: 0.007533686701208353\n",
      "train time for 4384 epochs, was 3608.0009920597076\n",
      "\n",
      "EPOCH 4386  (with max 8000), loss: 0.0045388429425656796\n",
      "train time for 4386 epochs, was 3609.635194540024\n",
      "\n",
      "EPOCH 4388  (with max 8000), loss: 0.00258088787086308\n",
      "train time for 4388 epochs, was 3611.26944732666\n",
      "\n",
      "EPOCH 4390  (with max 8000), loss: 0.002907348331063986\n",
      "train time for 4390 epochs, was 3612.9036252498627\n",
      "\n",
      "EPOCH 4392  (with max 8000), loss: 0.003338399576023221\n",
      "train time for 4392 epochs, was 3614.540192604065\n",
      "\n",
      "EPOCH 4394  (with max 8000), loss: 0.0003269524313509464\n",
      "train time for 4394 epochs, was 3616.174462080002\n",
      "\n",
      "EPOCH 4396  (with max 8000), loss: 0.0009439249988645315\n",
      "train time for 4396 epochs, was 3617.8084058761597\n",
      "\n",
      "EPOCH 4398  (with max 8000), loss: 0.003013193141669035\n",
      "train time for 4398 epochs, was 3619.4674627780914\n",
      "\n",
      "EPOCH 4400  (with max 8000), loss: 0.003135951003059745\n",
      "train time for 4400 epochs, was 3621.1016116142273\n",
      "\n",
      "EPOCH 4400 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_4400.pth\n",
      "\n",
      "EPOCH 4402  (with max 8000), loss: 0.01190278772264719\n",
      "train time for 4402 epochs, was 3622.771322965622\n",
      "\n",
      "EPOCH 4404  (with max 8000), loss: 0.05640111491084099\n",
      "train time for 4404 epochs, was 3624.407631635666\n",
      "\n",
      "EPOCH 4406  (with max 8000), loss: 0.014774751849472523\n",
      "train time for 4406 epochs, was 3626.0500814914703\n",
      "\n",
      "EPOCH 4408  (with max 8000), loss: 0.017496630549430847\n",
      "train time for 4408 epochs, was 3627.6840488910675\n",
      "\n",
      "EPOCH 4410  (with max 8000), loss: 0.01163251418620348\n",
      "train time for 4410 epochs, was 3629.3185081481934\n",
      "\n",
      "EPOCH 4412  (with max 8000), loss: 0.008279438130557537\n",
      "train time for 4412 epochs, was 3630.952794790268\n",
      "\n",
      "EPOCH 4414  (with max 8000), loss: 0.0021290206350386143\n",
      "train time for 4414 epochs, was 3632.5869669914246\n",
      "\n",
      "EPOCH 4416  (with max 8000), loss: 0.006172096356749535\n",
      "train time for 4416 epochs, was 3634.2211825847626\n",
      "\n",
      "EPOCH 4418  (with max 8000), loss: 0.007552265655249357\n",
      "train time for 4418 epochs, was 3635.8554005622864\n",
      "\n",
      "EPOCH 4420  (with max 8000), loss: 0.0042360443621873856\n",
      "train time for 4420 epochs, was 3637.4894778728485\n",
      "\n",
      "EPOCH 4422  (with max 8000), loss: 0.002568632597103715\n",
      "train time for 4422 epochs, was 3639.1236357688904\n",
      "\n",
      "EPOCH 4424  (with max 8000), loss: 0.0026876397896558046\n",
      "train time for 4424 epochs, was 3640.7577414512634\n",
      "\n",
      "EPOCH 4426  (with max 8000), loss: 0.03361038491129875\n",
      "train time for 4426 epochs, was 3642.391758441925\n",
      "\n",
      "EPOCH 4428  (with max 8000), loss: 0.009314780123531818\n",
      "train time for 4428 epochs, was 3644.0281393527985\n",
      "\n",
      "EPOCH 4430  (with max 8000), loss: 0.004927047528326511\n",
      "train time for 4430 epochs, was 3645.6646518707275\n",
      "\n",
      "EPOCH 4432  (with max 8000), loss: 0.004295529797673225\n",
      "train time for 4432 epochs, was 3647.298780441284\n",
      "\n",
      "EPOCH 4434  (with max 8000), loss: 0.0021628746762871742\n",
      "train time for 4434 epochs, was 3648.935187101364\n",
      "\n",
      "EPOCH 4436  (with max 8000), loss: 0.0014742686180397868\n",
      "train time for 4436 epochs, was 3650.578113794327\n",
      "\n",
      "EPOCH 4438  (with max 8000), loss: 0.0020591693464666605\n",
      "train time for 4438 epochs, was 3652.2144355773926\n",
      "\n",
      "EPOCH 4440  (with max 8000), loss: 0.0026595627423375845\n",
      "train time for 4440 epochs, was 3653.8529176712036\n",
      "\n",
      "EPOCH 4442  (with max 8000), loss: 0.022070633247494698\n",
      "train time for 4442 epochs, was 3655.4871208667755\n",
      "\n",
      "EPOCH 4444  (with max 8000), loss: 0.015356582589447498\n",
      "train time for 4444 epochs, was 3657.1213743686676\n",
      "\n",
      "EPOCH 4446  (with max 8000), loss: 0.004172517452389002\n",
      "train time for 4446 epochs, was 3658.772204399109\n",
      "\n",
      "EPOCH 4448  (with max 8000), loss: 0.0019679313991218805\n",
      "train time for 4448 epochs, was 3660.408636569977\n",
      "\n",
      "EPOCH 4450  (with max 8000), loss: 0.009954370558261871\n",
      "train time for 4450 epochs, was 3662.042977809906\n",
      "\n",
      "EPOCH 4452  (with max 8000), loss: 0.006528778001666069\n",
      "train time for 4452 epochs, was 3663.681547641754\n",
      "\n",
      "EPOCH 4454  (with max 8000), loss: 0.01328239031136036\n",
      "train time for 4454 epochs, was 3665.3159885406494\n",
      "\n",
      "EPOCH 4456  (with max 8000), loss: 0.0042273239232599735\n",
      "train time for 4456 epochs, was 3666.950242996216\n",
      "\n",
      "EPOCH 4458  (with max 8000), loss: 0.0017117188544943929\n",
      "train time for 4458 epochs, was 3668.5845761299133\n",
      "\n",
      "EPOCH 4460  (with max 8000), loss: 0.015037578530609608\n",
      "train time for 4460 epochs, was 3670.229276895523\n",
      "\n",
      "EPOCH 4462  (with max 8000), loss: 0.0074334517121315\n",
      "train time for 4462 epochs, was 3671.8635671138763\n",
      "\n",
      "EPOCH 4464  (with max 8000), loss: 0.06289593130350113\n",
      "train time for 4464 epochs, was 3673.499929666519\n",
      "\n",
      "EPOCH 4466  (with max 8000), loss: 0.02907540090382099\n",
      "train time for 4466 epochs, was 3675.136241912842\n",
      "\n",
      "EPOCH 4468  (with max 8000), loss: 0.006794722750782967\n",
      "train time for 4468 epochs, was 3676.77694773674\n",
      "\n",
      "EPOCH 4470  (with max 8000), loss: 0.008558989502489567\n",
      "train time for 4470 epochs, was 3678.413594484329\n",
      "\n",
      "EPOCH 4472  (with max 8000), loss: 0.010409773327410221\n",
      "train time for 4472 epochs, was 3680.047640323639\n",
      "\n",
      "EPOCH 4474  (with max 8000), loss: 0.009723144583404064\n",
      "train time for 4474 epochs, was 3681.6818301677704\n",
      "\n",
      "EPOCH 4476  (with max 8000), loss: 0.001902787946164608\n",
      "train time for 4476 epochs, was 3683.316035747528\n",
      "\n",
      "EPOCH 4478  (with max 8000), loss: 0.00573175773024559\n",
      "train time for 4478 epochs, was 3684.950266122818\n",
      "\n",
      "EPOCH 4480  (with max 8000), loss: 0.007263594307005405\n",
      "train time for 4480 epochs, was 3686.5868158340454\n",
      "\n",
      "EPOCH 4482  (with max 8000), loss: 0.00257709133438766\n",
      "train time for 4482 epochs, was 3688.225168466568\n",
      "\n",
      "EPOCH 4484  (with max 8000), loss: 0.007131841965019703\n",
      "train time for 4484 epochs, was 3689.8614020347595\n",
      "\n",
      "EPOCH 4486  (with max 8000), loss: 0.010310034267604351\n",
      "train time for 4486 epochs, was 3691.495574951172\n",
      "\n",
      "EPOCH 4488  (with max 8000), loss: 0.004408418200910091\n",
      "train time for 4488 epochs, was 3693.1299333572388\n",
      "\n",
      "EPOCH 4490  (with max 8000), loss: 0.009505405090749264\n",
      "train time for 4490 epochs, was 3694.7953469753265\n",
      "\n",
      "EPOCH 4492  (with max 8000), loss: 0.007250260561704636\n",
      "train time for 4492 epochs, was 3696.429548025131\n",
      "\n",
      "EPOCH 4494  (with max 8000), loss: 0.0026424480602145195\n",
      "train time for 4494 epochs, was 3698.063560962677\n",
      "\n",
      "EPOCH 4496  (with max 8000), loss: 0.00346015184186399\n",
      "train time for 4496 epochs, was 3699.6995866298676\n",
      "\n",
      "EPOCH 4498  (with max 8000), loss: 0.0031356115359812975\n",
      "train time for 4498 epochs, was 3701.3339166641235\n",
      "\n",
      "EPOCH 4500  (with max 8000), loss: 0.0025119190104305744\n",
      "train time for 4500 epochs, was 3702.9680376052856\n",
      "\n",
      "EPOCH 4502  (with max 8000), loss: 0.005569336004555225\n",
      "train time for 4502 epochs, was 3704.606423854828\n",
      "\n",
      "EPOCH 4504  (with max 8000), loss: 0.0058440882712602615\n",
      "train time for 4504 epochs, was 3706.2446773052216\n",
      "\n",
      "EPOCH 4506  (with max 8000), loss: 0.0152088962495327\n",
      "train time for 4506 epochs, was 3707.881011247635\n",
      "\n",
      "EPOCH 4508  (with max 8000), loss: 0.011941886506974697\n",
      "train time for 4508 epochs, was 3709.5197415351868\n",
      "\n",
      "EPOCH 4510  (with max 8000), loss: 0.006510460749268532\n",
      "train time for 4510 epochs, was 3711.160354614258\n",
      "\n",
      "EPOCH 4512  (with max 8000), loss: 0.03430970013141632\n",
      "train time for 4512 epochs, was 3712.794637441635\n",
      "\n",
      "EPOCH 4514  (with max 8000), loss: 0.048113979399204254\n",
      "train time for 4514 epochs, was 3714.4290177822113\n",
      "\n",
      "EPOCH 4516  (with max 8000), loss: 0.01587763987481594\n",
      "train time for 4516 epochs, was 3716.065259218216\n",
      "\n",
      "EPOCH 4518  (with max 8000), loss: 0.03526727855205536\n",
      "train time for 4518 epochs, was 3717.7144219875336\n",
      "\n",
      "EPOCH 4520  (with max 8000), loss: 0.021187620237469673\n",
      "train time for 4520 epochs, was 3719.3486773967743\n",
      "\n",
      "EPOCH 4522  (with max 8000), loss: 0.037258222699165344\n",
      "train time for 4522 epochs, was 3720.982924938202\n",
      "\n",
      "EPOCH 4524  (with max 8000), loss: 0.02812505140900612\n",
      "train time for 4524 epochs, was 3722.6174492836\n",
      "\n",
      "EPOCH 4526  (with max 8000), loss: 0.010741427540779114\n",
      "train time for 4526 epochs, was 3724.251400232315\n",
      "\n",
      "EPOCH 4528  (with max 8000), loss: 0.004966399632394314\n",
      "train time for 4528 epochs, was 3725.887542486191\n",
      "\n",
      "EPOCH 4530  (with max 8000), loss: 0.005411589052528143\n",
      "train time for 4530 epochs, was 3727.525973558426\n",
      "\n",
      "EPOCH 4532  (with max 8000), loss: 0.010612675920128822\n",
      "train time for 4532 epochs, was 3729.1603260040283\n",
      "\n",
      "EPOCH 4534  (with max 8000), loss: 0.00961126945912838\n",
      "train time for 4534 epochs, was 3730.8029441833496\n",
      "\n",
      "EPOCH 4536  (with max 8000), loss: 0.009935122914612293\n",
      "train time for 4536 epochs, was 3732.4391067028046\n",
      "\n",
      "EPOCH 4538  (with max 8000), loss: 0.027028772979974747\n",
      "train time for 4538 epochs, was 3734.090058326721\n",
      "\n",
      "EPOCH 4540  (with max 8000), loss: 0.007243485189974308\n",
      "train time for 4540 epochs, was 3735.730594396591\n",
      "\n",
      "EPOCH 4542  (with max 8000), loss: 0.013226059265434742\n",
      "train time for 4542 epochs, was 3737.3646323680878\n",
      "\n",
      "EPOCH 4544  (with max 8000), loss: 0.005620467942208052\n",
      "train time for 4544 epochs, was 3739.0008668899536\n",
      "\n",
      "EPOCH 4546  (with max 8000), loss: 0.012714781798422337\n",
      "train time for 4546 epochs, was 3740.635132789612\n",
      "\n",
      "EPOCH 4548  (with max 8000), loss: 0.005089704878628254\n",
      "train time for 4548 epochs, was 3742.2837936878204\n",
      "\n",
      "EPOCH 4550  (with max 8000), loss: 0.005678870715200901\n",
      "train time for 4550 epochs, was 3743.918016433716\n",
      "\n",
      "EPOCH 4552  (with max 8000), loss: 0.02181258238852024\n",
      "train time for 4552 epochs, was 3745.5521545410156\n",
      "\n",
      "EPOCH 4554  (with max 8000), loss: 0.005149992182850838\n",
      "train time for 4554 epochs, was 3747.1883409023285\n",
      "\n",
      "EPOCH 4556  (with max 8000), loss: 0.008844317868351936\n",
      "train time for 4556 epochs, was 3748.824531316757\n",
      "\n",
      "EPOCH 4558  (with max 8000), loss: 0.009948414750397205\n",
      "train time for 4558 epochs, was 3750.4609298706055\n",
      "\n",
      "EPOCH 4560  (with max 8000), loss: 0.0013286372413858771\n",
      "train time for 4560 epochs, was 3752.099109888077\n",
      "\n",
      "EPOCH 4562  (with max 8000), loss: 0.005182108376175165\n",
      "train time for 4562 epochs, was 3753.7330317497253\n",
      "\n",
      "EPOCH 4564  (with max 8000), loss: 0.005191825795918703\n",
      "train time for 4564 epochs, was 3755.3670692443848\n",
      "\n",
      "EPOCH 4566  (with max 8000), loss: 0.0032189807388931513\n",
      "train time for 4566 epochs, was 3757.00137925148\n",
      "\n",
      "EPOCH 4568  (with max 8000), loss: 0.1066298708319664\n",
      "train time for 4568 epochs, was 3758.635823249817\n",
      "\n",
      "EPOCH 4570  (with max 8000), loss: 0.046408843249082565\n",
      "train time for 4570 epochs, was 3760.2700204849243\n",
      "\n",
      "EPOCH 4572  (with max 8000), loss: 0.006059565115720034\n",
      "train time for 4572 epochs, was 3761.904069662094\n",
      "\n",
      "EPOCH 4574  (with max 8000), loss: 0.016469554975628853\n",
      "train time for 4574 epochs, was 3763.538076400757\n",
      "\n",
      "EPOCH 4576  (with max 8000), loss: 0.006693301256746054\n",
      "train time for 4576 epochs, was 3765.1723930835724\n",
      "\n",
      "EPOCH 4578  (with max 8000), loss: 0.0025554196909070015\n",
      "train time for 4578 epochs, was 3766.8397450447083\n",
      "\n",
      "EPOCH 4580  (with max 8000), loss: 0.010048499330878258\n",
      "train time for 4580 epochs, was 3768.4736709594727\n",
      "\n",
      "EPOCH 4582  (with max 8000), loss: 0.001690424745902419\n",
      "train time for 4582 epochs, was 3770.1079320907593\n",
      "\n",
      "EPOCH 4584  (with max 8000), loss: 0.0033345536794513464\n",
      "train time for 4584 epochs, was 3771.744170665741\n",
      "\n",
      "EPOCH 4586  (with max 8000), loss: 0.0014907951699569821\n",
      "train time for 4586 epochs, was 3773.3780658245087\n",
      "\n",
      "EPOCH 4588  (with max 8000), loss: 0.002466643461957574\n",
      "train time for 4588 epochs, was 3775.0121052265167\n",
      "\n",
      "EPOCH 4590  (with max 8000), loss: 0.0046890066005289555\n",
      "train time for 4590 epochs, was 3776.6461868286133\n",
      "\n",
      "EPOCH 4592  (with max 8000), loss: 0.015463607385754585\n",
      "train time for 4592 epochs, was 3778.2804157733917\n",
      "\n",
      "EPOCH 4594  (with max 8000), loss: 0.0027554109692573547\n",
      "train time for 4594 epochs, was 3779.914603471756\n",
      "\n",
      "EPOCH 4596  (with max 8000), loss: 0.001992274774238467\n",
      "train time for 4596 epochs, was 3781.5487072467804\n",
      "\n",
      "EPOCH 4598  (with max 8000), loss: 0.003462259890511632\n",
      "train time for 4598 epochs, was 3783.189216375351\n",
      "\n",
      "EPOCH 4600  (with max 8000), loss: 0.0011891089379787445\n",
      "train time for 4600 epochs, was 3784.827621459961\n",
      "\n",
      "EPOCH 4600 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_4600.pth\n",
      "\n",
      "EPOCH 4602  (with max 8000), loss: 0.0029087765142321587\n",
      "train time for 4602 epochs, was 3786.4974534511566\n",
      "\n",
      "EPOCH 4604  (with max 8000), loss: 0.00703010568395257\n",
      "train time for 4604 epochs, was 3788.1378247737885\n",
      "\n",
      "EPOCH 4606  (with max 8000), loss: 0.0032285507768392563\n",
      "train time for 4606 epochs, was 3789.7738769054413\n",
      "\n",
      "EPOCH 4608  (with max 8000), loss: 0.004890685901045799\n",
      "train time for 4608 epochs, was 3791.408089876175\n",
      "\n",
      "EPOCH 4610  (with max 8000), loss: 0.040451932698488235\n",
      "train time for 4610 epochs, was 3793.042145013809\n",
      "\n",
      "EPOCH 4612  (with max 8000), loss: 0.14974138140678406\n",
      "train time for 4612 epochs, was 3794.676317214966\n",
      "\n",
      "EPOCH 4614  (with max 8000), loss: 0.025641797110438347\n",
      "train time for 4614 epochs, was 3796.3103079795837\n",
      "\n",
      "EPOCH 4616  (with max 8000), loss: 0.01808958873152733\n",
      "train time for 4616 epochs, was 3797.948506593704\n",
      "\n",
      "EPOCH 4618  (with max 8000), loss: 0.004369756206870079\n",
      "train time for 4618 epochs, was 3799.5825867652893\n",
      "\n",
      "EPOCH 4620  (with max 8000), loss: 0.011648816056549549\n",
      "train time for 4620 epochs, was 3801.2170271873474\n",
      "\n",
      "EPOCH 4622  (with max 8000), loss: 0.015688618645071983\n",
      "train time for 4622 epochs, was 3802.8533792495728\n",
      "\n",
      "EPOCH 4624  (with max 8000), loss: 0.03202242776751518\n",
      "train time for 4624 epochs, was 3804.4875195026398\n",
      "\n",
      "EPOCH 4626  (with max 8000), loss: 0.01958290860056877\n",
      "train time for 4626 epochs, was 3806.1239161491394\n",
      "\n",
      "EPOCH 4628  (with max 8000), loss: 0.013491973280906677\n",
      "train time for 4628 epochs, was 3807.758303642273\n",
      "\n",
      "EPOCH 4630  (with max 8000), loss: 0.012805920094251633\n",
      "train time for 4630 epochs, was 3809.394551038742\n",
      "\n",
      "EPOCH 4632  (with max 8000), loss: 0.009603766724467278\n",
      "train time for 4632 epochs, was 3811.0287070274353\n",
      "\n",
      "EPOCH 4634  (with max 8000), loss: 0.008633187040686607\n",
      "train time for 4634 epochs, was 3812.6627044677734\n",
      "\n",
      "EPOCH 4636  (with max 8000), loss: 0.0075415195897221565\n",
      "train time for 4636 epochs, was 3814.296862602234\n",
      "\n",
      "EPOCH 4638  (with max 8000), loss: 0.010901499539613724\n",
      "train time for 4638 epochs, was 3815.9308767318726\n",
      "\n",
      "EPOCH 4640  (with max 8000), loss: 0.008677548728883266\n",
      "train time for 4640 epochs, was 3817.5669462680817\n",
      "\n",
      "EPOCH 4642  (with max 8000), loss: 0.0053812009282410145\n",
      "train time for 4642 epochs, was 3819.2007105350494\n",
      "\n",
      "EPOCH 4644  (with max 8000), loss: 0.0056104338727891445\n",
      "train time for 4644 epochs, was 3820.834617137909\n",
      "\n",
      "EPOCH 4646  (with max 8000), loss: 0.004154080059379339\n",
      "train time for 4646 epochs, was 3822.4687910079956\n",
      "\n",
      "EPOCH 4648  (with max 8000), loss: 0.008383313193917274\n",
      "train time for 4648 epochs, was 3824.1028084754944\n",
      "\n",
      "EPOCH 4650  (with max 8000), loss: 0.013522015884518623\n",
      "train time for 4650 epochs, was 3825.7891726493835\n",
      "\n",
      "EPOCH 4652  (with max 8000), loss: 0.003928703255951405\n",
      "train time for 4652 epochs, was 3827.4275076389313\n",
      "\n",
      "EPOCH 4654  (with max 8000), loss: 0.004539464134722948\n",
      "train time for 4654 epochs, was 3829.0640540122986\n",
      "\n",
      "EPOCH 4656  (with max 8000), loss: 0.005000094883143902\n",
      "train time for 4656 epochs, was 3830.6981744766235\n",
      "\n",
      "EPOCH 4658  (with max 8000), loss: 0.007970758713781834\n",
      "train time for 4658 epochs, was 3832.3343000411987\n",
      "\n",
      "EPOCH 4660  (with max 8000), loss: 0.03074200078845024\n",
      "train time for 4660 epochs, was 3833.970361471176\n",
      "\n",
      "EPOCH 4662  (with max 8000), loss: 0.010632514022290707\n",
      "train time for 4662 epochs, was 3835.608535528183\n",
      "\n",
      "EPOCH 4664  (with max 8000), loss: 0.0541510246694088\n",
      "train time for 4664 epochs, was 3837.284526348114\n",
      "\n",
      "EPOCH 4666  (with max 8000), loss: 0.032052841037511826\n",
      "train time for 4666 epochs, was 3838.924891471863\n",
      "\n",
      "EPOCH 4668  (with max 8000), loss: 0.015719782561063766\n",
      "train time for 4668 epochs, was 3840.558958053589\n",
      "\n",
      "EPOCH 4670  (with max 8000), loss: 0.04841340705752373\n",
      "train time for 4670 epochs, was 3842.1951813697815\n",
      "\n",
      "EPOCH 4672  (with max 8000), loss: 0.02304866351187229\n",
      "train time for 4672 epochs, was 3843.8292169570923\n",
      "\n",
      "EPOCH 4674  (with max 8000), loss: 0.015674946829676628\n",
      "train time for 4674 epochs, was 3845.4633419513702\n",
      "\n",
      "EPOCH 4676  (with max 8000), loss: 0.014271716587245464\n",
      "train time for 4676 epochs, was 3847.097510099411\n",
      "\n",
      "EPOCH 4678  (with max 8000), loss: 0.01508532464504242\n",
      "train time for 4678 epochs, was 3848.731690645218\n",
      "\n",
      "EPOCH 4680  (with max 8000), loss: 0.00908304937183857\n",
      "train time for 4680 epochs, was 3850.3681824207306\n",
      "\n",
      "EPOCH 4682  (with max 8000), loss: 0.006267262622714043\n",
      "train time for 4682 epochs, was 3852.0026421546936\n",
      "\n",
      "EPOCH 4684  (with max 8000), loss: 0.006465132348239422\n",
      "train time for 4684 epochs, was 3853.6369075775146\n",
      "\n",
      "EPOCH 4686  (with max 8000), loss: 0.009243233129382133\n",
      "train time for 4686 epochs, was 3855.273084640503\n",
      "\n",
      "EPOCH 4688  (with max 8000), loss: 0.0021718849893659353\n",
      "train time for 4688 epochs, was 3856.9070677757263\n",
      "\n",
      "EPOCH 4690  (with max 8000), loss: 0.003888307372108102\n",
      "train time for 4690 epochs, was 3858.5433480739594\n",
      "\n",
      "EPOCH 4692  (with max 8000), loss: 0.00842459499835968\n",
      "train time for 4692 epochs, was 3860.183662891388\n",
      "\n",
      "EPOCH 4694  (with max 8000), loss: 0.008346149697899818\n",
      "train time for 4694 epochs, was 3861.817668199539\n",
      "\n",
      "EPOCH 4696  (with max 8000), loss: 0.012186824344098568\n",
      "train time for 4696 epochs, was 3863.45166516304\n",
      "\n",
      "EPOCH 4698  (with max 8000), loss: 0.004495052620768547\n",
      "train time for 4698 epochs, was 3865.087942838669\n",
      "\n",
      "EPOCH 4700  (with max 8000), loss: 0.002839625347405672\n",
      "train time for 4700 epochs, was 3866.721938610077\n",
      "\n",
      "EPOCH 4702  (with max 8000), loss: 0.0030949742067605257\n",
      "train time for 4702 epochs, was 3868.356009244919\n",
      "\n",
      "EPOCH 4704  (with max 8000), loss: 0.005952936597168446\n",
      "train time for 4704 epochs, was 3869.990108013153\n",
      "\n",
      "EPOCH 4706  (with max 8000), loss: 0.006284297443926334\n",
      "train time for 4706 epochs, was 3871.624145746231\n",
      "\n",
      "EPOCH 4708  (with max 8000), loss: 0.027624187991023064\n",
      "train time for 4708 epochs, was 3873.2876217365265\n",
      "\n",
      "EPOCH 4710  (with max 8000), loss: 0.006179742515087128\n",
      "train time for 4710 epochs, was 3874.921717643738\n",
      "\n",
      "EPOCH 4712  (with max 8000), loss: 0.01353040523827076\n",
      "train time for 4712 epochs, was 3876.5558428764343\n",
      "\n",
      "EPOCH 4714  (with max 8000), loss: 0.002891725627705455\n",
      "train time for 4714 epochs, was 3878.1898744106293\n",
      "\n",
      "EPOCH 4716  (with max 8000), loss: 0.0017521395348012447\n",
      "train time for 4716 epochs, was 3879.823919773102\n",
      "\n",
      "EPOCH 4718  (with max 8000), loss: 0.1421019285917282\n",
      "train time for 4718 epochs, was 3881.457927942276\n",
      "\n",
      "EPOCH 4720  (with max 8000), loss: 0.022633971646428108\n",
      "train time for 4720 epochs, was 3883.0920956134796\n",
      "\n",
      "EPOCH 4722  (with max 8000), loss: 0.017028240486979485\n",
      "train time for 4722 epochs, was 3884.726188182831\n",
      "\n",
      "EPOCH 4724  (with max 8000), loss: 0.010998576879501343\n",
      "train time for 4724 epochs, was 3886.3605358600616\n",
      "\n",
      "EPOCH 4726  (with max 8000), loss: 0.03953996300697327\n",
      "train time for 4726 epochs, was 3887.994715452194\n",
      "\n",
      "EPOCH 4728  (with max 8000), loss: 0.009553247131407261\n",
      "train time for 4728 epochs, was 3889.6332890987396\n",
      "\n",
      "EPOCH 4730  (with max 8000), loss: 0.015186013653874397\n",
      "train time for 4730 epochs, was 3891.26748752594\n",
      "\n",
      "EPOCH 4732  (with max 8000), loss: 0.005588947329670191\n",
      "train time for 4732 epochs, was 3892.9016275405884\n",
      "\n",
      "EPOCH 4734  (with max 8000), loss: 0.012900327332317829\n",
      "train time for 4734 epochs, was 3894.5443818569183\n",
      "\n",
      "EPOCH 4736  (with max 8000), loss: 0.017145324498414993\n",
      "train time for 4736 epochs, was 3896.1785187721252\n",
      "\n",
      "EPOCH 4738  (with max 8000), loss: 0.01258730236440897\n",
      "train time for 4738 epochs, was 3897.8146753311157\n",
      "\n",
      "EPOCH 4740  (with max 8000), loss: 0.01661105640232563\n",
      "train time for 4740 epochs, was 3899.4509217739105\n",
      "\n",
      "EPOCH 4742  (with max 8000), loss: 0.008364595472812653\n",
      "train time for 4742 epochs, was 3901.0871896743774\n",
      "\n",
      "EPOCH 4744  (with max 8000), loss: 0.0033778653014451265\n",
      "train time for 4744 epochs, was 3902.7213129997253\n",
      "\n",
      "EPOCH 4746  (with max 8000), loss: 0.009277441538870335\n",
      "train time for 4746 epochs, was 3904.3554921150208\n",
      "\n",
      "EPOCH 4748  (with max 8000), loss: 0.018260540440678596\n",
      "train time for 4748 epochs, was 3905.9917500019073\n",
      "\n",
      "EPOCH 4750  (with max 8000), loss: 0.0030304391402751207\n",
      "train time for 4750 epochs, was 3907.625833749771\n",
      "\n",
      "EPOCH 4752  (with max 8000), loss: 0.0038060296792536974\n",
      "train time for 4752 epochs, was 3909.278832912445\n",
      "\n",
      "EPOCH 4754  (with max 8000), loss: 0.0034818549174815416\n",
      "train time for 4754 epochs, was 3910.912706375122\n",
      "\n",
      "EPOCH 4756  (with max 8000), loss: 0.002796862507238984\n",
      "train time for 4756 epochs, was 3912.5592041015625\n",
      "\n",
      "EPOCH 4758  (with max 8000), loss: 0.005130710545927286\n",
      "train time for 4758 epochs, was 3914.1930973529816\n",
      "\n",
      "EPOCH 4760  (with max 8000), loss: 0.005548629444092512\n",
      "train time for 4760 epochs, was 3915.8271808624268\n",
      "\n",
      "EPOCH 4762  (with max 8000), loss: 0.00421036034822464\n",
      "train time for 4762 epochs, was 3917.4611427783966\n",
      "\n",
      "EPOCH 4764  (with max 8000), loss: 0.01060109119862318\n",
      "train time for 4764 epochs, was 3919.0953595638275\n",
      "\n",
      "EPOCH 4766  (with max 8000), loss: 0.006457064766436815\n",
      "train time for 4766 epochs, was 3920.7336192131042\n",
      "\n",
      "EPOCH 4768  (with max 8000), loss: 0.002085765590891242\n",
      "train time for 4768 epochs, was 3922.3699159622192\n",
      "\n",
      "EPOCH 4770  (with max 8000), loss: 0.00777438422665\n",
      "train time for 4770 epochs, was 3924.010200023651\n",
      "\n",
      "EPOCH 4772  (with max 8000), loss: 0.011552016250789165\n",
      "train time for 4772 epochs, was 3925.6441793441772\n",
      "\n",
      "EPOCH 4774  (with max 8000), loss: 0.006219055037945509\n",
      "train time for 4774 epochs, was 3927.2784922122955\n",
      "\n",
      "EPOCH 4776  (with max 8000), loss: 0.016851600259542465\n",
      "train time for 4776 epochs, was 3928.9168305397034\n",
      "\n",
      "EPOCH 4778  (with max 8000), loss: 0.01582363061606884\n",
      "train time for 4778 epochs, was 3930.552919149399\n",
      "\n",
      "EPOCH 4780  (with max 8000), loss: 0.02120819315314293\n",
      "train time for 4780 epochs, was 3932.187025785446\n",
      "\n",
      "EPOCH 4782  (with max 8000), loss: 0.10758395493030548\n",
      "train time for 4782 epochs, was 3933.8209278583527\n",
      "\n",
      "EPOCH 4784  (with max 8000), loss: 0.03747318312525749\n",
      "train time for 4784 epochs, was 3935.457072496414\n",
      "\n",
      "EPOCH 4786  (with max 8000), loss: 0.02251408062875271\n",
      "train time for 4786 epochs, was 3937.091138124466\n",
      "\n",
      "EPOCH 4788  (with max 8000), loss: 0.0056715901009738445\n",
      "train time for 4788 epochs, was 3938.7337493896484\n",
      "\n",
      "EPOCH 4790  (with max 8000), loss: 0.01066876482218504\n",
      "train time for 4790 epochs, was 3940.367673635483\n",
      "\n",
      "EPOCH 4792  (with max 8000), loss: 0.005753401666879654\n",
      "train time for 4792 epochs, was 3942.0015115737915\n",
      "\n",
      "EPOCH 4794  (with max 8000), loss: 0.0061142584308981895\n",
      "train time for 4794 epochs, was 3943.6355907917023\n",
      "\n",
      "EPOCH 4796  (with max 8000), loss: 0.01642528735101223\n",
      "train time for 4796 epochs, was 3945.2697291374207\n",
      "\n",
      "EPOCH 4798  (with max 8000), loss: 0.0066064693965017796\n",
      "train time for 4798 epochs, was 3946.934936761856\n",
      "\n",
      "EPOCH 4800  (with max 8000), loss: 0.010410713963210583\n",
      "train time for 4800 epochs, was 3948.568948030472\n",
      "\n",
      "EPOCH 4800 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_4800.pth\n",
      "\n",
      "EPOCH 4802  (with max 8000), loss: 0.0047740088775753975\n",
      "train time for 4802 epochs, was 3950.236592531204\n",
      "\n",
      "EPOCH 4804  (with max 8000), loss: 0.005986263044178486\n",
      "train time for 4804 epochs, was 3951.87051987648\n",
      "\n",
      "EPOCH 4806  (with max 8000), loss: 0.007159118540585041\n",
      "train time for 4806 epochs, was 3953.5045142173767\n",
      "\n",
      "EPOCH 4808  (with max 8000), loss: 0.0022804762702435255\n",
      "train time for 4808 epochs, was 3955.138483762741\n",
      "\n",
      "EPOCH 4810  (with max 8000), loss: 0.009762614965438843\n",
      "train time for 4810 epochs, was 3956.782717704773\n",
      "\n",
      "EPOCH 4812  (with max 8000), loss: 0.004645080305635929\n",
      "train time for 4812 epochs, was 3958.4189100265503\n",
      "\n",
      "EPOCH 4814  (with max 8000), loss: 0.0026680086739361286\n",
      "train time for 4814 epochs, was 3960.0528724193573\n",
      "\n",
      "EPOCH 4816  (with max 8000), loss: 0.0046031358651816845\n",
      "train time for 4816 epochs, was 3961.68665933609\n",
      "\n",
      "EPOCH 4818  (with max 8000), loss: 0.012629677541553974\n",
      "train time for 4818 epochs, was 3963.3289692401886\n",
      "\n",
      "EPOCH 4820  (with max 8000), loss: 0.012127657420933247\n",
      "train time for 4820 epochs, was 3964.9628760814667\n",
      "\n",
      "EPOCH 4822  (with max 8000), loss: 0.009015325456857681\n",
      "train time for 4822 epochs, was 3966.599005460739\n",
      "\n",
      "EPOCH 4824  (with max 8000), loss: 0.01232022326439619\n",
      "train time for 4824 epochs, was 3968.2328679561615\n",
      "\n",
      "EPOCH 4826  (with max 8000), loss: 0.007175276521593332\n",
      "train time for 4826 epochs, was 3969.875217437744\n",
      "\n",
      "EPOCH 4828  (with max 8000), loss: 0.002901771804317832\n",
      "train time for 4828 epochs, was 3971.509182214737\n",
      "\n",
      "EPOCH 4830  (with max 8000), loss: 0.002026430331170559\n",
      "train time for 4830 epochs, was 3973.1455121040344\n",
      "\n",
      "EPOCH 4832  (with max 8000), loss: 0.0065588741563260555\n",
      "train time for 4832 epochs, was 3974.779387950897\n",
      "\n",
      "EPOCH 4834  (with max 8000), loss: 0.0025433336850255728\n",
      "train time for 4834 epochs, was 3976.4174242019653\n",
      "\n",
      "EPOCH 4836  (with max 8000), loss: 0.0032637135591357946\n",
      "train time for 4836 epochs, was 3978.0513350963593\n",
      "\n",
      "EPOCH 4838  (with max 8000), loss: 0.0013168136356398463\n",
      "train time for 4838 epochs, was 3979.685446500778\n",
      "\n",
      "EPOCH 4840  (with max 8000), loss: 0.0014486212749034166\n",
      "train time for 4840 epochs, was 3981.3236544132233\n",
      "\n",
      "EPOCH 4842  (with max 8000), loss: 0.013073492795228958\n",
      "train time for 4842 epochs, was 3982.966165304184\n",
      "\n",
      "EPOCH 4844  (with max 8000), loss: 0.04390252009034157\n",
      "train time for 4844 epochs, was 3984.6002430915833\n",
      "\n",
      "EPOCH 4846  (with max 8000), loss: 0.05594000965356827\n",
      "train time for 4846 epochs, was 3986.2343606948853\n",
      "\n",
      "EPOCH 4848  (with max 8000), loss: 0.035622354596853256\n",
      "train time for 4848 epochs, was 3987.8684895038605\n",
      "\n",
      "EPOCH 4850  (with max 8000), loss: 0.014793001115322113\n",
      "train time for 4850 epochs, was 3989.5043756961823\n",
      "\n",
      "EPOCH 4852  (with max 8000), loss: 0.003089078702032566\n",
      "train time for 4852 epochs, was 3991.138340950012\n",
      "\n",
      "EPOCH 4854  (with max 8000), loss: 0.008456634357571602\n",
      "train time for 4854 epochs, was 3992.7744765281677\n",
      "\n",
      "EPOCH 4856  (with max 8000), loss: 0.00461406446993351\n",
      "train time for 4856 epochs, was 3994.425318002701\n",
      "\n",
      "EPOCH 4858  (with max 8000), loss: 0.0051290737465023994\n",
      "train time for 4858 epochs, was 3996.059473991394\n",
      "\n",
      "EPOCH 4860  (with max 8000), loss: 0.006771571468561888\n",
      "train time for 4860 epochs, was 3997.6956746578217\n",
      "\n",
      "EPOCH 4862  (with max 8000), loss: 0.0028911023400723934\n",
      "train time for 4862 epochs, was 3999.329856157303\n",
      "\n",
      "EPOCH 4864  (with max 8000), loss: 0.0007610640022903681\n",
      "train time for 4864 epochs, was 4000.966073513031\n",
      "\n",
      "EPOCH 4866  (with max 8000), loss: 0.007857833057641983\n",
      "train time for 4866 epochs, was 4002.6002008914948\n",
      "\n",
      "EPOCH 4868  (with max 8000), loss: 0.005364169832319021\n",
      "train time for 4868 epochs, was 4004.234238386154\n",
      "\n",
      "EPOCH 4870  (with max 8000), loss: 0.019346479326486588\n",
      "train time for 4870 epochs, was 4005.870418071747\n",
      "\n",
      "EPOCH 4872  (with max 8000), loss: 0.046478718519210815\n",
      "train time for 4872 epochs, was 4007.504531621933\n",
      "\n",
      "EPOCH 4874  (with max 8000), loss: 0.012449553236365318\n",
      "train time for 4874 epochs, was 4009.138797521591\n",
      "\n",
      "EPOCH 4876  (with max 8000), loss: 0.004838018678128719\n",
      "train time for 4876 epochs, was 4010.772861480713\n",
      "\n",
      "EPOCH 4878  (with max 8000), loss: 0.004149491433054209\n",
      "train time for 4878 epochs, was 4012.406985759735\n",
      "\n",
      "EPOCH 4880  (with max 8000), loss: 0.016113992780447006\n",
      "train time for 4880 epochs, was 4014.0413007736206\n",
      "\n",
      "EPOCH 4882  (with max 8000), loss: 0.005395391955971718\n",
      "train time for 4882 epochs, was 4015.6758155822754\n",
      "\n",
      "EPOCH 4884  (with max 8000), loss: 0.01237786840647459\n",
      "train time for 4884 epochs, was 4017.3096454143524\n",
      "\n",
      "EPOCH 4886  (with max 8000), loss: 0.0072800759226083755\n",
      "train time for 4886 epochs, was 4018.956251859665\n",
      "\n",
      "EPOCH 4888  (with max 8000), loss: 0.004310469143092632\n",
      "train time for 4888 epochs, was 4020.590153694153\n",
      "\n",
      "EPOCH 4890  (with max 8000), loss: 0.0039818002842366695\n",
      "train time for 4890 epochs, was 4022.2259771823883\n",
      "\n",
      "EPOCH 4892  (with max 8000), loss: 0.0041673150844872\n",
      "train time for 4892 epochs, was 4023.8599779605865\n",
      "\n",
      "EPOCH 4894  (with max 8000), loss: 0.01650446467101574\n",
      "train time for 4894 epochs, was 4025.4939301013947\n",
      "\n",
      "EPOCH 4896  (with max 8000), loss: 0.015840986743569374\n",
      "train time for 4896 epochs, was 4027.132047176361\n",
      "\n",
      "EPOCH 4898  (with max 8000), loss: 0.010229907929897308\n",
      "train time for 4898 epochs, was 4028.76584982872\n",
      "\n",
      "EPOCH 4900  (with max 8000), loss: 0.3230340778827667\n",
      "train time for 4900 epochs, was 4030.402064561844\n",
      "\n",
      "EPOCH 4902  (with max 8000), loss: 0.014227645471692085\n",
      "train time for 4902 epochs, was 4032.036145210266\n",
      "\n",
      "EPOCH 4904  (with max 8000), loss: 0.11112452298402786\n",
      "train time for 4904 epochs, was 4033.6721518039703\n",
      "\n",
      "EPOCH 4906  (with max 8000), loss: 0.02095114439725876\n",
      "train time for 4906 epochs, was 4035.3101501464844\n",
      "\n",
      "EPOCH 4908  (with max 8000), loss: 0.017765408381819725\n",
      "train time for 4908 epochs, was 4036.946189880371\n",
      "\n",
      "EPOCH 4910  (with max 8000), loss: 0.027174731716513634\n",
      "train time for 4910 epochs, was 4038.5842459201813\n",
      "\n",
      "EPOCH 4912  (with max 8000), loss: 0.016217835247516632\n",
      "train time for 4912 epochs, was 4040.2183623313904\n",
      "\n",
      "EPOCH 4914  (with max 8000), loss: 0.03185589239001274\n",
      "train time for 4914 epochs, was 4041.8524265289307\n",
      "\n",
      "EPOCH 4916  (with max 8000), loss: 0.019608408212661743\n",
      "train time for 4916 epochs, was 4043.486534357071\n",
      "\n",
      "EPOCH 4918  (with max 8000), loss: 0.03544598072767258\n",
      "train time for 4918 epochs, was 4045.120623111725\n",
      "\n",
      "EPOCH 4920  (with max 8000), loss: 0.016658920794725418\n",
      "train time for 4920 epochs, was 4046.7545993328094\n",
      "\n",
      "EPOCH 4922  (with max 8000), loss: 0.016844257712364197\n",
      "train time for 4922 epochs, was 4048.4178116321564\n",
      "\n",
      "EPOCH 4924  (with max 8000), loss: 0.009747837670147419\n",
      "train time for 4924 epochs, was 4050.051753759384\n",
      "\n",
      "EPOCH 4926  (with max 8000), loss: 0.02712537907063961\n",
      "train time for 4926 epochs, was 4051.6879422664642\n",
      "\n",
      "EPOCH 4928  (with max 8000), loss: 0.006587641779333353\n",
      "train time for 4928 epochs, was 4053.321897506714\n",
      "\n",
      "EPOCH 4930  (with max 8000), loss: 0.01568262092769146\n",
      "train time for 4930 epochs, was 4054.9599797725677\n",
      "\n",
      "EPOCH 4932  (with max 8000), loss: 0.004643773194402456\n",
      "train time for 4932 epochs, was 4056.593999147415\n",
      "\n",
      "EPOCH 4934  (with max 8000), loss: 0.0031450928654521704\n",
      "train time for 4934 epochs, was 4058.2278821468353\n",
      "\n",
      "EPOCH 4936  (with max 8000), loss: 0.004027943592518568\n",
      "train time for 4936 epochs, was 4059.861798763275\n",
      "\n",
      "EPOCH 4938  (with max 8000), loss: 0.002907605841755867\n",
      "train time for 4938 epochs, was 4061.497815132141\n",
      "\n",
      "EPOCH 4940  (with max 8000), loss: 0.013254089280962944\n",
      "train time for 4940 epochs, was 4063.131777048111\n",
      "\n",
      "EPOCH 4942  (with max 8000), loss: 0.009763418696820736\n",
      "train time for 4942 epochs, was 4064.7657816410065\n",
      "\n",
      "EPOCH 4944  (with max 8000), loss: 0.0035169359762221575\n",
      "train time for 4944 epochs, was 4066.399788379669\n",
      "\n",
      "EPOCH 4946  (with max 8000), loss: 0.016450919210910797\n",
      "train time for 4946 epochs, was 4068.0337245464325\n",
      "\n",
      "EPOCH 4948  (with max 8000), loss: 0.006694835145026445\n",
      "train time for 4948 epochs, was 4069.670067548752\n",
      "\n",
      "EPOCH 4950  (with max 8000), loss: 0.010418785735964775\n",
      "train time for 4950 epochs, was 4071.304004907608\n",
      "\n",
      "EPOCH 4952  (with max 8000), loss: 0.013915102928876877\n",
      "train time for 4952 epochs, was 4072.9383597373962\n",
      "\n",
      "EPOCH 4954  (with max 8000), loss: 0.017401190474629402\n",
      "train time for 4954 epochs, was 4074.574474096298\n",
      "\n",
      "EPOCH 4956  (with max 8000), loss: 0.00786985456943512\n",
      "train time for 4956 epochs, was 4076.208459854126\n",
      "\n",
      "EPOCH 4958  (with max 8000), loss: 0.007195283193141222\n",
      "train time for 4958 epochs, was 4077.842500925064\n",
      "\n",
      "EPOCH 4960  (with max 8000), loss: 0.003450979944318533\n",
      "train time for 4960 epochs, was 4079.4786949157715\n",
      "\n",
      "EPOCH 4962  (with max 8000), loss: 0.028840502724051476\n",
      "train time for 4962 epochs, was 4081.1128573417664\n",
      "\n",
      "EPOCH 4964  (with max 8000), loss: 0.01660001464188099\n",
      "train time for 4964 epochs, was 4082.746938228607\n",
      "\n",
      "EPOCH 4966  (with max 8000), loss: 0.009474731981754303\n",
      "train time for 4966 epochs, was 4084.3808064460754\n",
      "\n",
      "EPOCH 4968  (with max 8000), loss: 0.009811395779252052\n",
      "train time for 4968 epochs, was 4086.0168402194977\n",
      "\n",
      "EPOCH 4970  (with max 8000), loss: 0.008912311866879463\n",
      "train time for 4970 epochs, was 4087.6509165763855\n",
      "\n",
      "EPOCH 4972  (with max 8000), loss: 0.0021523202303797007\n",
      "train time for 4972 epochs, was 4089.284686565399\n",
      "\n",
      "EPOCH 4974  (with max 8000), loss: 0.0074776699766516685\n",
      "train time for 4974 epochs, was 4090.9186112880707\n",
      "\n",
      "EPOCH 4976  (with max 8000), loss: 0.004370151087641716\n",
      "train time for 4976 epochs, was 4092.5546202659607\n",
      "\n",
      "EPOCH 4978  (with max 8000), loss: 0.00788696389645338\n",
      "train time for 4978 epochs, was 4094.192920923233\n",
      "\n",
      "EPOCH 4980  (with max 8000), loss: 0.005172951612621546\n",
      "train time for 4980 epochs, was 4095.8268582820892\n",
      "\n",
      "EPOCH 4982  (with max 8000), loss: 0.005232822149991989\n",
      "train time for 4982 epochs, was 4097.46066570282\n",
      "\n",
      "EPOCH 4984  (with max 8000), loss: 0.0023029327858239412\n",
      "train time for 4984 epochs, was 4099.09663438797\n",
      "\n",
      "EPOCH 4986  (with max 8000), loss: 0.0037975190207362175\n",
      "train time for 4986 epochs, was 4100.732585430145\n",
      "\n",
      "EPOCH 4988  (with max 8000), loss: 0.0027091987431049347\n",
      "train time for 4988 epochs, was 4102.366699934006\n",
      "\n",
      "EPOCH 4990  (with max 8000), loss: 0.002431112341582775\n",
      "train time for 4990 epochs, was 4104.000819683075\n",
      "\n",
      "EPOCH 4992  (with max 8000), loss: 0.002632429823279381\n",
      "train time for 4992 epochs, was 4105.634984493256\n",
      "\n",
      "EPOCH 4994  (with max 8000), loss: 0.0029573722276836634\n",
      "train time for 4994 epochs, was 4107.271280765533\n",
      "\n",
      "EPOCH 4996  (with max 8000), loss: 0.0029282462783157825\n",
      "train time for 4996 epochs, was 4108.909593343735\n",
      "\n",
      "EPOCH 4998  (with max 8000), loss: 0.07316453009843826\n",
      "train time for 4998 epochs, was 4110.543518304825\n",
      "\n",
      "EPOCH 5000  (with max 8000), loss: 0.01805262081325054\n",
      "train time for 5000 epochs, was 4112.177440643311\n",
      "\n",
      "EPOCH 5000 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_5000.pth\n",
      "\n",
      "EPOCH 5002  (with max 8000), loss: 0.009630249813199043\n",
      "train time for 5002 epochs, was 4113.847154855728\n",
      "\n",
      "EPOCH 5004  (with max 8000), loss: 0.0035974737256765366\n",
      "train time for 5004 epochs, was 4115.481296300888\n",
      "\n",
      "EPOCH 5006  (with max 8000), loss: 0.020856020972132683\n",
      "train time for 5006 epochs, was 4117.115491867065\n",
      "\n",
      "EPOCH 5008  (with max 8000), loss: 0.006385840941220522\n",
      "train time for 5008 epochs, was 4118.749585390091\n",
      "\n",
      "EPOCH 5010  (with max 8000), loss: 0.0019897562451660633\n",
      "train time for 5010 epochs, was 4120.383716344833\n",
      "\n",
      "EPOCH 5012  (with max 8000), loss: 0.005230920389294624\n",
      "train time for 5012 epochs, was 4122.017753362656\n",
      "\n",
      "EPOCH 5014  (with max 8000), loss: 0.002394256182014942\n",
      "train time for 5014 epochs, was 4123.651745080948\n",
      "\n",
      "EPOCH 5016  (with max 8000), loss: 0.003372435225173831\n",
      "train time for 5016 epochs, was 4125.285597085953\n",
      "\n",
      "EPOCH 5018  (with max 8000), loss: 0.003082102397456765\n",
      "train time for 5018 epochs, was 4126.919545888901\n",
      "\n",
      "EPOCH 5020  (with max 8000), loss: 0.005618615075945854\n",
      "train time for 5020 epochs, was 4128.58898806572\n",
      "\n",
      "EPOCH 5022  (with max 8000), loss: 0.0179340448230505\n",
      "train time for 5022 epochs, was 4130.223464727402\n",
      "\n",
      "EPOCH 5024  (with max 8000), loss: 0.009884437546133995\n",
      "train time for 5024 epochs, was 4131.859446763992\n",
      "\n",
      "EPOCH 5026  (with max 8000), loss: 0.006622439716011286\n",
      "train time for 5026 epochs, was 4133.495544672012\n",
      "\n",
      "EPOCH 5028  (with max 8000), loss: 0.002630658447742462\n",
      "train time for 5028 epochs, was 4135.133801460266\n",
      "\n",
      "EPOCH 5030  (with max 8000), loss: 0.021650025621056557\n",
      "train time for 5030 epochs, was 4136.7676067352295\n",
      "\n",
      "EPOCH 5032  (with max 8000), loss: 0.005526809487491846\n",
      "train time for 5032 epochs, was 4138.4058628082275\n",
      "\n",
      "EPOCH 5034  (with max 8000), loss: 0.014681407250463963\n",
      "train time for 5034 epochs, was 4140.041818141937\n",
      "\n",
      "EPOCH 5036  (with max 8000), loss: 0.008268156088888645\n",
      "train time for 5036 epochs, was 4141.677756309509\n",
      "\n",
      "EPOCH 5038  (with max 8000), loss: 0.005254983901977539\n",
      "train time for 5038 epochs, was 4143.316076040268\n",
      "\n",
      "EPOCH 5040  (with max 8000), loss: 0.021191421896219254\n",
      "train time for 5040 epochs, was 4144.9502239227295\n",
      "\n",
      "EPOCH 5042  (with max 8000), loss: 0.004483767319470644\n",
      "train time for 5042 epochs, was 4146.584157943726\n",
      "\n",
      "EPOCH 5044  (with max 8000), loss: 0.00578088965266943\n",
      "train time for 5044 epochs, was 4148.220314741135\n",
      "\n",
      "EPOCH 5046  (with max 8000), loss: 0.017316525802016258\n",
      "train time for 5046 epochs, was 4149.8541004657745\n",
      "\n",
      "EPOCH 5048  (with max 8000), loss: 0.007730948273092508\n",
      "train time for 5048 epochs, was 4151.500518321991\n",
      "\n",
      "EPOCH 5050  (with max 8000), loss: 0.05528166890144348\n",
      "train time for 5050 epochs, was 4153.13424539566\n",
      "\n",
      "EPOCH 5052  (with max 8000), loss: 0.048615600913763046\n",
      "train time for 5052 epochs, was 4154.770238637924\n",
      "\n",
      "EPOCH 5054  (with max 8000), loss: 0.01628980040550232\n",
      "train time for 5054 epochs, was 4156.403979063034\n",
      "\n",
      "EPOCH 5056  (with max 8000), loss: 0.006642561871558428\n",
      "train time for 5056 epochs, was 4158.037851572037\n",
      "\n",
      "EPOCH 5058  (with max 8000), loss: 0.04525873810052872\n",
      "train time for 5058 epochs, was 4159.676197767258\n",
      "\n",
      "EPOCH 5060  (with max 8000), loss: 0.2457178831100464\n",
      "train time for 5060 epochs, was 4161.310194015503\n",
      "\n",
      "EPOCH 5062  (with max 8000), loss: 0.17881707847118378\n",
      "train time for 5062 epochs, was 4162.944257259369\n",
      "\n",
      "EPOCH 5064  (with max 8000), loss: 0.06507540494203568\n",
      "train time for 5064 epochs, was 4164.582515478134\n",
      "\n",
      "EPOCH 5066  (with max 8000), loss: 0.05984581634402275\n",
      "train time for 5066 epochs, was 4166.216530799866\n",
      "\n",
      "EPOCH 5068  (with max 8000), loss: 0.054112788289785385\n",
      "train time for 5068 epochs, was 4167.850357055664\n",
      "\n",
      "EPOCH 5070  (with max 8000), loss: 0.02658577635884285\n",
      "train time for 5070 epochs, was 4169.484591960907\n",
      "\n",
      "EPOCH 5072  (with max 8000), loss: 0.052802231162786484\n",
      "train time for 5072 epochs, was 4171.1207010746\n",
      "\n",
      "EPOCH 5074  (with max 8000), loss: 0.024902742356061935\n",
      "train time for 5074 epochs, was 4172.754374504089\n",
      "\n",
      "EPOCH 5076  (with max 8000), loss: 0.02713596262037754\n",
      "train time for 5076 epochs, was 4174.392543077469\n",
      "\n",
      "EPOCH 5078  (with max 8000), loss: 0.028167173266410828\n",
      "train time for 5078 epochs, was 4176.02649474144\n",
      "\n",
      "EPOCH 5080  (with max 8000), loss: 0.045464299619197845\n",
      "train time for 5080 epochs, was 4177.660499572754\n",
      "\n",
      "EPOCH 5082  (with max 8000), loss: 0.0214945487678051\n",
      "train time for 5082 epochs, was 4179.294398784637\n",
      "\n",
      "EPOCH 5084  (with max 8000), loss: 0.019323760643601418\n",
      "train time for 5084 epochs, was 4180.928270578384\n",
      "\n",
      "EPOCH 5086  (with max 8000), loss: 0.029527932405471802\n",
      "train time for 5086 epochs, was 4182.562119960785\n",
      "\n",
      "EPOCH 5088  (with max 8000), loss: 0.014515580609440804\n",
      "train time for 5088 epochs, was 4184.196000337601\n",
      "\n",
      "EPOCH 5090  (with max 8000), loss: 0.013532411307096481\n",
      "train time for 5090 epochs, was 4185.829848051071\n",
      "\n",
      "EPOCH 5092  (with max 8000), loss: 0.009145366959273815\n",
      "train time for 5092 epochs, was 4187.463709115982\n",
      "\n",
      "EPOCH 5094  (with max 8000), loss: 0.01010151207447052\n",
      "train time for 5094 epochs, was 4189.0977239608765\n",
      "\n",
      "EPOCH 5096  (with max 8000), loss: 0.010196714662015438\n",
      "train time for 5096 epochs, was 4190.733644247055\n",
      "\n",
      "EPOCH 5098  (with max 8000), loss: 0.00981552992016077\n",
      "train time for 5098 epochs, was 4192.367575645447\n",
      "\n",
      "EPOCH 5100  (with max 8000), loss: 0.03190024942159653\n",
      "train time for 5100 epochs, was 4194.003490686417\n",
      "\n",
      "EPOCH 5102  (with max 8000), loss: 0.028592074289917946\n",
      "train time for 5102 epochs, was 4195.641638755798\n",
      "\n",
      "EPOCH 5104  (with max 8000), loss: 0.014281167648732662\n",
      "train time for 5104 epochs, was 4197.2754962444305\n",
      "\n",
      "EPOCH 5106  (with max 8000), loss: 0.012165076099336147\n",
      "train time for 5106 epochs, was 4198.913536787033\n",
      "\n",
      "EPOCH 5108  (with max 8000), loss: 0.014842800796031952\n",
      "train time for 5108 epochs, was 4200.576605796814\n",
      "\n",
      "EPOCH 5110  (with max 8000), loss: 0.008592990227043629\n",
      "train time for 5110 epochs, was 4202.210619211197\n",
      "\n",
      "EPOCH 5112  (with max 8000), loss: 0.009764512069523335\n",
      "train time for 5112 epochs, was 4203.84437918663\n",
      "\n",
      "EPOCH 5114  (with max 8000), loss: 0.004821692127734423\n",
      "train time for 5114 epochs, was 4205.480172634125\n",
      "\n",
      "EPOCH 5116  (with max 8000), loss: 0.015560283325612545\n",
      "train time for 5116 epochs, was 4207.11599779129\n",
      "\n",
      "EPOCH 5118  (with max 8000), loss: 0.022283123806118965\n",
      "train time for 5118 epochs, was 4208.749845743179\n",
      "\n",
      "EPOCH 5120  (with max 8000), loss: 0.024187516421079636\n",
      "train time for 5120 epochs, was 4210.398482084274\n",
      "\n",
      "EPOCH 5122  (with max 8000), loss: 0.010606150142848492\n",
      "train time for 5122 epochs, was 4212.03431892395\n",
      "\n",
      "EPOCH 5124  (with max 8000), loss: 0.013795632869005203\n",
      "train time for 5124 epochs, was 4213.67004942894\n",
      "\n",
      "EPOCH 5126  (with max 8000), loss: 0.006891187746077776\n",
      "train time for 5126 epochs, was 4215.3038873672485\n",
      "\n",
      "EPOCH 5128  (with max 8000), loss: 0.006314111407846212\n",
      "train time for 5128 epochs, was 4216.939808607101\n",
      "\n",
      "EPOCH 5130  (with max 8000), loss: 0.005839604884386063\n",
      "train time for 5130 epochs, was 4218.575773715973\n",
      "\n",
      "EPOCH 5132  (with max 8000), loss: 0.009665070101618767\n",
      "train time for 5132 epochs, was 4220.211951494217\n",
      "\n",
      "EPOCH 5134  (with max 8000), loss: 0.006817273795604706\n",
      "train time for 5134 epochs, was 4221.846129894257\n",
      "\n",
      "EPOCH 5136  (with max 8000), loss: 0.0090390769764781\n",
      "train time for 5136 epochs, was 4223.480197429657\n",
      "\n",
      "EPOCH 5138  (with max 8000), loss: 0.01577582396566868\n",
      "train time for 5138 epochs, was 4225.114174365997\n",
      "\n",
      "EPOCH 5140  (with max 8000), loss: 0.024790717288851738\n",
      "train time for 5140 epochs, was 4226.74794960022\n",
      "\n",
      "EPOCH 5142  (with max 8000), loss: 0.003599602496251464\n",
      "train time for 5142 epochs, was 4228.381611585617\n",
      "\n",
      "EPOCH 5144  (with max 8000), loss: 0.02142617665231228\n",
      "train time for 5144 epochs, was 4230.015236616135\n",
      "\n",
      "EPOCH 5146  (with max 8000), loss: 0.01175145898014307\n",
      "train time for 5146 epochs, was 4231.651338100433\n",
      "\n",
      "EPOCH 5148  (with max 8000), loss: 0.00908579584211111\n",
      "train time for 5148 epochs, was 4233.285093545914\n",
      "\n",
      "EPOCH 5150  (with max 8000), loss: 0.004216509871184826\n",
      "train time for 5150 epochs, was 4234.921092510223\n",
      "\n",
      "EPOCH 5152  (with max 8000), loss: 0.015746593475341797\n",
      "train time for 5152 epochs, was 4236.5549528598785\n",
      "\n",
      "EPOCH 5154  (with max 8000), loss: 0.004087982699275017\n",
      "train time for 5154 epochs, was 4238.193268299103\n",
      "\n",
      "EPOCH 5156  (with max 8000), loss: 0.007427123375236988\n",
      "train time for 5156 epochs, was 4239.829289197922\n",
      "\n",
      "EPOCH 5158  (with max 8000), loss: 0.007296436000615358\n",
      "train time for 5158 epochs, was 4241.4630291461945\n",
      "\n",
      "EPOCH 5160  (with max 8000), loss: 0.008646571077406406\n",
      "train time for 5160 epochs, was 4243.096805334091\n",
      "\n",
      "EPOCH 5162  (with max 8000), loss: 0.006159902550280094\n",
      "train time for 5162 epochs, was 4244.735013246536\n",
      "\n",
      "EPOCH 5164  (with max 8000), loss: 0.0049991849809885025\n",
      "train time for 5164 epochs, was 4246.368791818619\n",
      "\n",
      "EPOCH 5166  (with max 8000), loss: 0.015437766909599304\n",
      "train time for 5166 epochs, was 4248.004772424698\n",
      "\n",
      "EPOCH 5168  (with max 8000), loss: 0.005823772866278887\n",
      "train time for 5168 epochs, was 4249.640927553177\n",
      "\n",
      "EPOCH 5170  (with max 8000), loss: 0.003665426978841424\n",
      "train time for 5170 epochs, was 4251.279260635376\n",
      "\n",
      "EPOCH 5172  (with max 8000), loss: 0.013946772553026676\n",
      "train time for 5172 epochs, was 4252.913331747055\n",
      "\n",
      "EPOCH 5174  (with max 8000), loss: 0.023167066276073456\n",
      "train time for 5174 epochs, was 4254.547485589981\n",
      "\n",
      "EPOCH 5176  (with max 8000), loss: 0.02178538590669632\n",
      "train time for 5176 epochs, was 4256.183519363403\n",
      "\n",
      "EPOCH 5178  (with max 8000), loss: 0.01401811558753252\n",
      "train time for 5178 epochs, was 4257.8215935230255\n",
      "\n",
      "EPOCH 5180  (with max 8000), loss: 0.005644813645631075\n",
      "train time for 5180 epochs, was 4259.457673549652\n",
      "\n",
      "EPOCH 5182  (with max 8000), loss: 0.004589213989675045\n",
      "train time for 5182 epochs, was 4261.0937621593475\n",
      "\n",
      "EPOCH 5184  (with max 8000), loss: 0.017289599403738976\n",
      "train time for 5184 epochs, was 4262.727653503418\n",
      "\n",
      "EPOCH 5186  (with max 8000), loss: 0.013314077630639076\n",
      "train time for 5186 epochs, was 4264.363487243652\n",
      "\n",
      "EPOCH 5188  (with max 8000), loss: 0.010094364173710346\n",
      "train time for 5188 epochs, was 4265.997302532196\n",
      "\n",
      "EPOCH 5190  (with max 8000), loss: 0.01587492600083351\n",
      "train time for 5190 epochs, was 4267.631383657455\n",
      "\n",
      "EPOCH 5192  (with max 8000), loss: 0.003896381938830018\n",
      "train time for 5192 epochs, was 4269.26514005661\n",
      "\n",
      "EPOCH 5194  (with max 8000), loss: 0.008583429269492626\n",
      "train time for 5194 epochs, was 4270.898990392685\n",
      "\n",
      "EPOCH 5196  (with max 8000), loss: 0.02537861466407776\n",
      "train time for 5196 epochs, was 4272.532756328583\n",
      "\n",
      "EPOCH 5198  (with max 8000), loss: 0.02173677459359169\n",
      "train time for 5198 epochs, was 4274.166871786118\n",
      "\n",
      "EPOCH 5200  (with max 8000), loss: 0.012453182600438595\n",
      "train time for 5200 epochs, was 4275.821613550186\n",
      "\n",
      "EPOCH 5200 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_5200.pth\n",
      "\n",
      "EPOCH 5202  (with max 8000), loss: 0.00833966862410307\n",
      "train time for 5202 epochs, was 4277.489262104034\n",
      "\n",
      "EPOCH 5204  (with max 8000), loss: 0.04017136991024017\n",
      "train time for 5204 epochs, was 4279.123285770416\n",
      "\n",
      "EPOCH 5206  (with max 8000), loss: 2.8479926586151123\n",
      "train time for 5206 epochs, was 4280.782406568527\n",
      "\n",
      "EPOCH 5208  (with max 8000), loss: 0.08018352836370468\n",
      "train time for 5208 epochs, was 4282.422582864761\n",
      "\n",
      "EPOCH 5210  (with max 8000), loss: 0.07884540408849716\n",
      "train time for 5210 epochs, was 4284.058362960815\n",
      "\n",
      "EPOCH 5212  (with max 8000), loss: 0.03648928180336952\n",
      "train time for 5212 epochs, was 4285.694541692734\n",
      "\n",
      "EPOCH 5214  (with max 8000), loss: 0.04201206564903259\n",
      "train time for 5214 epochs, was 4287.328680753708\n",
      "\n",
      "EPOCH 5216  (with max 8000), loss: 0.02701118029654026\n",
      "train time for 5216 epochs, was 4288.964869022369\n",
      "\n",
      "EPOCH 5218  (with max 8000), loss: 0.04740459471940994\n",
      "train time for 5218 epochs, was 4290.611192703247\n",
      "\n",
      "EPOCH 5220  (with max 8000), loss: 0.030105626210570335\n",
      "train time for 5220 epochs, was 4292.251264572144\n",
      "\n",
      "EPOCH 5222  (with max 8000), loss: 0.023014089092612267\n",
      "train time for 5222 epochs, was 4293.884820461273\n",
      "\n",
      "EPOCH 5224  (with max 8000), loss: 0.036760538816452026\n",
      "train time for 5224 epochs, was 4295.520763397217\n",
      "\n",
      "EPOCH 5226  (with max 8000), loss: 0.018405187875032425\n",
      "train time for 5226 epochs, was 4297.154606580734\n",
      "\n",
      "EPOCH 5228  (with max 8000), loss: 0.01266823336482048\n",
      "train time for 5228 epochs, was 4298.788371086121\n",
      "\n",
      "EPOCH 5230  (with max 8000), loss: 0.011711942963302135\n",
      "train time for 5230 epochs, was 4300.422296285629\n",
      "\n",
      "EPOCH 5232  (with max 8000), loss: 0.027521485462784767\n",
      "train time for 5232 epochs, was 4302.055996656418\n",
      "\n",
      "EPOCH 5234  (with max 8000), loss: 0.004974338226020336\n",
      "train time for 5234 epochs, was 4303.689497232437\n",
      "\n",
      "EPOCH 5236  (with max 8000), loss: 0.008533619344234467\n",
      "train time for 5236 epochs, was 4305.32312130928\n",
      "\n",
      "EPOCH 5238  (with max 8000), loss: 0.015070918947458267\n",
      "train time for 5238 epochs, was 4306.959028720856\n",
      "\n",
      "EPOCH 5240  (with max 8000), loss: 0.01715594157576561\n",
      "train time for 5240 epochs, was 4308.594732284546\n",
      "\n",
      "EPOCH 5242  (with max 8000), loss: 0.02119370363652706\n",
      "train time for 5242 epochs, was 4310.228764295578\n",
      "\n",
      "EPOCH 5244  (with max 8000), loss: 0.02160773240029812\n",
      "train time for 5244 epochs, was 4311.898064374924\n",
      "\n",
      "EPOCH 5246  (with max 8000), loss: 0.019469892606139183\n",
      "train time for 5246 epochs, was 4313.542476177216\n",
      "\n",
      "EPOCH 5248  (with max 8000), loss: 0.020247863605618477\n",
      "train time for 5248 epochs, was 4315.1762890815735\n",
      "\n",
      "EPOCH 5250  (with max 8000), loss: 0.013968484476208687\n",
      "train time for 5250 epochs, was 4316.810320854187\n",
      "\n",
      "EPOCH 5252  (with max 8000), loss: 0.01969059556722641\n",
      "train time for 5252 epochs, was 4318.444112300873\n",
      "\n",
      "EPOCH 5254  (with max 8000), loss: 0.012230024673044682\n",
      "train time for 5254 epochs, was 4320.077788114548\n",
      "\n",
      "EPOCH 5256  (with max 8000), loss: 0.012205351144075394\n",
      "train time for 5256 epochs, was 4321.711513757706\n",
      "\n",
      "EPOCH 5258  (with max 8000), loss: 0.012362451292574406\n",
      "train time for 5258 epochs, was 4323.345248699188\n",
      "\n",
      "EPOCH 5260  (with max 8000), loss: 0.02139647863805294\n",
      "train time for 5260 epochs, was 4324.979248523712\n",
      "\n",
      "EPOCH 5262  (with max 8000), loss: 0.02337353676557541\n",
      "train time for 5262 epochs, was 4326.613187551498\n",
      "\n",
      "EPOCH 5264  (with max 8000), loss: 0.013603976927697659\n",
      "train time for 5264 epochs, was 4328.25551366806\n",
      "\n",
      "EPOCH 5266  (with max 8000), loss: 0.018985385075211525\n",
      "train time for 5266 epochs, was 4329.889267683029\n",
      "\n",
      "EPOCH 5268  (with max 8000), loss: 0.010059261694550514\n",
      "train time for 5268 epochs, was 4331.529303789139\n",
      "\n",
      "EPOCH 5270  (with max 8000), loss: 0.021219734102487564\n",
      "train time for 5270 epochs, was 4333.163033246994\n",
      "\n",
      "EPOCH 5272  (with max 8000), loss: 0.02501159906387329\n",
      "train time for 5272 epochs, was 4334.796650886536\n",
      "\n",
      "EPOCH 5274  (with max 8000), loss: 0.01816588267683983\n",
      "train time for 5274 epochs, was 4336.430257797241\n",
      "\n",
      "EPOCH 5276  (with max 8000), loss: 0.006591315381228924\n",
      "train time for 5276 epochs, was 4338.064081430435\n",
      "\n",
      "EPOCH 5278  (with max 8000), loss: 0.02535846456885338\n",
      "train time for 5278 epochs, was 4339.701929330826\n",
      "\n",
      "EPOCH 5280  (with max 8000), loss: 0.011012204922735691\n",
      "train time for 5280 epochs, was 4341.335632801056\n",
      "\n",
      "EPOCH 5282  (with max 8000), loss: 0.011248738504946232\n",
      "train time for 5282 epochs, was 4342.973499059677\n",
      "\n",
      "EPOCH 5284  (with max 8000), loss: 0.014774967916309834\n",
      "train time for 5284 epochs, was 4344.607177495956\n",
      "\n",
      "EPOCH 5286  (with max 8000), loss: 0.009046311490237713\n",
      "train time for 5286 epochs, was 4346.241003274918\n",
      "\n",
      "EPOCH 5288  (with max 8000), loss: 0.020709175616502762\n",
      "train time for 5288 epochs, was 4347.897704601288\n",
      "\n",
      "EPOCH 5290  (with max 8000), loss: 0.016821734607219696\n",
      "train time for 5290 epochs, was 4349.533556699753\n",
      "\n",
      "EPOCH 5292  (with max 8000), loss: 0.006737685762345791\n",
      "train time for 5292 epochs, was 4351.167229652405\n",
      "\n",
      "EPOCH 5294  (with max 8000), loss: 0.01034433301538229\n",
      "train time for 5294 epochs, was 4352.803137302399\n",
      "\n",
      "EPOCH 5296  (with max 8000), loss: 0.025793153792619705\n",
      "train time for 5296 epochs, was 4354.436898231506\n",
      "\n",
      "EPOCH 5298  (with max 8000), loss: 0.003770646173506975\n",
      "train time for 5298 epochs, was 4356.070560693741\n",
      "\n",
      "EPOCH 5300  (with max 8000), loss: 0.010527476668357849\n",
      "train time for 5300 epochs, was 4357.704425573349\n",
      "\n",
      "EPOCH 5302  (with max 8000), loss: 0.00790206715464592\n",
      "train time for 5302 epochs, was 4359.33841586113\n",
      "\n",
      "EPOCH 5304  (with max 8000), loss: 0.007618224248290062\n",
      "train time for 5304 epochs, was 4360.972138643265\n",
      "\n",
      "EPOCH 5306  (with max 8000), loss: 0.009104100055992603\n",
      "train time for 5306 epochs, was 4362.605962514877\n",
      "\n",
      "EPOCH 5308  (with max 8000), loss: 0.009498189203441143\n",
      "train time for 5308 epochs, was 4364.239967823029\n",
      "\n",
      "EPOCH 5310  (with max 8000), loss: 0.013502411544322968\n",
      "train time for 5310 epochs, was 4365.873755455017\n",
      "\n",
      "EPOCH 5312  (with max 8000), loss: 0.005834012757986784\n",
      "train time for 5312 epochs, was 4367.509751796722\n",
      "\n",
      "EPOCH 5314  (with max 8000), loss: 0.017993127927184105\n",
      "train time for 5314 epochs, was 4369.143892526627\n",
      "\n",
      "EPOCH 5316  (with max 8000), loss: 0.015190169215202332\n",
      "train time for 5316 epochs, was 4370.779875040054\n",
      "\n",
      "EPOCH 5318  (with max 8000), loss: 0.017422132194042206\n",
      "train time for 5318 epochs, was 4372.415829658508\n",
      "\n",
      "EPOCH 5320  (with max 8000), loss: 0.024307625368237495\n",
      "train time for 5320 epochs, was 4374.05210185051\n",
      "\n",
      "EPOCH 5322  (with max 8000), loss: 0.009350063279271126\n",
      "train time for 5322 epochs, was 4375.690074205399\n",
      "\n",
      "EPOCH 5324  (with max 8000), loss: 0.008904187008738518\n",
      "train time for 5324 epochs, was 4377.325917720795\n",
      "\n",
      "EPOCH 5326  (with max 8000), loss: 0.010708835907280445\n",
      "train time for 5326 epochs, was 4378.959645271301\n",
      "\n",
      "EPOCH 5328  (with max 8000), loss: 0.007706307340413332\n",
      "train time for 5328 epochs, was 4380.593467950821\n",
      "\n",
      "EPOCH 5330  (with max 8000), loss: 0.02475251629948616\n",
      "train time for 5330 epochs, was 4382.227588176727\n",
      "\n",
      "EPOCH 5332  (with max 8000), loss: 0.015687763690948486\n",
      "train time for 5332 epochs, was 4383.861394643784\n",
      "\n",
      "EPOCH 5334  (with max 8000), loss: 0.009817352518439293\n",
      "train time for 5334 epochs, was 4385.499346971512\n",
      "\n",
      "EPOCH 5336  (with max 8000), loss: 0.01489400677382946\n",
      "train time for 5336 epochs, was 4387.13302898407\n",
      "\n",
      "EPOCH 5338  (with max 8000), loss: 0.16668228805065155\n",
      "train time for 5338 epochs, was 4388.769072294235\n",
      "\n",
      "EPOCH 5340  (with max 8000), loss: 0.020079074427485466\n",
      "train time for 5340 epochs, was 4390.411412477493\n",
      "\n",
      "EPOCH 5342  (with max 8000), loss: 0.016601942479610443\n",
      "train time for 5342 epochs, was 4392.053609132767\n",
      "\n",
      "EPOCH 5344  (with max 8000), loss: 0.013932588510215282\n",
      "train time for 5344 epochs, was 4393.687760591507\n",
      "\n",
      "EPOCH 5346  (with max 8000), loss: 0.013068192638456821\n",
      "train time for 5346 epochs, was 4395.323737382889\n",
      "\n",
      "EPOCH 5348  (with max 8000), loss: 0.010720889084041119\n",
      "train time for 5348 epochs, was 4396.957631349564\n",
      "\n",
      "EPOCH 5350  (with max 8000), loss: 0.006662988569587469\n",
      "train time for 5350 epochs, was 4398.593668460846\n",
      "\n",
      "EPOCH 5352  (with max 8000), loss: 0.009450708515942097\n",
      "train time for 5352 epochs, was 4400.227359294891\n",
      "\n",
      "EPOCH 5354  (with max 8000), loss: 0.03344016894698143\n",
      "train time for 5354 epochs, was 4401.861073732376\n",
      "\n",
      "EPOCH 5356  (with max 8000), loss: 0.1692211925983429\n",
      "train time for 5356 epochs, was 4403.495021820068\n",
      "\n",
      "EPOCH 5358  (with max 8000), loss: 0.07786035537719727\n",
      "train time for 5358 epochs, was 4405.128551244736\n",
      "\n",
      "EPOCH 5360  (with max 8000), loss: 0.020531058311462402\n",
      "train time for 5360 epochs, was 4406.762088537216\n",
      "\n",
      "EPOCH 5362  (with max 8000), loss: 0.008669976145029068\n",
      "train time for 5362 epochs, was 4408.396006822586\n",
      "\n",
      "EPOCH 5364  (with max 8000), loss: 0.018358031287789345\n",
      "train time for 5364 epochs, was 4410.030054569244\n",
      "\n",
      "EPOCH 5366  (with max 8000), loss: 0.004845508374273777\n",
      "train time for 5366 epochs, was 4411.664216041565\n",
      "\n",
      "EPOCH 5368  (with max 8000), loss: 0.011073152534663677\n",
      "train time for 5368 epochs, was 4413.298088550568\n",
      "\n",
      "EPOCH 5370  (with max 8000), loss: 0.01134396530687809\n",
      "train time for 5370 epochs, was 4414.938351869583\n",
      "\n",
      "EPOCH 5372  (with max 8000), loss: 0.007979595102369785\n",
      "train time for 5372 epochs, was 4416.572381258011\n",
      "\n",
      "EPOCH 5374  (with max 8000), loss: 0.012034418061375618\n",
      "train time for 5374 epochs, was 4418.206367492676\n",
      "\n",
      "EPOCH 5376  (with max 8000), loss: 0.011072482913732529\n",
      "train time for 5376 epochs, was 4419.8401091098785\n",
      "\n",
      "EPOCH 5378  (with max 8000), loss: 0.0071164281107485294\n",
      "train time for 5378 epochs, was 4421.475951194763\n",
      "\n",
      "EPOCH 5380  (with max 8000), loss: 0.008939119055867195\n",
      "train time for 5380 epochs, was 4423.120155572891\n",
      "\n",
      "EPOCH 5382  (with max 8000), loss: 0.0037383355665951967\n",
      "train time for 5382 epochs, was 4424.783281803131\n",
      "\n",
      "EPOCH 5384  (with max 8000), loss: 0.011237853206694126\n",
      "train time for 5384 epochs, was 4426.417227268219\n",
      "\n",
      "EPOCH 5386  (with max 8000), loss: 0.008885650895535946\n",
      "train time for 5386 epochs, was 4428.053074598312\n",
      "\n",
      "EPOCH 5388  (with max 8000), loss: 0.09049424529075623\n",
      "train time for 5388 epochs, was 4429.687029838562\n",
      "\n",
      "EPOCH 5390  (with max 8000), loss: 0.022525157779455185\n",
      "train time for 5390 epochs, was 4431.321036577225\n",
      "\n",
      "EPOCH 5392  (with max 8000), loss: 0.011963087134063244\n",
      "train time for 5392 epochs, was 4432.954747676849\n",
      "\n",
      "EPOCH 5394  (with max 8000), loss: 0.026306232437491417\n",
      "train time for 5394 epochs, was 4434.588358402252\n",
      "\n",
      "EPOCH 5396  (with max 8000), loss: 0.011558749713003635\n",
      "train time for 5396 epochs, was 4436.222021102905\n",
      "\n",
      "EPOCH 5398  (with max 8000), loss: 0.012645739130675793\n",
      "train time for 5398 epochs, was 4437.855971336365\n",
      "\n",
      "EPOCH 5400  (with max 8000), loss: 0.01703474670648575\n",
      "train time for 5400 epochs, was 4439.490020751953\n",
      "\n",
      "EPOCH 5400 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_5400.pth\n",
      "\n",
      "EPOCH 5402  (with max 8000), loss: 0.005377921741455793\n",
      "train time for 5402 epochs, was 4441.167702198029\n",
      "\n",
      "EPOCH 5404  (with max 8000), loss: 0.01900804415345192\n",
      "train time for 5404 epochs, was 4442.801347255707\n",
      "\n",
      "EPOCH 5406  (with max 8000), loss: 0.012542852200567722\n",
      "train time for 5406 epochs, was 4444.435298204422\n",
      "\n",
      "EPOCH 5408  (with max 8000), loss: 0.013312006369233131\n",
      "train time for 5408 epochs, was 4446.0691068172455\n",
      "\n",
      "EPOCH 5410  (with max 8000), loss: 0.011010799556970596\n",
      "train time for 5410 epochs, was 4447.702675819397\n",
      "\n",
      "EPOCH 5412  (with max 8000), loss: 0.00809384137392044\n",
      "train time for 5412 epochs, was 4449.340497255325\n",
      "\n",
      "EPOCH 5414  (with max 8000), loss: 0.02360762655735016\n",
      "train time for 5414 epochs, was 4450.974448442459\n",
      "\n",
      "EPOCH 5416  (with max 8000), loss: 1.989661693572998\n",
      "train time for 5416 epochs, was 4452.616641044617\n",
      "\n",
      "EPOCH 5418  (with max 8000), loss: 0.12471575289964676\n",
      "train time for 5418 epochs, was 4454.250139951706\n",
      "\n",
      "EPOCH 5420  (with max 8000), loss: 0.16368304193019867\n",
      "train time for 5420 epochs, was 4455.883730173111\n",
      "\n",
      "EPOCH 5422  (with max 8000), loss: 0.0633099153637886\n",
      "train time for 5422 epochs, was 4457.517196178436\n",
      "\n",
      "EPOCH 5424  (with max 8000), loss: 0.05897308886051178\n",
      "train time for 5424 epochs, was 4459.16553735733\n",
      "\n",
      "EPOCH 5426  (with max 8000), loss: 0.05279006063938141\n",
      "train time for 5426 epochs, was 4460.799849033356\n",
      "\n",
      "EPOCH 5428  (with max 8000), loss: 0.022285694256424904\n",
      "train time for 5428 epochs, was 4462.433939695358\n",
      "\n",
      "EPOCH 5430  (with max 8000), loss: 0.022239092737436295\n",
      "train time for 5430 epochs, was 4464.067986726761\n",
      "\n",
      "EPOCH 5432  (with max 8000), loss: 0.0401369109749794\n",
      "train time for 5432 epochs, was 4465.701815605164\n",
      "\n",
      "EPOCH 5434  (with max 8000), loss: 0.037111006677150726\n",
      "train time for 5434 epochs, was 4467.335729837418\n",
      "\n",
      "EPOCH 5436  (with max 8000), loss: 0.03867623582482338\n",
      "train time for 5436 epochs, was 4468.969548463821\n",
      "\n",
      "EPOCH 5438  (with max 8000), loss: 0.023451494053006172\n",
      "train time for 5438 epochs, was 4470.603214740753\n",
      "\n",
      "EPOCH 5440  (with max 8000), loss: 0.020990654826164246\n",
      "train time for 5440 epochs, was 4472.237160682678\n",
      "\n",
      "EPOCH 5442  (with max 8000), loss: 0.021541301161050797\n",
      "train time for 5442 epochs, was 4473.870991706848\n",
      "\n",
      "EPOCH 5444  (with max 8000), loss: 0.02260766737163067\n",
      "train time for 5444 epochs, was 4475.504875421524\n",
      "\n",
      "EPOCH 5446  (with max 8000), loss: 0.01588021218776703\n",
      "train time for 5446 epochs, was 4477.1383934021\n",
      "\n",
      "EPOCH 5448  (with max 8000), loss: 0.01720251329243183\n",
      "train time for 5448 epochs, was 4478.772070407867\n",
      "\n",
      "EPOCH 5450  (with max 8000), loss: 0.01936447061598301\n",
      "train time for 5450 epochs, was 4480.407795190811\n",
      "\n",
      "EPOCH 5452  (with max 8000), loss: 0.007117823697626591\n",
      "train time for 5452 epochs, was 4482.041576862335\n",
      "\n",
      "EPOCH 5454  (with max 8000), loss: 0.010224523954093456\n",
      "train time for 5454 epochs, was 4483.675616502762\n",
      "\n",
      "EPOCH 5456  (with max 8000), loss: 0.01026960089802742\n",
      "train time for 5456 epochs, was 4485.3092648983\n",
      "\n",
      "EPOCH 5458  (with max 8000), loss: 0.014536621049046516\n",
      "train time for 5458 epochs, was 4486.944896936417\n",
      "\n",
      "EPOCH 5460  (with max 8000), loss: 0.010389082133769989\n",
      "train time for 5460 epochs, was 4488.5809671878815\n",
      "\n",
      "EPOCH 5462  (with max 8000), loss: 0.00933548342436552\n",
      "train time for 5462 epochs, was 4490.214674949646\n",
      "\n",
      "EPOCH 5464  (with max 8000), loss: 0.008447466418147087\n",
      "train time for 5464 epochs, was 4491.848187446594\n",
      "\n",
      "EPOCH 5466  (with max 8000), loss: 0.014607078395783901\n",
      "train time for 5466 epochs, was 4493.481751680374\n",
      "\n",
      "EPOCH 5468  (with max 8000), loss: 0.009028070606291294\n",
      "train time for 5468 epochs, was 4495.117623806\n",
      "\n",
      "EPOCH 5470  (with max 8000), loss: 0.014271298423409462\n",
      "train time for 5470 epochs, was 4496.751520872116\n",
      "\n",
      "EPOCH 5472  (with max 8000), loss: 0.01201849989593029\n",
      "train time for 5472 epochs, was 4498.385162591934\n",
      "\n",
      "EPOCH 5474  (with max 8000), loss: 0.013789795339107513\n",
      "train time for 5474 epochs, was 4500.019018411636\n",
      "\n",
      "EPOCH 5476  (with max 8000), loss: 0.02345362864434719\n",
      "train time for 5476 epochs, was 4501.652463674545\n",
      "\n",
      "EPOCH 5478  (with max 8000), loss: 0.013645083643496037\n",
      "train time for 5478 epochs, was 4503.286151409149\n",
      "\n",
      "EPOCH 5480  (with max 8000), loss: 0.011821814812719822\n",
      "train time for 5480 epochs, was 4504.919889211655\n",
      "\n",
      "EPOCH 5482  (with max 8000), loss: 0.006654295604676008\n",
      "train time for 5482 epochs, was 4506.553592205048\n",
      "\n",
      "EPOCH 5484  (with max 8000), loss: 0.030003873631358147\n",
      "train time for 5484 epochs, was 4508.187189340591\n",
      "\n",
      "EPOCH 5486  (with max 8000), loss: 0.02382519096136093\n",
      "train time for 5486 epochs, was 4509.82074546814\n",
      "\n",
      "EPOCH 5488  (with max 8000), loss: 0.013026655651628971\n",
      "train time for 5488 epochs, was 4511.454697370529\n",
      "\n",
      "EPOCH 5490  (with max 8000), loss: 0.01289271004498005\n",
      "train time for 5490 epochs, was 4513.088532924652\n",
      "\n",
      "EPOCH 5492  (with max 8000), loss: 0.013022174127399921\n",
      "train time for 5492 epochs, was 4514.724631309509\n",
      "\n",
      "EPOCH 5494  (with max 8000), loss: 0.010033928789198399\n",
      "train time for 5494 epochs, was 4516.358302354813\n",
      "\n",
      "EPOCH 5496  (with max 8000), loss: 0.008535504341125488\n",
      "train time for 5496 epochs, was 4517.992169380188\n",
      "\n",
      "EPOCH 5498  (with max 8000), loss: 0.006795632187277079\n",
      "train time for 5498 epochs, was 4519.634207010269\n",
      "\n",
      "EPOCH 5500  (with max 8000), loss: 0.008466417901217937\n",
      "train time for 5500 epochs, was 4521.267892360687\n",
      "\n",
      "EPOCH 5502  (with max 8000), loss: 0.027522370219230652\n",
      "train time for 5502 epochs, was 4522.901510953903\n",
      "\n",
      "EPOCH 5504  (with max 8000), loss: 0.01728205196559429\n",
      "train time for 5504 epochs, was 4524.537432909012\n",
      "\n",
      "EPOCH 5506  (with max 8000), loss: 0.02197101339697838\n",
      "train time for 5506 epochs, was 4526.171073436737\n",
      "\n",
      "EPOCH 5508  (with max 8000), loss: 0.013344359584152699\n",
      "train time for 5508 epochs, was 4527.804682016373\n",
      "\n",
      "EPOCH 5510  (with max 8000), loss: 0.012310522608458996\n",
      "train time for 5510 epochs, was 4529.4382247924805\n",
      "\n",
      "EPOCH 5512  (with max 8000), loss: 0.017882920801639557\n",
      "train time for 5512 epochs, was 4531.074153184891\n",
      "\n",
      "EPOCH 5514  (with max 8000), loss: 0.027262747287750244\n",
      "train time for 5514 epochs, was 4532.709806919098\n",
      "\n",
      "EPOCH 5516  (with max 8000), loss: 0.029126640409231186\n",
      "train time for 5516 epochs, was 4534.34576010704\n",
      "\n",
      "EPOCH 5518  (with max 8000), loss: 0.011796568520367146\n",
      "train time for 5518 epochs, was 4535.98392701149\n",
      "\n",
      "EPOCH 5520  (with max 8000), loss: 0.013549095951020718\n",
      "train time for 5520 epochs, was 4537.617778539658\n",
      "\n",
      "EPOCH 5522  (with max 8000), loss: 0.02733307145535946\n",
      "train time for 5522 epochs, was 4539.253913402557\n",
      "\n",
      "EPOCH 5524  (with max 8000), loss: 0.016600528731942177\n",
      "train time for 5524 epochs, was 4540.889628648758\n",
      "\n",
      "EPOCH 5526  (with max 8000), loss: 0.016521507874131203\n",
      "train time for 5526 epochs, was 4542.523245096207\n",
      "\n",
      "EPOCH 5528  (with max 8000), loss: 0.027820754796266556\n",
      "train time for 5528 epochs, was 4544.1737105846405\n",
      "\n",
      "EPOCH 5530  (with max 8000), loss: 0.89170902967453\n",
      "train time for 5530 epochs, was 4545.80974316597\n",
      "\n",
      "EPOCH 5532  (with max 8000), loss: 0.0486752949655056\n",
      "train time for 5532 epochs, was 4547.445839166641\n",
      "\n",
      "EPOCH 5534  (with max 8000), loss: 0.031330931931734085\n",
      "train time for 5534 epochs, was 4549.081869840622\n",
      "\n",
      "EPOCH 5536  (with max 8000), loss: 0.022166263312101364\n",
      "train time for 5536 epochs, was 4550.715504169464\n",
      "\n",
      "EPOCH 5538  (with max 8000), loss: 0.022725071758031845\n",
      "train time for 5538 epochs, was 4552.349103450775\n",
      "\n",
      "EPOCH 5540  (with max 8000), loss: 0.008192483335733414\n",
      "train time for 5540 epochs, was 4553.983118772507\n",
      "\n",
      "EPOCH 5542  (with max 8000), loss: 0.014773393049836159\n",
      "train time for 5542 epochs, was 4555.617146730423\n",
      "\n",
      "EPOCH 5544  (with max 8000), loss: 0.01468510553240776\n",
      "train time for 5544 epochs, was 4557.251149654388\n",
      "\n",
      "EPOCH 5546  (with max 8000), loss: 0.007058882620185614\n",
      "train time for 5546 epochs, was 4558.884878158569\n",
      "\n",
      "EPOCH 5548  (with max 8000), loss: 0.012426394037902355\n",
      "train time for 5548 epochs, was 4560.519060134888\n",
      "\n",
      "EPOCH 5550  (with max 8000), loss: 0.0065064760856330395\n",
      "train time for 5550 epochs, was 4562.152951002121\n",
      "\n",
      "EPOCH 5552  (with max 8000), loss: 0.007123831659555435\n",
      "train time for 5552 epochs, was 4563.786738872528\n",
      "\n",
      "EPOCH 5554  (with max 8000), loss: 0.005003660451620817\n",
      "train time for 5554 epochs, was 4565.420274019241\n",
      "\n",
      "EPOCH 5556  (with max 8000), loss: 0.013427257537841797\n",
      "train time for 5556 epochs, was 4567.070919036865\n",
      "\n",
      "EPOCH 5558  (with max 8000), loss: 0.01040080189704895\n",
      "train time for 5558 epochs, was 4568.709066390991\n",
      "\n",
      "EPOCH 5560  (with max 8000), loss: 0.017115989699959755\n",
      "train time for 5560 epochs, was 4570.342979669571\n",
      "\n",
      "EPOCH 5562  (with max 8000), loss: 0.011585067957639694\n",
      "train time for 5562 epochs, was 4571.977159500122\n",
      "\n",
      "EPOCH 5564  (with max 8000), loss: 0.006355578545480967\n",
      "train time for 5564 epochs, was 4573.615204334259\n",
      "\n",
      "EPOCH 5566  (with max 8000), loss: 0.014261964708566666\n",
      "train time for 5566 epochs, was 4575.249176740646\n",
      "\n",
      "EPOCH 5568  (with max 8000), loss: 0.00721373688429594\n",
      "train time for 5568 epochs, was 4576.8849222660065\n",
      "\n",
      "EPOCH 5570  (with max 8000), loss: 0.009216154925525188\n",
      "train time for 5570 epochs, was 4578.518769741058\n",
      "\n",
      "EPOCH 5572  (with max 8000), loss: 0.011862657964229584\n",
      "train time for 5572 epochs, was 4580.152372598648\n",
      "\n",
      "EPOCH 5574  (with max 8000), loss: 0.020304184406995773\n",
      "train time for 5574 epochs, was 4581.786119222641\n",
      "\n",
      "EPOCH 5576  (with max 8000), loss: 0.009183698333799839\n",
      "train time for 5576 epochs, was 4583.419824361801\n",
      "\n",
      "EPOCH 5578  (with max 8000), loss: 0.007975509390234947\n",
      "train time for 5578 epochs, was 4585.053591012955\n",
      "\n",
      "EPOCH 5580  (with max 8000), loss: 0.007465228904038668\n",
      "train time for 5580 epochs, was 4586.689388751984\n",
      "\n",
      "EPOCH 5582  (with max 8000), loss: 0.007459660992026329\n",
      "train time for 5582 epochs, was 4588.322959423065\n",
      "\n",
      "EPOCH 5584  (with max 8000), loss: 0.007182515691965818\n",
      "train time for 5584 epochs, was 4589.956825494766\n",
      "\n",
      "EPOCH 5586  (with max 8000), loss: 0.01151718944311142\n",
      "train time for 5586 epochs, was 4591.590599775314\n",
      "\n",
      "EPOCH 5588  (with max 8000), loss: 0.014565451070666313\n",
      "train time for 5588 epochs, was 4593.2245309352875\n",
      "\n",
      "EPOCH 5590  (with max 8000), loss: 0.010177533142268658\n",
      "train time for 5590 epochs, was 4594.858265399933\n",
      "\n",
      "EPOCH 5592  (with max 8000), loss: 0.009417256340384483\n",
      "train time for 5592 epochs, was 4596.492199897766\n",
      "\n",
      "EPOCH 5594  (with max 8000), loss: 0.03353065997362137\n",
      "train time for 5594 epochs, was 4598.126049280167\n",
      "\n",
      "EPOCH 5596  (with max 8000), loss: 0.008770354092121124\n",
      "train time for 5596 epochs, was 4599.759764432907\n",
      "\n",
      "EPOCH 5598  (with max 8000), loss: 0.018365005031228065\n",
      "train time for 5598 epochs, was 4601.393442153931\n",
      "\n",
      "EPOCH 5600  (with max 8000), loss: 0.039176829159259796\n",
      "train time for 5600 epochs, was 4603.027307987213\n",
      "\n",
      "EPOCH 5600 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_5600.pth\n",
      "\n",
      "EPOCH 5602  (with max 8000), loss: 0.005001825280487537\n",
      "train time for 5602 epochs, was 4604.69472193718\n",
      "\n",
      "EPOCH 5604  (with max 8000), loss: 0.005406631622463465\n",
      "train time for 5604 epochs, was 4606.36404466629\n",
      "\n",
      "EPOCH 5606  (with max 8000), loss: 0.005513133481144905\n",
      "train time for 5606 epochs, was 4607.999940872192\n",
      "\n",
      "EPOCH 5608  (with max 8000), loss: 0.008100897073745728\n",
      "train time for 5608 epochs, was 4609.633682489395\n",
      "\n",
      "EPOCH 5610  (with max 8000), loss: 0.01302552130073309\n",
      "train time for 5610 epochs, was 4611.267592191696\n",
      "\n",
      "EPOCH 5612  (with max 8000), loss: 0.009228975512087345\n",
      "train time for 5612 epochs, was 4612.911987543106\n",
      "\n",
      "EPOCH 5614  (with max 8000), loss: 0.017388850450515747\n",
      "train time for 5614 epochs, was 4614.545992612839\n",
      "\n",
      "EPOCH 5616  (with max 8000), loss: 0.019250905141234398\n",
      "train time for 5616 epochs, was 4616.180039405823\n",
      "\n",
      "EPOCH 5618  (with max 8000), loss: 0.056626833975315094\n",
      "train time for 5618 epochs, was 4617.817884206772\n",
      "\n",
      "EPOCH 5620  (with max 8000), loss: 0.025429444387555122\n",
      "train time for 5620 epochs, was 4619.451666355133\n",
      "\n",
      "EPOCH 5622  (with max 8000), loss: 0.023333434015512466\n",
      "train time for 5622 epochs, was 4621.085024833679\n",
      "\n",
      "EPOCH 5624  (with max 8000), loss: 0.0455070361495018\n",
      "train time for 5624 epochs, was 4622.718326330185\n",
      "\n",
      "EPOCH 5626  (with max 8000), loss: 0.016160503029823303\n",
      "train time for 5626 epochs, was 4624.351742267609\n",
      "\n",
      "EPOCH 5628  (with max 8000), loss: 0.026822233572602272\n",
      "train time for 5628 epochs, was 4625.985383272171\n",
      "\n",
      "EPOCH 5630  (with max 8000), loss: 0.014978698454797268\n",
      "train time for 5630 epochs, was 4627.619002342224\n",
      "\n",
      "EPOCH 5632  (with max 8000), loss: 0.005816291086375713\n",
      "train time for 5632 epochs, was 4629.252802371979\n",
      "\n",
      "EPOCH 5634  (with max 8000), loss: 0.01433415338397026\n",
      "train time for 5634 epochs, was 4630.886431932449\n",
      "\n",
      "EPOCH 5636  (with max 8000), loss: 0.004981180187314749\n",
      "train time for 5636 epochs, was 4632.524476528168\n",
      "\n",
      "EPOCH 5638  (with max 8000), loss: 0.017265425994992256\n",
      "train time for 5638 epochs, was 4634.172646522522\n",
      "\n",
      "EPOCH 5640  (with max 8000), loss: 0.008345728740096092\n",
      "train time for 5640 epochs, was 4635.808446884155\n",
      "\n",
      "EPOCH 5642  (with max 8000), loss: 0.009112633764743805\n",
      "train time for 5642 epochs, was 4637.442023515701\n",
      "\n",
      "EPOCH 5644  (with max 8000), loss: 0.0145151661708951\n",
      "train time for 5644 epochs, was 4639.0756759643555\n",
      "\n",
      "EPOCH 5646  (with max 8000), loss: 0.005374671891331673\n",
      "train time for 5646 epochs, was 4640.709352016449\n",
      "\n",
      "EPOCH 5648  (with max 8000), loss: 0.005396424327045679\n",
      "train time for 5648 epochs, was 4642.359708309174\n",
      "\n",
      "EPOCH 5650  (with max 8000), loss: 0.003852848894894123\n",
      "train time for 5650 epochs, was 4643.993252277374\n",
      "\n",
      "EPOCH 5652  (with max 8000), loss: 0.028009802103042603\n",
      "train time for 5652 epochs, was 4645.6291790008545\n",
      "\n",
      "EPOCH 5654  (with max 8000), loss: 0.00651579350233078\n",
      "train time for 5654 epochs, was 4647.265027046204\n",
      "\n",
      "EPOCH 5656  (with max 8000), loss: 0.010665377601981163\n",
      "train time for 5656 epochs, was 4648.898999929428\n",
      "\n",
      "EPOCH 5658  (with max 8000), loss: 0.020691704005002975\n",
      "train time for 5658 epochs, was 4650.532682418823\n",
      "\n",
      "EPOCH 5660  (with max 8000), loss: 0.014751868322491646\n",
      "train time for 5660 epochs, was 4652.166285276413\n",
      "\n",
      "EPOCH 5662  (with max 8000), loss: 0.009101693518459797\n",
      "train time for 5662 epochs, was 4653.800082445145\n",
      "\n",
      "EPOCH 5664  (with max 8000), loss: 0.005496502388268709\n",
      "train time for 5664 epochs, was 4655.433705329895\n",
      "\n",
      "EPOCH 5666  (with max 8000), loss: 0.0070167467929422855\n",
      "train time for 5666 epochs, was 4657.067692279816\n",
      "\n",
      "EPOCH 5668  (with max 8000), loss: 0.005800904240459204\n",
      "train time for 5668 epochs, was 4658.701216220856\n",
      "\n",
      "EPOCH 5670  (with max 8000), loss: 0.02283449098467827\n",
      "train time for 5670 epochs, was 4660.33469581604\n",
      "\n",
      "EPOCH 5672  (with max 8000), loss: 0.02625785954296589\n",
      "train time for 5672 epochs, was 4661.980965137482\n",
      "\n",
      "EPOCH 5674  (with max 8000), loss: 0.013086698949337006\n",
      "train time for 5674 epochs, was 4663.614509344101\n",
      "\n",
      "EPOCH 5676  (with max 8000), loss: 0.011523245833814144\n",
      "train time for 5676 epochs, was 4665.24839758873\n",
      "\n",
      "EPOCH 5678  (with max 8000), loss: 0.0009693031897768378\n",
      "train time for 5678 epochs, was 4666.881877422333\n",
      "\n",
      "EPOCH 5680  (with max 8000), loss: 0.006174540147185326\n",
      "train time for 5680 epochs, was 4668.5157153606415\n",
      "\n",
      "EPOCH 5682  (with max 8000), loss: 0.004167983774095774\n",
      "train time for 5682 epochs, was 4670.149467229843\n",
      "\n",
      "EPOCH 5684  (with max 8000), loss: 0.00582607788965106\n",
      "train time for 5684 epochs, was 4671.787159919739\n",
      "\n",
      "EPOCH 5686  (with max 8000), loss: 0.02102014422416687\n",
      "train time for 5686 epochs, was 4673.42288351059\n",
      "\n",
      "EPOCH 5688  (with max 8000), loss: 0.005267235450446606\n",
      "train time for 5688 epochs, was 4675.059126615524\n",
      "\n",
      "EPOCH 5690  (with max 8000), loss: 0.0063569447956979275\n",
      "train time for 5690 epochs, was 4676.6932780742645\n",
      "\n",
      "EPOCH 5692  (with max 8000), loss: 0.19186949729919434\n",
      "train time for 5692 epochs, was 4678.354362010956\n",
      "\n",
      "EPOCH 5694  (with max 8000), loss: 0.01648012176156044\n",
      "train time for 5694 epochs, was 4679.990084409714\n",
      "\n",
      "EPOCH 5696  (with max 8000), loss: 0.03398045897483826\n",
      "train time for 5696 epochs, was 4681.623564720154\n",
      "\n",
      "EPOCH 5698  (with max 8000), loss: 0.024247227236628532\n",
      "train time for 5698 epochs, was 4683.265258550644\n",
      "\n",
      "EPOCH 5700  (with max 8000), loss: 0.014569354243576527\n",
      "train time for 5700 epochs, was 4684.898731231689\n",
      "\n",
      "EPOCH 5702  (with max 8000), loss: 0.011826171539723873\n",
      "train time for 5702 epochs, was 4686.5346603393555\n",
      "\n",
      "EPOCH 5704  (with max 8000), loss: 0.02760245092213154\n",
      "train time for 5704 epochs, was 4688.170478343964\n",
      "\n",
      "EPOCH 5706  (with max 8000), loss: 0.027893656864762306\n",
      "train time for 5706 epochs, was 4689.804526805878\n",
      "\n",
      "EPOCH 5708  (with max 8000), loss: 0.013227582909166813\n",
      "train time for 5708 epochs, was 4691.438540220261\n",
      "\n",
      "EPOCH 5710  (with max 8000), loss: 0.018088268116116524\n",
      "train time for 5710 epochs, was 4693.074390411377\n",
      "\n",
      "EPOCH 5712  (with max 8000), loss: 0.01682370901107788\n",
      "train time for 5712 epochs, was 4694.708282470703\n",
      "\n",
      "EPOCH 5714  (with max 8000), loss: 0.007154897321015596\n",
      "train time for 5714 epochs, was 4696.343694448471\n",
      "\n",
      "EPOCH 5716  (with max 8000), loss: 0.012086549773812294\n",
      "train time for 5716 epochs, was 4697.976838588715\n",
      "\n",
      "EPOCH 5718  (with max 8000), loss: 0.012717965990304947\n",
      "train time for 5718 epochs, was 4699.610126256943\n",
      "\n",
      "EPOCH 5720  (with max 8000), loss: 0.0014640080044046044\n",
      "train time for 5720 epochs, was 4701.2433342933655\n",
      "\n",
      "EPOCH 5722  (with max 8000), loss: 0.008510137908160686\n",
      "train time for 5722 epochs, was 4702.876632928848\n",
      "\n",
      "EPOCH 5724  (with max 8000), loss: 0.004944975953549147\n",
      "train time for 5724 epochs, was 4704.5185441970825\n",
      "\n",
      "EPOCH 5726  (with max 8000), loss: 0.01793925277888775\n",
      "train time for 5726 epochs, was 4706.162225961685\n",
      "\n",
      "EPOCH 5728  (with max 8000), loss: 0.14740903675556183\n",
      "train time for 5728 epochs, was 4707.795566082001\n",
      "\n",
      "EPOCH 5730  (with max 8000), loss: 0.19677305221557617\n",
      "train time for 5730 epochs, was 4709.430708408356\n",
      "\n",
      "EPOCH 5732  (with max 8000), loss: 0.06886744499206543\n",
      "train time for 5732 epochs, was 4711.087073564529\n",
      "\n",
      "EPOCH 5734  (with max 8000), loss: 0.04779056832194328\n",
      "train time for 5734 epochs, was 4712.7201635837555\n",
      "\n",
      "EPOCH 5736  (with max 8000), loss: 0.033502135425806046\n",
      "train time for 5736 epochs, was 4714.380430936813\n",
      "\n",
      "EPOCH 5738  (with max 8000), loss: 0.045348793268203735\n",
      "train time for 5738 epochs, was 4716.015781164169\n",
      "\n",
      "EPOCH 5740  (with max 8000), loss: 0.020519660785794258\n",
      "train time for 5740 epochs, was 4717.6491005420685\n",
      "\n",
      "EPOCH 5742  (with max 8000), loss: 0.026969127357006073\n",
      "train time for 5742 epochs, was 4719.282387971878\n",
      "\n",
      "EPOCH 5744  (with max 8000), loss: 0.02744969353079796\n",
      "train time for 5744 epochs, was 4720.928208351135\n",
      "\n",
      "EPOCH 5746  (with max 8000), loss: 0.016998490318655968\n",
      "train time for 5746 epochs, was 4722.561398029327\n",
      "\n",
      "EPOCH 5748  (with max 8000), loss: 0.014048180542886257\n",
      "train time for 5748 epochs, was 4724.194685935974\n",
      "\n",
      "EPOCH 5750  (with max 8000), loss: 0.02149857208132744\n",
      "train time for 5750 epochs, was 4725.8301684856415\n",
      "\n",
      "EPOCH 5752  (with max 8000), loss: 0.018407417461276054\n",
      "train time for 5752 epochs, was 4727.463660240173\n",
      "\n",
      "EPOCH 5754  (with max 8000), loss: 0.03712056577205658\n",
      "train time for 5754 epochs, was 4729.099157333374\n",
      "\n",
      "EPOCH 5756  (with max 8000), loss: 0.011502956040203571\n",
      "train time for 5756 epochs, was 4730.732228755951\n",
      "\n",
      "EPOCH 5758  (with max 8000), loss: 0.01781878061592579\n",
      "train time for 5758 epochs, was 4732.365391731262\n",
      "\n",
      "EPOCH 5760  (with max 8000), loss: 0.016190489754080772\n",
      "train time for 5760 epochs, was 4734.000730037689\n",
      "\n",
      "EPOCH 5762  (with max 8000), loss: 0.011265667155385017\n",
      "train time for 5762 epochs, was 4735.634046077728\n",
      "\n",
      "EPOCH 5764  (with max 8000), loss: 0.01463550329208374\n",
      "train time for 5764 epochs, was 4737.267480611801\n",
      "\n",
      "EPOCH 5766  (with max 8000), loss: 0.020230228081345558\n",
      "train time for 5766 epochs, was 4738.900437831879\n",
      "\n",
      "EPOCH 5768  (with max 8000), loss: 0.008876514621078968\n",
      "train time for 5768 epochs, was 4740.533661603928\n",
      "\n",
      "EPOCH 5770  (with max 8000), loss: 0.043511562049388885\n",
      "train time for 5770 epochs, was 4742.168820858002\n",
      "\n",
      "EPOCH 5772  (with max 8000), loss: 0.013278678059577942\n",
      "train time for 5772 epochs, was 4743.80198764801\n",
      "\n",
      "EPOCH 5774  (with max 8000), loss: 0.01009290013462305\n",
      "train time for 5774 epochs, was 4745.435166835785\n",
      "\n",
      "EPOCH 5776  (with max 8000), loss: 0.009730684570968151\n",
      "train time for 5776 epochs, was 4747.068307161331\n",
      "\n",
      "EPOCH 5778  (with max 8000), loss: 0.00885467417538166\n",
      "train time for 5778 epochs, was 4748.701482057571\n",
      "\n",
      "EPOCH 5780  (with max 8000), loss: 0.00684010935947299\n",
      "train time for 5780 epochs, was 4750.351220607758\n",
      "\n",
      "EPOCH 5782  (with max 8000), loss: 0.03248046338558197\n",
      "train time for 5782 epochs, was 4751.986686468124\n",
      "\n",
      "EPOCH 5784  (with max 8000), loss: 0.03127388656139374\n",
      "train time for 5784 epochs, was 4753.626342058182\n",
      "\n",
      "EPOCH 5786  (with max 8000), loss: 0.16155335307121277\n",
      "train time for 5786 epochs, was 4755.267554283142\n",
      "\n",
      "EPOCH 5788  (with max 8000), loss: 0.017529740929603577\n",
      "train time for 5788 epochs, was 4756.900389909744\n",
      "\n",
      "EPOCH 5790  (with max 8000), loss: 0.02362647093832493\n",
      "train time for 5790 epochs, was 4758.5339522361755\n",
      "\n",
      "EPOCH 5792  (with max 8000), loss: 0.01941542699933052\n",
      "train time for 5792 epochs, was 4760.169562339783\n",
      "\n",
      "EPOCH 5794  (with max 8000), loss: 0.022028714418411255\n",
      "train time for 5794 epochs, was 4761.803453922272\n",
      "\n",
      "EPOCH 5796  (with max 8000), loss: 0.007108855992555618\n",
      "train time for 5796 epochs, was 4763.437521696091\n",
      "\n",
      "EPOCH 5798  (with max 8000), loss: 0.009666593745350838\n",
      "train time for 5798 epochs, was 4765.073440551758\n",
      "\n",
      "EPOCH 5800  (with max 8000), loss: 0.013738195411860943\n",
      "train time for 5800 epochs, was 4766.70719575882\n",
      "\n",
      "EPOCH 5800 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_5800.pth\n",
      "\n",
      "EPOCH 5802  (with max 8000), loss: 0.008706430904567242\n",
      "train time for 5802 epochs, was 4768.376717090607\n",
      "\n",
      "EPOCH 5804  (with max 8000), loss: 0.014229122549295425\n",
      "train time for 5804 epochs, was 4770.010386943817\n",
      "\n",
      "EPOCH 5806  (with max 8000), loss: 0.02061333693563938\n",
      "train time for 5806 epochs, was 4771.6440489292145\n",
      "\n",
      "EPOCH 5808  (with max 8000), loss: 0.016028856858611107\n",
      "train time for 5808 epochs, was 4773.2775938510895\n",
      "\n",
      "EPOCH 5810  (with max 8000), loss: 0.011351168155670166\n",
      "train time for 5810 epochs, was 4774.915369987488\n",
      "\n",
      "EPOCH 5812  (with max 8000), loss: 0.0064018783159554005\n",
      "train time for 5812 epochs, was 4776.549098730087\n",
      "\n",
      "EPOCH 5814  (with max 8000), loss: 0.01234092004597187\n",
      "train time for 5814 epochs, was 4778.182807683945\n",
      "\n",
      "EPOCH 5816  (with max 8000), loss: 0.011981719173491001\n",
      "train time for 5816 epochs, was 4779.8168432712555\n",
      "\n",
      "EPOCH 5818  (with max 8000), loss: 0.004788529593497515\n",
      "train time for 5818 epochs, was 4781.45054268837\n",
      "\n",
      "EPOCH 5820  (with max 8000), loss: 0.010071543045341969\n",
      "train time for 5820 epochs, was 4783.088688135147\n",
      "\n",
      "EPOCH 5822  (with max 8000), loss: 0.016417963430285454\n",
      "train time for 5822 epochs, was 4784.724456548691\n",
      "\n",
      "EPOCH 5824  (with max 8000), loss: 0.03851732611656189\n",
      "train time for 5824 epochs, was 4786.378849506378\n",
      "\n",
      "EPOCH 5826  (with max 8000), loss: 0.02307042106986046\n",
      "train time for 5826 epochs, was 4788.018705368042\n",
      "\n",
      "EPOCH 5828  (with max 8000), loss: 0.02034023031592369\n",
      "train time for 5828 epochs, was 4789.65892124176\n",
      "\n",
      "EPOCH 5830  (with max 8000), loss: 0.019177190959453583\n",
      "train time for 5830 epochs, was 4791.298487663269\n",
      "\n",
      "EPOCH 5832  (with max 8000), loss: 0.027868784964084625\n",
      "train time for 5832 epochs, was 4792.932219743729\n",
      "\n",
      "EPOCH 5834  (with max 8000), loss: 0.02281433902680874\n",
      "train time for 5834 epochs, was 4794.568198680878\n",
      "\n",
      "EPOCH 5836  (with max 8000), loss: 0.013911901973187923\n",
      "train time for 5836 epochs, was 4796.2017390728\n",
      "\n",
      "EPOCH 5838  (with max 8000), loss: 0.013227774761617184\n",
      "train time for 5838 epochs, was 4797.835599422455\n",
      "\n",
      "EPOCH 5840  (with max 8000), loss: 0.012622211128473282\n",
      "train time for 5840 epochs, was 4799.469185113907\n",
      "\n",
      "EPOCH 5842  (with max 8000), loss: 0.01156429573893547\n",
      "train time for 5842 epochs, was 4801.102837085724\n",
      "\n",
      "EPOCH 5844  (with max 8000), loss: 0.013413246721029282\n",
      "train time for 5844 epochs, was 4802.73864531517\n",
      "\n",
      "EPOCH 5846  (with max 8000), loss: 0.007254845928400755\n",
      "train time for 5846 epochs, was 4804.372474193573\n",
      "\n",
      "EPOCH 5848  (with max 8000), loss: 0.015713095664978027\n",
      "train time for 5848 epochs, was 4806.006120920181\n",
      "\n",
      "EPOCH 5850  (with max 8000), loss: 0.011988920159637928\n",
      "train time for 5850 epochs, was 4807.6397495269775\n",
      "\n",
      "EPOCH 5852  (with max 8000), loss: 0.007243866566568613\n",
      "train time for 5852 epochs, was 4809.273134231567\n",
      "\n",
      "EPOCH 5854  (with max 8000), loss: 0.009410916827619076\n",
      "train time for 5854 epochs, was 4810.906516075134\n",
      "\n",
      "EPOCH 5856  (with max 8000), loss: 0.011632738634943962\n",
      "train time for 5856 epochs, was 4812.540181159973\n",
      "\n",
      "EPOCH 5858  (with max 8000), loss: 0.03049706295132637\n",
      "train time for 5858 epochs, was 4814.173857450485\n",
      "\n",
      "EPOCH 5860  (with max 8000), loss: 0.007505605462938547\n",
      "train time for 5860 epochs, was 4815.8078598976135\n",
      "\n",
      "EPOCH 5862  (with max 8000), loss: 0.017077913507819176\n",
      "train time for 5862 epochs, was 4817.441614866257\n",
      "\n",
      "EPOCH 5864  (with max 8000), loss: 0.009683556854724884\n",
      "train time for 5864 epochs, was 4819.07746386528\n",
      "\n",
      "EPOCH 5866  (with max 8000), loss: 0.011959158815443516\n",
      "train time for 5866 epochs, was 4820.715238571167\n",
      "\n",
      "EPOCH 5868  (with max 8000), loss: 0.013792351819574833\n",
      "train time for 5868 epochs, was 4822.369706869125\n",
      "\n",
      "EPOCH 5870  (with max 8000), loss: 0.013850049115717411\n",
      "train time for 5870 epochs, was 4824.003316640854\n",
      "\n",
      "EPOCH 5872  (with max 8000), loss: 0.018355030566453934\n",
      "train time for 5872 epochs, was 4825.639129400253\n",
      "\n",
      "EPOCH 5874  (with max 8000), loss: 0.011835922487080097\n",
      "train time for 5874 epochs, was 4827.274819850922\n",
      "\n",
      "EPOCH 5876  (with max 8000), loss: 0.020725982263684273\n",
      "train time for 5876 epochs, was 4828.912525177002\n",
      "\n",
      "EPOCH 5878  (with max 8000), loss: 0.009981135837733746\n",
      "train time for 5878 epochs, was 4830.547848701477\n",
      "\n",
      "EPOCH 5880  (with max 8000), loss: 0.021741127595305443\n",
      "train time for 5880 epochs, was 4832.183479070663\n",
      "\n",
      "EPOCH 5882  (with max 8000), loss: 0.012417690828442574\n",
      "train time for 5882 epochs, was 4833.8171401023865\n",
      "\n",
      "EPOCH 5884  (with max 8000), loss: 0.024970635771751404\n",
      "train time for 5884 epochs, was 4835.452700138092\n",
      "\n",
      "EPOCH 5886  (with max 8000), loss: 0.05453210696578026\n",
      "train time for 5886 epochs, was 4837.086388349533\n",
      "\n",
      "EPOCH 5888  (with max 8000), loss: 0.8348827958106995\n",
      "train time for 5888 epochs, was 4838.720118761063\n",
      "\n",
      "EPOCH 5890  (with max 8000), loss: 0.05321788415312767\n",
      "train time for 5890 epochs, was 4840.354073762894\n",
      "\n",
      "EPOCH 5892  (with max 8000), loss: 0.033949390053749084\n",
      "train time for 5892 epochs, was 4841.988120794296\n",
      "\n",
      "EPOCH 5894  (with max 8000), loss: 0.02737637236714363\n",
      "train time for 5894 epochs, was 4843.623950719833\n",
      "\n",
      "EPOCH 5896  (with max 8000), loss: 0.029134467244148254\n",
      "train time for 5896 epochs, was 4845.259793996811\n",
      "\n",
      "EPOCH 5898  (with max 8000), loss: 0.022888345643877983\n",
      "train time for 5898 epochs, was 4846.893537521362\n",
      "\n",
      "EPOCH 5900  (with max 8000), loss: 0.012438403442502022\n",
      "train time for 5900 epochs, was 4848.52737736702\n",
      "\n",
      "EPOCH 5902  (with max 8000), loss: 0.019986560568213463\n",
      "train time for 5902 epochs, was 4850.161408424377\n",
      "\n",
      "EPOCH 5904  (with max 8000), loss: 0.016950249671936035\n",
      "train time for 5904 epochs, was 4851.81387758255\n",
      "\n",
      "EPOCH 5906  (with max 8000), loss: 0.029231838881969452\n",
      "train time for 5906 epochs, was 4853.449512958527\n",
      "\n",
      "EPOCH 5908  (with max 8000), loss: 0.011510664597153664\n",
      "train time for 5908 epochs, was 4855.085467100143\n",
      "\n",
      "EPOCH 5910  (with max 8000), loss: 0.024305004626512527\n",
      "train time for 5910 epochs, was 4856.719154596329\n",
      "\n",
      "EPOCH 5912  (with max 8000), loss: 0.008640224114060402\n",
      "train time for 5912 epochs, was 4858.354811906815\n",
      "\n",
      "EPOCH 5914  (with max 8000), loss: 0.00968883652240038\n",
      "train time for 5914 epochs, was 4860.007318735123\n",
      "\n",
      "EPOCH 5916  (with max 8000), loss: 0.010995120741426945\n",
      "train time for 5916 epochs, was 4861.640985965729\n",
      "\n",
      "EPOCH 5918  (with max 8000), loss: 0.014959163032472134\n",
      "train time for 5918 epochs, was 4863.2746925354\n",
      "\n",
      "EPOCH 5920  (with max 8000), loss: 0.009625272825360298\n",
      "train time for 5920 epochs, was 4864.908245563507\n",
      "\n",
      "EPOCH 5922  (with max 8000), loss: 0.0050596329383552074\n",
      "train time for 5922 epochs, was 4866.541741371155\n",
      "\n",
      "EPOCH 5924  (with max 8000), loss: 0.007969966158270836\n",
      "train time for 5924 epochs, was 4868.175230741501\n",
      "\n",
      "EPOCH 5926  (with max 8000), loss: 0.010240850038826466\n",
      "train time for 5926 epochs, was 4869.809363126755\n",
      "\n",
      "EPOCH 5928  (with max 8000), loss: 0.010512170381844044\n",
      "train time for 5928 epochs, was 4871.442931890488\n",
      "\n",
      "EPOCH 5930  (with max 8000), loss: 0.007854285649955273\n",
      "train time for 5930 epochs, was 4873.076531410217\n",
      "\n",
      "EPOCH 5932  (with max 8000), loss: 0.00991497840732336\n",
      "train time for 5932 epochs, was 4874.710378170013\n",
      "\n",
      "EPOCH 5934  (with max 8000), loss: 0.03251965716481209\n",
      "train time for 5934 epochs, was 4876.3462381362915\n",
      "\n",
      "EPOCH 5936  (with max 8000), loss: 0.015536424703896046\n",
      "train time for 5936 epochs, was 4877.98193192482\n",
      "\n",
      "EPOCH 5938  (with max 8000), loss: 0.003961572423577309\n",
      "train time for 5938 epochs, was 4879.615748167038\n",
      "\n",
      "EPOCH 5940  (with max 8000), loss: 0.01142887957394123\n",
      "train time for 5940 epochs, was 4881.251362085342\n",
      "\n",
      "EPOCH 5942  (with max 8000), loss: 0.00997438095510006\n",
      "train time for 5942 epochs, was 4882.885322570801\n",
      "\n",
      "EPOCH 5944  (with max 8000), loss: 0.012318804860115051\n",
      "train time for 5944 epochs, was 4884.519011259079\n",
      "\n",
      "EPOCH 5946  (with max 8000), loss: 0.11396816372871399\n",
      "train time for 5946 epochs, was 4886.152680158615\n",
      "\n",
      "EPOCH 5948  (with max 8000), loss: 0.03176679462194443\n",
      "train time for 5948 epochs, was 4887.788403511047\n",
      "\n",
      "EPOCH 5950  (with max 8000), loss: 0.04690069332718849\n",
      "train time for 5950 epochs, was 4889.421979427338\n",
      "\n",
      "EPOCH 5952  (with max 8000), loss: 0.015988323837518692\n",
      "train time for 5952 epochs, was 4891.055626869202\n",
      "\n",
      "EPOCH 5954  (with max 8000), loss: 0.01556206401437521\n",
      "train time for 5954 epochs, was 4892.689329147339\n",
      "\n",
      "EPOCH 5956  (with max 8000), loss: 0.009892231784760952\n",
      "train time for 5956 epochs, was 4894.356509208679\n",
      "\n",
      "EPOCH 5958  (with max 8000), loss: 0.01912415772676468\n",
      "train time for 5958 epochs, was 4895.990277051926\n",
      "\n",
      "EPOCH 5960  (with max 8000), loss: 0.017788391560316086\n",
      "train time for 5960 epochs, was 4897.632513284683\n",
      "\n",
      "EPOCH 5962  (with max 8000), loss: 0.023997744545340538\n",
      "train time for 5962 epochs, was 4899.268176794052\n",
      "\n",
      "EPOCH 5964  (with max 8000), loss: 0.01844906434416771\n",
      "train time for 5964 epochs, was 4900.901639223099\n",
      "\n",
      "EPOCH 5966  (with max 8000), loss: 0.014115081168711185\n",
      "train time for 5966 epochs, was 4902.535232305527\n",
      "\n",
      "EPOCH 5968  (with max 8000), loss: 0.01420657616108656\n",
      "train time for 5968 epochs, was 4904.168953180313\n",
      "\n",
      "EPOCH 5970  (with max 8000), loss: 0.02159154787659645\n",
      "train time for 5970 epochs, was 4905.802609205246\n",
      "\n",
      "EPOCH 5972  (with max 8000), loss: 0.010564982891082764\n",
      "train time for 5972 epochs, was 4907.436115026474\n",
      "\n",
      "EPOCH 5974  (with max 8000), loss: 0.007123345509171486\n",
      "train time for 5974 epochs, was 4909.069686174393\n",
      "\n",
      "EPOCH 5976  (with max 8000), loss: 0.016369229182600975\n",
      "train time for 5976 epochs, was 4910.7054142951965\n",
      "\n",
      "EPOCH 5978  (with max 8000), loss: 0.01120807882398367\n",
      "train time for 5978 epochs, was 4912.33913397789\n",
      "\n",
      "EPOCH 5980  (with max 8000), loss: 0.02854475937783718\n",
      "train time for 5980 epochs, was 4913.972827672958\n",
      "\n",
      "EPOCH 5982  (with max 8000), loss: 0.03765668347477913\n",
      "train time for 5982 epochs, was 4915.606406211853\n",
      "\n",
      "EPOCH 5984  (with max 8000), loss: 0.02231687307357788\n",
      "train time for 5984 epochs, was 4917.239924192429\n",
      "\n",
      "EPOCH 5986  (with max 8000), loss: 0.009524869732558727\n",
      "train time for 5986 epochs, was 4918.875738620758\n",
      "\n",
      "EPOCH 5988  (with max 8000), loss: 0.01034010760486126\n",
      "train time for 5988 epochs, was 4920.511469125748\n",
      "\n",
      "EPOCH 5990  (with max 8000), loss: 0.0093552740290761\n",
      "train time for 5990 epochs, was 4922.144905328751\n",
      "\n",
      "EPOCH 5992  (with max 8000), loss: 0.034257177263498306\n",
      "train time for 5992 epochs, was 4923.780371665955\n",
      "\n",
      "EPOCH 5994  (with max 8000), loss: 0.013272646814584732\n",
      "train time for 5994 epochs, was 4925.415848493576\n",
      "\n",
      "EPOCH 5996  (with max 8000), loss: 0.011261306703090668\n",
      "train time for 5996 epochs, was 4927.0493104457855\n",
      "\n",
      "EPOCH 5998  (with max 8000), loss: 0.14811722934246063\n",
      "train time for 5998 epochs, was 4928.683173418045\n",
      "\n",
      "EPOCH 6000  (with max 8000), loss: 0.8244344592094421\n",
      "train time for 6000 epochs, was 4930.347958564758\n",
      "\n",
      "EPOCH 6000 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_6000.pth\n",
      "\n",
      "EPOCH 6002  (with max 8000), loss: 0.11340764164924622\n",
      "train time for 6002 epochs, was 4932.0315980911255\n",
      "\n",
      "EPOCH 6004  (with max 8000), loss: 0.07877761125564575\n",
      "train time for 6004 epochs, was 4933.664867401123\n",
      "\n",
      "EPOCH 6006  (with max 8000), loss: 0.023022906854748726\n",
      "train time for 6006 epochs, was 4935.29798078537\n",
      "\n",
      "EPOCH 6008  (with max 8000), loss: 0.02768336609005928\n",
      "train time for 6008 epochs, was 4936.931174039841\n",
      "\n",
      "EPOCH 6010  (with max 8000), loss: 0.0761558786034584\n",
      "train time for 6010 epochs, was 4938.564504623413\n",
      "\n",
      "EPOCH 6012  (with max 8000), loss: 0.018414339050650597\n",
      "train time for 6012 epochs, was 4940.197907924652\n",
      "\n",
      "EPOCH 6014  (with max 8000), loss: 0.03880936652421951\n",
      "train time for 6014 epochs, was 4941.833607435226\n",
      "\n",
      "EPOCH 6016  (with max 8000), loss: 0.023597797378897667\n",
      "train time for 6016 epochs, was 4943.4671268463135\n",
      "\n",
      "EPOCH 6018  (with max 8000), loss: 0.04207587242126465\n",
      "train time for 6018 epochs, was 4945.10271191597\n",
      "\n",
      "EPOCH 6020  (with max 8000), loss: 0.024309230968356133\n",
      "train time for 6020 epochs, was 4946.736170053482\n",
      "\n",
      "EPOCH 6022  (with max 8000), loss: 0.02238234132528305\n",
      "train time for 6022 epochs, was 4948.369913578033\n",
      "\n",
      "EPOCH 6024  (with max 8000), loss: 0.024007918313145638\n",
      "train time for 6024 epochs, was 4950.003541946411\n",
      "\n",
      "EPOCH 6026  (with max 8000), loss: 0.030698034912347794\n",
      "train time for 6026 epochs, was 4951.6392204761505\n",
      "\n",
      "EPOCH 6028  (with max 8000), loss: 0.01564955525100231\n",
      "train time for 6028 epochs, was 4953.272707939148\n",
      "\n",
      "EPOCH 6030  (with max 8000), loss: 0.014419380575418472\n",
      "train time for 6030 epochs, was 4954.908268451691\n",
      "\n",
      "EPOCH 6032  (with max 8000), loss: 0.010828156024217606\n",
      "train time for 6032 epochs, was 4956.5436589717865\n",
      "\n",
      "EPOCH 6034  (with max 8000), loss: 0.023330943658947945\n",
      "train time for 6034 epochs, was 4958.179261922836\n",
      "\n",
      "EPOCH 6036  (with max 8000), loss: 0.017050012946128845\n",
      "train time for 6036 epochs, was 4959.8273956775665\n",
      "\n",
      "EPOCH 6038  (with max 8000), loss: 0.022458631545305252\n",
      "train time for 6038 epochs, was 4961.463201522827\n",
      "\n",
      "EPOCH 6040  (with max 8000), loss: 0.01417949516326189\n",
      "train time for 6040 epochs, was 4963.096700429916\n",
      "\n",
      "EPOCH 6042  (with max 8000), loss: 0.015020945109426975\n",
      "train time for 6042 epochs, was 4964.730178356171\n",
      "\n",
      "EPOCH 6044  (with max 8000), loss: 0.03517477586865425\n",
      "train time for 6044 epochs, was 4966.365726232529\n",
      "\n",
      "EPOCH 6046  (with max 8000), loss: 0.018666058778762817\n",
      "train time for 6046 epochs, was 4968.001189947128\n",
      "\n",
      "EPOCH 6048  (with max 8000), loss: 0.013563225977122784\n",
      "train time for 6048 epochs, was 4969.635194063187\n",
      "\n",
      "EPOCH 6050  (with max 8000), loss: 0.04622494801878929\n",
      "train time for 6050 epochs, was 4971.2707369327545\n",
      "\n",
      "EPOCH 6052  (with max 8000), loss: 0.033986203372478485\n",
      "train time for 6052 epochs, was 4972.904051780701\n",
      "\n",
      "EPOCH 6054  (with max 8000), loss: 0.03440968692302704\n",
      "train time for 6054 epochs, was 4974.541406869888\n",
      "\n",
      "EPOCH 6056  (with max 8000), loss: 0.036726631224155426\n",
      "train time for 6056 epochs, was 4976.181116819382\n",
      "\n",
      "EPOCH 6058  (with max 8000), loss: 0.012686872854828835\n",
      "train time for 6058 epochs, was 4977.81419968605\n",
      "\n",
      "EPOCH 6060  (with max 8000), loss: 0.0160656925290823\n",
      "train time for 6060 epochs, was 4979.44725227356\n",
      "\n",
      "EPOCH 6062  (with max 8000), loss: 0.01882912777364254\n",
      "train time for 6062 epochs, was 4981.082680463791\n",
      "\n",
      "EPOCH 6064  (with max 8000), loss: 0.017324160784482956\n",
      "train time for 6064 epochs, was 4982.716023445129\n",
      "\n",
      "EPOCH 6066  (with max 8000), loss: 0.020398149266839027\n",
      "train time for 6066 epochs, was 4984.349698066711\n",
      "\n",
      "EPOCH 6068  (with max 8000), loss: 0.018523981794714928\n",
      "train time for 6068 epochs, was 4985.985432386398\n",
      "\n",
      "EPOCH 6070  (with max 8000), loss: 0.01445880625396967\n",
      "train time for 6070 epochs, was 4987.623033761978\n",
      "\n",
      "EPOCH 6072  (with max 8000), loss: 0.017426595091819763\n",
      "train time for 6072 epochs, was 4989.256438493729\n",
      "\n",
      "EPOCH 6074  (with max 8000), loss: 0.006669501308351755\n",
      "train time for 6074 epochs, was 4990.896024465561\n",
      "\n",
      "EPOCH 6076  (with max 8000), loss: 0.008799108676612377\n",
      "train time for 6076 epochs, was 4992.529205322266\n",
      "\n",
      "EPOCH 6078  (with max 8000), loss: 0.3878598213195801\n",
      "train time for 6078 epochs, was 4994.164732933044\n",
      "\n",
      "EPOCH 6080  (with max 8000), loss: 0.016315702348947525\n",
      "train time for 6080 epochs, was 4995.798377037048\n",
      "\n",
      "EPOCH 6082  (with max 8000), loss: 0.02451486513018608\n",
      "train time for 6082 epochs, was 4997.433666467667\n",
      "\n",
      "EPOCH 6084  (with max 8000), loss: 0.024720078334212303\n",
      "train time for 6084 epochs, was 4999.068937778473\n",
      "\n",
      "EPOCH 6086  (with max 8000), loss: 0.026653148233890533\n",
      "train time for 6086 epochs, was 5000.702340841293\n",
      "\n",
      "EPOCH 6088  (with max 8000), loss: 0.01602483168244362\n",
      "train time for 6088 epochs, was 5002.3497796058655\n",
      "\n",
      "EPOCH 6090  (with max 8000), loss: 0.0174663495272398\n",
      "train time for 6090 epochs, was 5003.98273563385\n",
      "\n",
      "EPOCH 6092  (with max 8000), loss: 0.020109251141548157\n",
      "train time for 6092 epochs, was 5005.615740299225\n",
      "\n",
      "EPOCH 6094  (with max 8000), loss: 0.01481076143682003\n",
      "train time for 6094 epochs, was 5007.2487823963165\n",
      "\n",
      "EPOCH 6096  (with max 8000), loss: 0.033740073442459106\n",
      "train time for 6096 epochs, was 5008.88601398468\n",
      "\n",
      "EPOCH 6098  (with max 8000), loss: 0.16843783855438232\n",
      "train time for 6098 epochs, was 5010.518982410431\n",
      "\n",
      "EPOCH 6100  (with max 8000), loss: 0.02446748875081539\n",
      "train time for 6100 epochs, was 5012.1541566848755\n",
      "\n",
      "EPOCH 6102  (with max 8000), loss: 0.014523341320455074\n",
      "train time for 6102 epochs, was 5013.787205696106\n",
      "\n",
      "EPOCH 6104  (with max 8000), loss: 0.011922757141292095\n",
      "train time for 6104 epochs, was 5015.420226573944\n",
      "\n",
      "EPOCH 6106  (with max 8000), loss: 0.047598108649253845\n",
      "train time for 6106 epochs, was 5017.053075790405\n",
      "\n",
      "EPOCH 6108  (with max 8000), loss: 0.08880230039358139\n",
      "train time for 6108 epochs, was 5018.685914993286\n",
      "\n",
      "EPOCH 6110  (with max 8000), loss: 0.05448414012789726\n",
      "train time for 6110 epochs, was 5020.318941116333\n",
      "\n",
      "EPOCH 6112  (with max 8000), loss: 0.03926842287182808\n",
      "train time for 6112 epochs, was 5021.953988313675\n",
      "\n",
      "EPOCH 6114  (with max 8000), loss: 0.024197254329919815\n",
      "train time for 6114 epochs, was 5023.587113142014\n",
      "\n",
      "EPOCH 6116  (with max 8000), loss: 0.03338001295924187\n",
      "train time for 6116 epochs, was 5025.224426746368\n",
      "\n",
      "EPOCH 6118  (with max 8000), loss: 0.03252146393060684\n",
      "train time for 6118 epochs, was 5026.859882354736\n",
      "\n",
      "EPOCH 6120  (with max 8000), loss: 0.01933959871530533\n",
      "train time for 6120 epochs, was 5028.495218753815\n",
      "\n",
      "EPOCH 6122  (with max 8000), loss: 0.020914647728204727\n",
      "train time for 6122 epochs, was 5030.128642082214\n",
      "\n",
      "EPOCH 6124  (with max 8000), loss: 0.01691971719264984\n",
      "train time for 6124 epochs, was 5031.764082670212\n",
      "\n",
      "EPOCH 6126  (with max 8000), loss: 0.02961796522140503\n",
      "train time for 6126 epochs, was 5033.397488594055\n",
      "\n",
      "EPOCH 6128  (with max 8000), loss: 0.024438325315713882\n",
      "train time for 6128 epochs, was 5035.033197879791\n",
      "\n",
      "EPOCH 6130  (with max 8000), loss: 0.03099820949137211\n",
      "train time for 6130 epochs, was 5036.6709887981415\n",
      "\n",
      "EPOCH 6132  (with max 8000), loss: 0.01589277572929859\n",
      "train time for 6132 epochs, was 5038.306580543518\n",
      "\n",
      "EPOCH 6134  (with max 8000), loss: 0.013996902853250504\n",
      "train time for 6134 epochs, was 5039.96305680275\n",
      "\n",
      "EPOCH 6136  (with max 8000), loss: 0.013444744050502777\n",
      "train time for 6136 epochs, was 5041.602754831314\n",
      "\n",
      "EPOCH 6138  (with max 8000), loss: 0.009328285232186317\n",
      "train time for 6138 epochs, was 5043.242424726486\n",
      "\n",
      "EPOCH 6140  (with max 8000), loss: 0.0182908046990633\n",
      "train time for 6140 epochs, was 5044.882122516632\n",
      "\n",
      "EPOCH 6142  (with max 8000), loss: 0.03188613802194595\n",
      "train time for 6142 epochs, was 5046.515446424484\n",
      "\n",
      "EPOCH 6144  (with max 8000), loss: 0.028595179319381714\n",
      "train time for 6144 epochs, was 5048.148933172226\n",
      "\n",
      "EPOCH 6146  (with max 8000), loss: 0.014470037072896957\n",
      "train time for 6146 epochs, was 5049.786419630051\n",
      "\n",
      "EPOCH 6148  (with max 8000), loss: 0.018125468865036964\n",
      "train time for 6148 epochs, was 5051.419859886169\n",
      "\n",
      "EPOCH 6150  (with max 8000), loss: 0.00684694666415453\n",
      "train time for 6150 epochs, was 5053.0531532764435\n",
      "\n",
      "EPOCH 6152  (with max 8000), loss: 0.0193538349121809\n",
      "train time for 6152 epochs, was 5054.695075511932\n",
      "\n",
      "EPOCH 6154  (with max 8000), loss: 0.00874246098101139\n",
      "train time for 6154 epochs, was 5056.330440998077\n",
      "\n",
      "EPOCH 6156  (with max 8000), loss: 0.016084058210253716\n",
      "train time for 6156 epochs, was 5057.965909004211\n",
      "\n",
      "EPOCH 6158  (with max 8000), loss: 0.013428528793156147\n",
      "train time for 6158 epochs, was 5059.601469755173\n",
      "\n",
      "EPOCH 6160  (with max 8000), loss: 0.01619477942585945\n",
      "train time for 6160 epochs, was 5061.234851360321\n",
      "\n",
      "EPOCH 6162  (with max 8000), loss: 0.02095772884786129\n",
      "train time for 6162 epochs, was 5062.87051987648\n",
      "\n",
      "EPOCH 6164  (with max 8000), loss: 0.020634159445762634\n",
      "train time for 6164 epochs, was 5064.522741556168\n",
      "\n",
      "EPOCH 6166  (with max 8000), loss: 0.013111582025885582\n",
      "train time for 6166 epochs, was 5066.158247232437\n",
      "\n",
      "EPOCH 6168  (with max 8000), loss: 0.022190630435943604\n",
      "train time for 6168 epochs, was 5067.791724205017\n",
      "\n",
      "EPOCH 6170  (with max 8000), loss: 0.014833050779998302\n",
      "train time for 6170 epochs, was 5069.425393819809\n",
      "\n",
      "EPOCH 6172  (with max 8000), loss: 0.04206334054470062\n",
      "train time for 6172 epochs, was 5071.058947563171\n",
      "\n",
      "EPOCH 6174  (with max 8000), loss: 0.021158523857593536\n",
      "train time for 6174 epochs, was 5072.692427396774\n",
      "\n",
      "EPOCH 6176  (with max 8000), loss: 0.018899571150541306\n",
      "train time for 6176 epochs, was 5074.326007604599\n",
      "\n",
      "EPOCH 6178  (with max 8000), loss: 0.011000435799360275\n",
      "train time for 6178 epochs, was 5075.978327035904\n",
      "\n",
      "EPOCH 6180  (with max 8000), loss: 2.1879825592041016\n",
      "train time for 6180 epochs, was 5077.612035512924\n",
      "\n",
      "EPOCH 6182  (with max 8000), loss: 0.06388774514198303\n",
      "train time for 6182 epochs, was 5079.245164871216\n",
      "\n",
      "EPOCH 6184  (with max 8000), loss: 0.03209290653467178\n",
      "train time for 6184 epochs, was 5080.878178358078\n",
      "\n",
      "EPOCH 6186  (with max 8000), loss: 0.031558506190776825\n",
      "train time for 6186 epochs, was 5082.511288642883\n",
      "\n",
      "EPOCH 6188  (with max 8000), loss: 0.024908320978283882\n",
      "train time for 6188 epochs, was 5084.146371603012\n",
      "\n",
      "EPOCH 6190  (with max 8000), loss: 0.027526531368494034\n",
      "train time for 6190 epochs, was 5085.781591892242\n",
      "\n",
      "EPOCH 6192  (with max 8000), loss: 0.031079383566975594\n",
      "train time for 6192 epochs, was 5087.414540529251\n",
      "\n",
      "EPOCH 6194  (with max 8000), loss: 0.35137835144996643\n",
      "train time for 6194 epochs, was 5089.047746658325\n",
      "\n",
      "EPOCH 6196  (with max 8000), loss: 0.035804569721221924\n",
      "train time for 6196 epochs, was 5090.681113004684\n",
      "\n",
      "EPOCH 6198  (with max 8000), loss: 0.020120767876505852\n",
      "train time for 6198 epochs, was 5092.316386461258\n",
      "\n",
      "EPOCH 6200  (with max 8000), loss: 0.022922350093722343\n",
      "train time for 6200 epochs, was 5093.957848548889\n",
      "\n",
      "EPOCH 6200 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_6200.pth\n",
      "\n",
      "EPOCH 6202  (with max 8000), loss: 0.006467473693192005\n",
      "train time for 6202 epochs, was 5095.628534317017\n",
      "\n",
      "EPOCH 6204  (with max 8000), loss: 0.03254762664437294\n",
      "train time for 6204 epochs, was 5097.261579036713\n",
      "\n",
      "EPOCH 6206  (with max 8000), loss: 0.012274299748241901\n",
      "train time for 6206 epochs, was 5098.894668102264\n",
      "\n",
      "EPOCH 6208  (with max 8000), loss: 0.007383591029793024\n",
      "train time for 6208 epochs, was 5100.529821872711\n",
      "\n",
      "EPOCH 6210  (with max 8000), loss: 0.014246898703277111\n",
      "train time for 6210 epochs, was 5102.1628448963165\n",
      "\n",
      "EPOCH 6212  (with max 8000), loss: 0.010486220940947533\n",
      "train time for 6212 epochs, was 5103.795897483826\n",
      "\n",
      "EPOCH 6214  (with max 8000), loss: 0.009937804192304611\n",
      "train time for 6214 epochs, was 5105.429152727127\n",
      "\n",
      "EPOCH 6216  (with max 8000), loss: 0.011098049581050873\n",
      "train time for 6216 epochs, was 5107.062126159668\n",
      "\n",
      "EPOCH 6218  (with max 8000), loss: 0.010065312497317791\n",
      "train time for 6218 epochs, was 5108.695117712021\n",
      "\n",
      "EPOCH 6220  (with max 8000), loss: 0.012359553016722202\n",
      "train time for 6220 epochs, was 5110.330180644989\n",
      "\n",
      "EPOCH 6222  (with max 8000), loss: 0.017358940094709396\n",
      "train time for 6222 epochs, was 5111.980031967163\n",
      "\n",
      "EPOCH 6224  (with max 8000), loss: 0.01243691984564066\n",
      "train time for 6224 epochs, was 5113.615095615387\n",
      "\n",
      "EPOCH 6226  (with max 8000), loss: 0.02300681173801422\n",
      "train time for 6226 epochs, was 5115.252395868301\n",
      "\n",
      "EPOCH 6228  (with max 8000), loss: 0.015627194195985794\n",
      "train time for 6228 epochs, was 5116.8875987529755\n",
      "\n",
      "EPOCH 6230  (with max 8000), loss: 0.02321639470756054\n",
      "train time for 6230 epochs, was 5118.522851228714\n",
      "\n",
      "EPOCH 6232  (with max 8000), loss: 0.014322489500045776\n",
      "train time for 6232 epochs, was 5120.156131029129\n",
      "\n",
      "EPOCH 6234  (with max 8000), loss: 0.7932710647583008\n",
      "train time for 6234 epochs, was 5121.791296482086\n",
      "\n",
      "EPOCH 6236  (with max 8000), loss: 0.027477292343974113\n",
      "train time for 6236 epochs, was 5123.4241943359375\n",
      "\n",
      "EPOCH 6238  (with max 8000), loss: 0.014356826432049274\n",
      "train time for 6238 epochs, was 5125.057023525238\n",
      "\n",
      "EPOCH 6240  (with max 8000), loss: 0.010970687493681908\n",
      "train time for 6240 epochs, was 5126.689904928207\n",
      "\n",
      "EPOCH 6242  (with max 8000), loss: 0.02447200007736683\n",
      "train time for 6242 epochs, was 5128.322966337204\n",
      "\n",
      "EPOCH 6244  (with max 8000), loss: 0.02317969501018524\n",
      "train time for 6244 epochs, was 5129.958178520203\n",
      "\n",
      "EPOCH 6246  (with max 8000), loss: 0.03931499645113945\n",
      "train time for 6246 epochs, was 5131.593631029129\n",
      "\n",
      "EPOCH 6248  (with max 8000), loss: 0.03773188218474388\n",
      "train time for 6248 epochs, was 5133.226725101471\n",
      "\n",
      "EPOCH 6250  (with max 8000), loss: 0.01768636144697666\n",
      "train time for 6250 epochs, was 5134.862406730652\n",
      "\n",
      "EPOCH 6252  (with max 8000), loss: 0.015307072550058365\n",
      "train time for 6252 epochs, was 5136.495734930038\n",
      "\n",
      "EPOCH 6254  (with max 8000), loss: 0.010356839746236801\n",
      "train time for 6254 epochs, was 5138.137424230576\n",
      "\n",
      "EPOCH 6256  (with max 8000), loss: 0.016846008598804474\n",
      "train time for 6256 epochs, was 5139.772721529007\n",
      "\n",
      "EPOCH 6258  (with max 8000), loss: 0.014495315961539745\n",
      "train time for 6258 epochs, was 5141.4079711437225\n",
      "\n",
      "EPOCH 6260  (with max 8000), loss: 0.027011536061763763\n",
      "train time for 6260 epochs, was 5143.041209220886\n",
      "\n",
      "EPOCH 6262  (with max 8000), loss: 0.03255491331219673\n",
      "train time for 6262 epochs, was 5144.676509618759\n",
      "\n",
      "EPOCH 6264  (with max 8000), loss: 0.011179897002875805\n",
      "train time for 6264 epochs, was 5146.309715986252\n",
      "\n",
      "EPOCH 6266  (with max 8000), loss: 0.014042318798601627\n",
      "train time for 6266 epochs, was 5147.947124004364\n",
      "\n",
      "EPOCH 6268  (with max 8000), loss: 0.11505057662725449\n",
      "train time for 6268 epochs, was 5149.580363988876\n",
      "\n",
      "EPOCH 6270  (with max 8000), loss: 0.014666211791336536\n",
      "train time for 6270 epochs, was 5151.213539361954\n",
      "\n",
      "EPOCH 6272  (with max 8000), loss: 0.030897682532668114\n",
      "train time for 6272 epochs, was 5152.846632480621\n",
      "\n",
      "EPOCH 6274  (with max 8000), loss: 0.013828428462147713\n",
      "train time for 6274 epochs, was 5154.481971502304\n",
      "\n",
      "EPOCH 6276  (with max 8000), loss: 0.321078360080719\n",
      "train time for 6276 epochs, was 5156.117352247238\n",
      "\n",
      "EPOCH 6278  (with max 8000), loss: 0.019530370831489563\n",
      "train time for 6278 epochs, was 5157.752753973007\n",
      "\n",
      "EPOCH 6280  (with max 8000), loss: 0.012821326032280922\n",
      "train time for 6280 epochs, was 5159.402732133865\n",
      "\n",
      "EPOCH 6282  (with max 8000), loss: 0.020583342760801315\n",
      "train time for 6282 epochs, was 5161.0400631427765\n",
      "\n",
      "EPOCH 6284  (with max 8000), loss: 0.012845496647059917\n",
      "train time for 6284 epochs, was 5162.673445224762\n",
      "\n",
      "EPOCH 6286  (with max 8000), loss: 0.05895243212580681\n",
      "train time for 6286 epochs, was 5164.306600093842\n",
      "\n",
      "EPOCH 6288  (with max 8000), loss: 0.022755540907382965\n",
      "train time for 6288 epochs, was 5165.941843986511\n",
      "\n",
      "EPOCH 6290  (with max 8000), loss: 0.029938949272036552\n",
      "train time for 6290 epochs, was 5167.5771484375\n",
      "\n",
      "EPOCH 6292  (with max 8000), loss: 0.014944289810955524\n",
      "train time for 6292 epochs, was 5169.210248231888\n",
      "\n",
      "EPOCH 6294  (with max 8000), loss: 0.028636079281568527\n",
      "train time for 6294 epochs, was 5170.843487262726\n",
      "\n",
      "EPOCH 6296  (with max 8000), loss: 0.009971829131245613\n",
      "train time for 6296 epochs, was 5172.478755474091\n",
      "\n",
      "EPOCH 6298  (with max 8000), loss: 0.00424283416941762\n",
      "train time for 6298 epochs, was 5174.1117169857025\n",
      "\n",
      "EPOCH 6300  (with max 8000), loss: 0.014554616063833237\n",
      "train time for 6300 epochs, was 5175.744859218597\n",
      "\n",
      "EPOCH 6302  (with max 8000), loss: 0.018327616155147552\n",
      "train time for 6302 epochs, was 5177.380180835724\n",
      "\n",
      "EPOCH 6304  (with max 8000), loss: 0.022883325815200806\n",
      "train time for 6304 epochs, was 5179.01535654068\n",
      "\n",
      "EPOCH 6306  (with max 8000), loss: 0.016479644924402237\n",
      "train time for 6306 epochs, was 5180.652807235718\n",
      "\n",
      "EPOCH 6308  (with max 8000), loss: 0.015016419813036919\n",
      "train time for 6308 epochs, was 5182.285960435867\n",
      "\n",
      "EPOCH 6310  (with max 8000), loss: 0.015637490898370743\n",
      "train time for 6310 epochs, was 5183.936061859131\n",
      "\n",
      "EPOCH 6312  (with max 8000), loss: 0.011286327615380287\n",
      "train time for 6312 epochs, was 5185.56934261322\n",
      "\n",
      "EPOCH 6314  (with max 8000), loss: 0.016107995063066483\n",
      "train time for 6314 epochs, was 5187.204646587372\n",
      "\n",
      "EPOCH 6316  (with max 8000), loss: 0.0159104373306036\n",
      "train time for 6316 epochs, was 5188.837774515152\n",
      "\n",
      "EPOCH 6318  (with max 8000), loss: 0.016239497810602188\n",
      "train time for 6318 epochs, was 5190.470805644989\n",
      "\n",
      "EPOCH 6320  (with max 8000), loss: 0.010653759352862835\n",
      "train time for 6320 epochs, was 5192.103840827942\n",
      "\n",
      "EPOCH 6322  (with max 8000), loss: 0.012746439315378666\n",
      "train time for 6322 epochs, was 5193.738950252533\n",
      "\n",
      "EPOCH 6324  (with max 8000), loss: 0.01851482503116131\n",
      "train time for 6324 epochs, was 5195.372004270554\n",
      "\n",
      "EPOCH 6326  (with max 8000), loss: 0.020437225699424744\n",
      "train time for 6326 epochs, was 5197.005162477493\n",
      "\n",
      "EPOCH 6328  (with max 8000), loss: 0.011857165955007076\n",
      "train time for 6328 epochs, was 5198.638339757919\n",
      "\n",
      "EPOCH 6330  (with max 8000), loss: 0.018279677256941795\n",
      "train time for 6330 epochs, was 5200.271419763565\n",
      "\n",
      "EPOCH 6332  (with max 8000), loss: 0.016956256702542305\n",
      "train time for 6332 epochs, was 5201.9087035655975\n",
      "\n",
      "EPOCH 6334  (with max 8000), loss: 0.03378825634717941\n",
      "train time for 6334 epochs, was 5203.541883945465\n",
      "\n",
      "EPOCH 6336  (with max 8000), loss: 0.7187245488166809\n",
      "train time for 6336 epochs, was 5205.177393198013\n",
      "\n",
      "EPOCH 6338  (with max 8000), loss: 0.05849770829081535\n",
      "train time for 6338 epochs, was 5206.81062746048\n",
      "\n",
      "EPOCH 6340  (with max 8000), loss: 0.023226751014590263\n",
      "train time for 6340 epochs, was 5208.4436230659485\n",
      "\n",
      "EPOCH 6342  (with max 8000), loss: 0.01975928246974945\n",
      "train time for 6342 epochs, was 5210.078814983368\n",
      "\n",
      "EPOCH 6344  (with max 8000), loss: 0.020927390083670616\n",
      "train time for 6344 epochs, was 5211.711874485016\n",
      "\n",
      "EPOCH 6346  (with max 8000), loss: 0.010808785445988178\n",
      "train time for 6346 epochs, was 5213.345058679581\n",
      "\n",
      "EPOCH 6348  (with max 8000), loss: 0.018520928919315338\n",
      "train time for 6348 epochs, was 5214.978338956833\n",
      "\n",
      "EPOCH 6350  (with max 8000), loss: 0.013402756303548813\n",
      "train time for 6350 epochs, was 5216.611479520798\n",
      "\n",
      "EPOCH 6352  (with max 8000), loss: 0.0072891297750175\n",
      "train time for 6352 epochs, was 5218.267743349075\n",
      "\n",
      "EPOCH 6354  (with max 8000), loss: 0.01573915034532547\n",
      "train time for 6354 epochs, was 5219.901193857193\n",
      "\n",
      "EPOCH 6356  (with max 8000), loss: 0.03370765596628189\n",
      "train time for 6356 epochs, was 5221.534285783768\n",
      "\n",
      "EPOCH 6358  (with max 8000), loss: 0.013830759562551975\n",
      "train time for 6358 epochs, was 5223.169380426407\n",
      "\n",
      "EPOCH 6360  (with max 8000), loss: 0.049972306936979294\n",
      "train time for 6360 epochs, was 5224.802450656891\n",
      "\n",
      "EPOCH 6362  (with max 8000), loss: 0.02020157128572464\n",
      "train time for 6362 epochs, was 5226.437495708466\n",
      "\n",
      "EPOCH 6364  (with max 8000), loss: 0.018516283482313156\n",
      "train time for 6364 epochs, was 5228.0727186203\n",
      "\n",
      "EPOCH 6366  (with max 8000), loss: 0.014612912200391293\n",
      "train time for 6366 epochs, was 5229.705882072449\n",
      "\n",
      "EPOCH 6368  (with max 8000), loss: 0.011598104611039162\n",
      "train time for 6368 epochs, was 5231.338910341263\n",
      "\n",
      "EPOCH 6370  (with max 8000), loss: 0.008891573175787926\n",
      "train time for 6370 epochs, was 5232.9720141887665\n",
      "\n",
      "EPOCH 6372  (with max 8000), loss: 0.05830784887075424\n",
      "train time for 6372 epochs, was 5234.607425928116\n",
      "\n",
      "EPOCH 6374  (with max 8000), loss: 0.029594196006655693\n",
      "train time for 6374 epochs, was 5236.242545843124\n",
      "\n",
      "EPOCH 6376  (with max 8000), loss: 0.018758589401841164\n",
      "train time for 6376 epochs, was 5237.894262075424\n",
      "\n",
      "EPOCH 6378  (with max 8000), loss: 1.525484323501587\n",
      "train time for 6378 epochs, was 5239.527178764343\n",
      "\n",
      "EPOCH 6380  (with max 8000), loss: 0.033695414662361145\n",
      "train time for 6380 epochs, was 5241.162326335907\n",
      "\n",
      "EPOCH 6382  (with max 8000), loss: 0.021816842257976532\n",
      "train time for 6382 epochs, was 5242.7953062057495\n",
      "\n",
      "EPOCH 6384  (with max 8000), loss: 0.02877712994813919\n",
      "train time for 6384 epochs, was 5244.428256511688\n",
      "\n",
      "EPOCH 6386  (with max 8000), loss: 0.016999484971165657\n",
      "train time for 6386 epochs, was 5246.061218738556\n",
      "\n",
      "EPOCH 6388  (with max 8000), loss: 0.01161238458007574\n",
      "train time for 6388 epochs, was 5247.6942048072815\n",
      "\n",
      "EPOCH 6390  (with max 8000), loss: 0.01702968403697014\n",
      "train time for 6390 epochs, was 5249.381902933121\n",
      "\n",
      "EPOCH 6392  (with max 8000), loss: 0.00815262645483017\n",
      "train time for 6392 epochs, was 5251.023219823837\n",
      "\n",
      "EPOCH 6394  (with max 8000), loss: 0.01428322121500969\n",
      "train time for 6394 epochs, was 5252.656118631363\n",
      "\n",
      "EPOCH 6396  (with max 8000), loss: 0.018110930919647217\n",
      "train time for 6396 epochs, was 5254.293300867081\n",
      "\n",
      "EPOCH 6398  (with max 8000), loss: 0.01869743876159191\n",
      "train time for 6398 epochs, was 5255.926443338394\n",
      "\n",
      "EPOCH 6400  (with max 8000), loss: 0.009460671804845333\n",
      "train time for 6400 epochs, was 5257.55970621109\n",
      "\n",
      "EPOCH 6400 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_6400.pth\n",
      "\n",
      "EPOCH 6402  (with max 8000), loss: 0.031111251562833786\n",
      "train time for 6402 epochs, was 5259.228350639343\n",
      "\n",
      "EPOCH 6404  (with max 8000), loss: 0.012134765274822712\n",
      "train time for 6404 epochs, was 5260.861353635788\n",
      "\n",
      "EPOCH 6406  (with max 8000), loss: 0.010242659598588943\n",
      "train time for 6406 epochs, was 5262.494358301163\n",
      "\n",
      "EPOCH 6408  (with max 8000), loss: 0.010858947411179543\n",
      "train time for 6408 epochs, was 5264.127239227295\n",
      "\n",
      "EPOCH 6410  (with max 8000), loss: 0.015121053904294968\n",
      "train time for 6410 epochs, was 5265.76012301445\n",
      "\n",
      "EPOCH 6412  (with max 8000), loss: 0.010891839861869812\n",
      "train time for 6412 epochs, was 5267.392935991287\n",
      "\n",
      "EPOCH 6414  (with max 8000), loss: 0.01332160271704197\n",
      "train time for 6414 epochs, was 5269.025963544846\n",
      "\n",
      "EPOCH 6416  (with max 8000), loss: 0.008092224597930908\n",
      "train time for 6416 epochs, was 5270.659066915512\n",
      "\n",
      "EPOCH 6418  (with max 8000), loss: 0.0177000779658556\n",
      "train time for 6418 epochs, was 5272.294338226318\n",
      "\n",
      "EPOCH 6420  (with max 8000), loss: 0.011396474204957485\n",
      "train time for 6420 epochs, was 5273.927320957184\n",
      "\n",
      "EPOCH 6422  (with max 8000), loss: 0.01683562435209751\n",
      "train time for 6422 epochs, was 5275.560329437256\n",
      "\n",
      "EPOCH 6424  (with max 8000), loss: 0.01534095499664545\n",
      "train time for 6424 epochs, was 5277.193513631821\n",
      "\n",
      "EPOCH 6426  (with max 8000), loss: 0.17211902141571045\n",
      "train time for 6426 epochs, was 5278.82642698288\n",
      "\n",
      "EPOCH 6428  (with max 8000), loss: 0.02539789490401745\n",
      "train time for 6428 epochs, was 5280.459372282028\n",
      "\n",
      "EPOCH 6430  (with max 8000), loss: 0.01996763050556183\n",
      "train time for 6430 epochs, was 5282.092314958572\n",
      "\n",
      "EPOCH 6432  (with max 8000), loss: 0.012483049184083939\n",
      "train time for 6432 epochs, was 5283.725229740143\n",
      "\n",
      "EPOCH 6434  (with max 8000), loss: 0.020140303298830986\n",
      "train time for 6434 epochs, was 5285.360489368439\n",
      "\n",
      "EPOCH 6436  (with max 8000), loss: 0.017583563923835754\n",
      "train time for 6436 epochs, was 5286.993542432785\n",
      "\n",
      "EPOCH 6438  (with max 8000), loss: 0.017748940736055374\n",
      "train time for 6438 epochs, was 5288.6265704631805\n",
      "\n",
      "EPOCH 6440  (with max 8000), loss: 0.01769077405333519\n",
      "train time for 6440 epochs, was 5290.280483722687\n",
      "\n",
      "EPOCH 6442  (with max 8000), loss: 0.004079463426023722\n",
      "train time for 6442 epochs, was 5291.915939331055\n",
      "\n",
      "EPOCH 6444  (with max 8000), loss: 0.014368473552167416\n",
      "train time for 6444 epochs, was 5293.549225568771\n",
      "\n",
      "EPOCH 6446  (with max 8000), loss: 0.01707754284143448\n",
      "train time for 6446 epochs, was 5295.1824259758\n",
      "\n",
      "EPOCH 6448  (with max 8000), loss: 0.017567938193678856\n",
      "train time for 6448 epochs, was 5296.815424919128\n",
      "\n",
      "EPOCH 6450  (with max 8000), loss: 0.02077612839639187\n",
      "train time for 6450 epochs, was 5298.448681354523\n",
      "\n",
      "EPOCH 6452  (with max 8000), loss: 0.011842803098261356\n",
      "train time for 6452 epochs, was 5300.083810567856\n",
      "\n",
      "EPOCH 6454  (with max 8000), loss: 0.008390329778194427\n",
      "train time for 6454 epochs, was 5301.716878890991\n",
      "\n",
      "EPOCH 6456  (with max 8000), loss: 0.02108423411846161\n",
      "train time for 6456 epochs, was 5303.350061178207\n",
      "\n",
      "EPOCH 6458  (with max 8000), loss: 0.008467266336083412\n",
      "train time for 6458 epochs, was 5304.983182430267\n",
      "\n",
      "EPOCH 6460  (with max 8000), loss: 0.00964412372559309\n",
      "train time for 6460 epochs, was 5306.616457462311\n",
      "\n",
      "EPOCH 6462  (with max 8000), loss: 0.005264335311949253\n",
      "train time for 6462 epochs, was 5308.249529361725\n",
      "\n",
      "EPOCH 6464  (with max 8000), loss: 0.01615247130393982\n",
      "train time for 6464 epochs, was 5309.884737253189\n",
      "\n",
      "EPOCH 6466  (with max 8000), loss: 0.020678864791989326\n",
      "train time for 6466 epochs, was 5311.517872571945\n",
      "\n",
      "EPOCH 6468  (with max 8000), loss: 0.010364208370447159\n",
      "train time for 6468 epochs, was 5313.151084184647\n",
      "\n",
      "EPOCH 6470  (with max 8000), loss: 0.011612939648330212\n",
      "train time for 6470 epochs, was 5314.7840938568115\n",
      "\n",
      "EPOCH 6472  (with max 8000), loss: 0.012847291305661201\n",
      "train time for 6472 epochs, was 5316.417263507843\n",
      "\n",
      "EPOCH 6474  (with max 8000), loss: 0.00827665627002716\n",
      "train time for 6474 epochs, was 5318.050572156906\n",
      "\n",
      "EPOCH 6476  (with max 8000), loss: 0.01462713535875082\n",
      "train time for 6476 epochs, was 5319.685910701752\n",
      "\n",
      "EPOCH 6478  (with max 8000), loss: 0.031616974622011185\n",
      "train time for 6478 epochs, was 5321.31938624382\n",
      "\n",
      "EPOCH 6480  (with max 8000), loss: 0.04685399681329727\n",
      "train time for 6480 epochs, was 5322.952543735504\n",
      "\n",
      "EPOCH 6482  (with max 8000), loss: 0.02546357363462448\n",
      "train time for 6482 epochs, was 5324.58566904068\n",
      "\n",
      "EPOCH 6484  (with max 8000), loss: 0.020800219848752022\n",
      "train time for 6484 epochs, was 5326.218579053879\n",
      "\n",
      "EPOCH 6486  (with max 8000), loss: 0.016968606039881706\n",
      "train time for 6486 epochs, was 5327.853765487671\n",
      "\n",
      "EPOCH 6488  (with max 8000), loss: 0.019439322873950005\n",
      "train time for 6488 epochs, was 5329.487021207809\n",
      "\n",
      "EPOCH 6490  (with max 8000), loss: 0.013113673776388168\n",
      "train time for 6490 epochs, was 5331.120305299759\n",
      "\n",
      "EPOCH 6492  (with max 8000), loss: 0.03452744707465172\n",
      "train time for 6492 epochs, was 5332.753473043442\n",
      "\n",
      "EPOCH 6494  (with max 8000), loss: 0.010163398459553719\n",
      "train time for 6494 epochs, was 5334.386642932892\n",
      "\n",
      "EPOCH 6496  (with max 8000), loss: 0.026313934475183487\n",
      "train time for 6496 epochs, was 5336.023899316788\n",
      "\n",
      "EPOCH 6498  (with max 8000), loss: 0.03576015308499336\n",
      "train time for 6498 epochs, was 5337.659149646759\n",
      "\n",
      "EPOCH 6500  (with max 8000), loss: 0.047241903841495514\n",
      "train time for 6500 epochs, was 5339.294353485107\n",
      "\n",
      "EPOCH 6502  (with max 8000), loss: 0.009762161411345005\n",
      "train time for 6502 epochs, was 5340.929696321487\n",
      "\n",
      "EPOCH 6504  (with max 8000), loss: 0.025323914363980293\n",
      "train time for 6504 epochs, was 5342.565132856369\n",
      "\n",
      "EPOCH 6506  (with max 8000), loss: 0.17765292525291443\n",
      "train time for 6506 epochs, was 5344.198310136795\n",
      "\n",
      "EPOCH 6508  (with max 8000), loss: 0.04515993967652321\n",
      "train time for 6508 epochs, was 5345.831472158432\n",
      "\n",
      "EPOCH 6510  (with max 8000), loss: 0.029824933037161827\n",
      "train time for 6510 epochs, was 5347.464699983597\n",
      "\n",
      "EPOCH 6512  (with max 8000), loss: 0.015134193934500217\n",
      "train time for 6512 epochs, was 5349.097950458527\n",
      "\n",
      "EPOCH 6514  (with max 8000), loss: 0.01570228673517704\n",
      "train time for 6514 epochs, was 5350.733069896698\n",
      "\n",
      "EPOCH 6516  (with max 8000), loss: 0.033541519194841385\n",
      "train time for 6516 epochs, was 5352.366211652756\n",
      "\n",
      "EPOCH 6518  (with max 8000), loss: 0.013145837932825089\n",
      "train time for 6518 epochs, was 5354.001492738724\n",
      "\n",
      "EPOCH 6520  (with max 8000), loss: 0.010003285482525826\n",
      "train time for 6520 epochs, was 5355.636729955673\n",
      "\n",
      "EPOCH 6522  (with max 8000), loss: 0.015852341428399086\n",
      "train time for 6522 epochs, was 5357.270063877106\n",
      "\n",
      "EPOCH 6524  (with max 8000), loss: 0.024968085810542107\n",
      "train time for 6524 epochs, was 5358.903302431107\n",
      "\n",
      "EPOCH 6526  (with max 8000), loss: 0.011683198623359203\n",
      "train time for 6526 epochs, was 5360.536477804184\n",
      "\n",
      "EPOCH 6528  (with max 8000), loss: 0.02544218860566616\n",
      "train time for 6528 epochs, was 5362.169615507126\n",
      "\n",
      "EPOCH 6530  (with max 8000), loss: 0.014084252528846264\n",
      "train time for 6530 epochs, was 5363.819492340088\n",
      "\n",
      "EPOCH 6532  (with max 8000), loss: 0.019891928881406784\n",
      "train time for 6532 epochs, was 5365.452566385269\n",
      "\n",
      "EPOCH 6534  (with max 8000), loss: 0.01862145960330963\n",
      "train time for 6534 epochs, was 5367.087785482407\n",
      "\n",
      "EPOCH 6536  (with max 8000), loss: 0.00895128957927227\n",
      "train time for 6536 epochs, was 5368.720992326736\n",
      "\n",
      "EPOCH 6538  (with max 8000), loss: 0.012466991320252419\n",
      "train time for 6538 epochs, was 5370.354412317276\n",
      "\n",
      "EPOCH 6540  (with max 8000), loss: 0.013173451647162437\n",
      "train time for 6540 epochs, was 5371.987482070923\n",
      "\n",
      "EPOCH 6542  (with max 8000), loss: 0.01150729600340128\n",
      "train time for 6542 epochs, was 5373.620546579361\n",
      "\n",
      "EPOCH 6544  (with max 8000), loss: 0.012081677094101906\n",
      "train time for 6544 epochs, was 5375.253622770309\n",
      "\n",
      "EPOCH 6546  (with max 8000), loss: 0.01088708359748125\n",
      "train time for 6546 epochs, was 5376.8886523246765\n",
      "\n",
      "EPOCH 6548  (with max 8000), loss: 0.0131329745054245\n",
      "train time for 6548 epochs, was 5378.521703004837\n",
      "\n",
      "EPOCH 6550  (with max 8000), loss: 0.015822501853108406\n",
      "train time for 6550 epochs, was 5380.154706478119\n",
      "\n",
      "EPOCH 6552  (with max 8000), loss: 0.007744230795651674\n",
      "train time for 6552 epochs, was 5381.789965867996\n",
      "\n",
      "EPOCH 6554  (with max 8000), loss: 0.017473265528678894\n",
      "train time for 6554 epochs, was 5383.423407793045\n",
      "\n",
      "EPOCH 6556  (with max 8000), loss: 0.2852471172809601\n",
      "train time for 6556 epochs, was 5385.056809425354\n",
      "\n",
      "EPOCH 6558  (with max 8000), loss: 0.03502938523888588\n",
      "train time for 6558 epochs, was 5386.690323829651\n",
      "\n",
      "EPOCH 6560  (with max 8000), loss: 0.032708510756492615\n",
      "train time for 6560 epochs, was 5388.323538780212\n",
      "\n",
      "EPOCH 6562  (with max 8000), loss: 0.015965985134243965\n",
      "train time for 6562 epochs, was 5389.956739664078\n",
      "\n",
      "EPOCH 6564  (with max 8000), loss: 0.008490605279803276\n",
      "train time for 6564 epochs, was 5391.589801311493\n",
      "\n",
      "EPOCH 6566  (with max 8000), loss: 0.011282645165920258\n",
      "train time for 6566 epochs, was 5393.22271156311\n",
      "\n",
      "EPOCH 6568  (with max 8000), loss: 0.015326949767768383\n",
      "train time for 6568 epochs, was 5394.855713129044\n",
      "\n",
      "EPOCH 6570  (with max 8000), loss: 0.008849241770803928\n",
      "train time for 6570 epochs, was 5396.488623857498\n",
      "\n",
      "EPOCH 6572  (with max 8000), loss: 0.013012304902076721\n",
      "train time for 6572 epochs, was 5398.14031291008\n",
      "\n",
      "EPOCH 6574  (with max 8000), loss: 0.014639753848314285\n",
      "train time for 6574 epochs, was 5399.784030199051\n",
      "\n",
      "EPOCH 6576  (with max 8000), loss: 0.011536347679793835\n",
      "train time for 6576 epochs, was 5401.423367500305\n",
      "\n",
      "EPOCH 6578  (with max 8000), loss: 0.013738561421632767\n",
      "train time for 6578 epochs, was 5403.058621883392\n",
      "\n",
      "EPOCH 6580  (with max 8000), loss: 0.015978623181581497\n",
      "train time for 6580 epochs, was 5404.693836927414\n",
      "\n",
      "EPOCH 6582  (with max 8000), loss: 0.010652768425643444\n",
      "train time for 6582 epochs, was 5406.3271741867065\n",
      "\n",
      "EPOCH 6584  (with max 8000), loss: 0.007965371944010258\n",
      "train time for 6584 epochs, was 5407.960573673248\n",
      "\n",
      "EPOCH 6586  (with max 8000), loss: 0.03175870329141617\n",
      "train time for 6586 epochs, was 5409.593791723251\n",
      "\n",
      "EPOCH 6588  (with max 8000), loss: 0.00886826403439045\n",
      "train time for 6588 epochs, was 5411.2290868759155\n",
      "\n",
      "EPOCH 6590  (with max 8000), loss: 0.015169884078204632\n",
      "train time for 6590 epochs, was 5412.862242937088\n",
      "\n",
      "EPOCH 6592  (with max 8000), loss: 0.9033939242362976\n",
      "train time for 6592 epochs, was 5414.495485305786\n",
      "\n",
      "EPOCH 6594  (with max 8000), loss: 0.03775731846690178\n",
      "train time for 6594 epochs, was 5416.130611896515\n",
      "\n",
      "EPOCH 6596  (with max 8000), loss: 0.02280343510210514\n",
      "train time for 6596 epochs, was 5417.763604402542\n",
      "\n",
      "EPOCH 6598  (with max 8000), loss: 0.019785450771450996\n",
      "train time for 6598 epochs, was 5419.396698951721\n",
      "\n",
      "EPOCH 6600  (with max 8000), loss: 0.02829398401081562\n",
      "train time for 6600 epochs, was 5421.03000998497\n",
      "\n",
      "EPOCH 6600 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_6600.pth\n",
      "\n",
      "EPOCH 6602  (with max 8000), loss: 0.01652311347424984\n",
      "train time for 6602 epochs, was 5422.698897123337\n",
      "\n",
      "EPOCH 6604  (with max 8000), loss: 0.013989710249006748\n",
      "train time for 6604 epochs, was 5424.332090854645\n",
      "\n",
      "EPOCH 6606  (with max 8000), loss: 0.014356935396790504\n",
      "train time for 6606 epochs, was 5425.9653170108795\n",
      "\n",
      "EPOCH 6608  (with max 8000), loss: 0.0163896307349205\n",
      "train time for 6608 epochs, was 5427.600495100021\n",
      "\n",
      "EPOCH 6610  (with max 8000), loss: 0.016206732019782066\n",
      "train time for 6610 epochs, was 5429.233338356018\n",
      "\n",
      "EPOCH 6612  (with max 8000), loss: 0.03946087136864662\n",
      "train time for 6612 epochs, was 5430.866078853607\n",
      "\n",
      "EPOCH 6614  (with max 8000), loss: 0.011301986873149872\n",
      "train time for 6614 epochs, was 5432.499031305313\n",
      "\n",
      "EPOCH 6616  (with max 8000), loss: 0.022025419399142265\n",
      "train time for 6616 epochs, was 5434.138424873352\n",
      "\n",
      "EPOCH 6618  (with max 8000), loss: 0.017167774960398674\n",
      "train time for 6618 epochs, was 5435.786548137665\n",
      "\n",
      "EPOCH 6620  (with max 8000), loss: 0.009221287444233894\n",
      "train time for 6620 epochs, was 5437.419753789902\n",
      "\n",
      "EPOCH 6622  (with max 8000), loss: 0.014504852704703808\n",
      "train time for 6622 epochs, was 5439.057174682617\n",
      "\n",
      "EPOCH 6624  (with max 8000), loss: 0.016137607395648956\n",
      "train time for 6624 epochs, was 5440.694658279419\n",
      "\n",
      "EPOCH 6626  (with max 8000), loss: 0.008982566185295582\n",
      "train time for 6626 epochs, was 5442.3300631046295\n",
      "\n",
      "EPOCH 6628  (with max 8000), loss: 0.007994405925273895\n",
      "train time for 6628 epochs, was 5443.965203285217\n",
      "\n",
      "EPOCH 6630  (with max 8000), loss: 0.010321792215108871\n",
      "train time for 6630 epochs, was 5445.600701570511\n",
      "\n",
      "EPOCH 6632  (with max 8000), loss: 0.007970821112394333\n",
      "train time for 6632 epochs, was 5447.238354921341\n",
      "\n",
      "EPOCH 6634  (with max 8000), loss: 0.013011648319661617\n",
      "train time for 6634 epochs, was 5448.871780395508\n",
      "\n",
      "EPOCH 6636  (with max 8000), loss: 0.005144296679645777\n",
      "train time for 6636 epochs, was 5450.509526491165\n",
      "\n",
      "EPOCH 6638  (with max 8000), loss: 0.008026675321161747\n",
      "train time for 6638 epochs, was 5452.144683122635\n",
      "\n",
      "EPOCH 6640  (with max 8000), loss: 0.01734103076159954\n",
      "train time for 6640 epochs, was 5453.777755022049\n",
      "\n",
      "EPOCH 6642  (with max 8000), loss: 0.008245501667261124\n",
      "train time for 6642 epochs, was 5455.415219783783\n",
      "\n",
      "EPOCH 6644  (with max 8000), loss: 1.371644377708435\n",
      "train time for 6644 epochs, was 5457.048617601395\n",
      "\n",
      "EPOCH 6646  (with max 8000), loss: 0.035523220896720886\n",
      "train time for 6646 epochs, was 5458.681597471237\n",
      "\n",
      "EPOCH 6648  (with max 8000), loss: 0.036660026758909225\n",
      "train time for 6648 epochs, was 5460.314690828323\n",
      "\n",
      "EPOCH 6650  (with max 8000), loss: 0.018506865948438644\n",
      "train time for 6650 epochs, was 5461.947549104691\n",
      "\n",
      "EPOCH 6652  (with max 8000), loss: 0.11575718224048615\n",
      "train time for 6652 epochs, was 5463.580632686615\n",
      "\n",
      "EPOCH 6654  (with max 8000), loss: 0.02357480302453041\n",
      "train time for 6654 epochs, was 5465.21372127533\n",
      "\n",
      "EPOCH 6656  (with max 8000), loss: 0.013615615665912628\n",
      "train time for 6656 epochs, was 5466.846872806549\n",
      "\n",
      "EPOCH 6658  (with max 8000), loss: 0.015267111361026764\n",
      "train time for 6658 epochs, was 5468.480135440826\n",
      "\n",
      "EPOCH 6660  (with max 8000), loss: 0.003799605881795287\n",
      "train time for 6660 epochs, was 5470.142751455307\n",
      "\n",
      "EPOCH 6662  (with max 8000), loss: 0.02991860918700695\n",
      "train time for 6662 epochs, was 5471.782364845276\n",
      "\n",
      "EPOCH 6664  (with max 8000), loss: 0.012741900980472565\n",
      "train time for 6664 epochs, was 5473.4157538414\n",
      "\n",
      "EPOCH 6666  (with max 8000), loss: 0.01230701059103012\n",
      "train time for 6666 epochs, was 5475.069899082184\n",
      "\n",
      "EPOCH 6668  (with max 8000), loss: 0.012356013990938663\n",
      "train time for 6668 epochs, was 5476.705126285553\n",
      "\n",
      "EPOCH 6670  (with max 8000), loss: 0.010112680494785309\n",
      "train time for 6670 epochs, was 5478.342826366425\n",
      "\n",
      "EPOCH 6672  (with max 8000), loss: 0.014647339470684528\n",
      "train time for 6672 epochs, was 5479.982491970062\n",
      "\n",
      "EPOCH 6674  (with max 8000), loss: 0.00959338340908289\n",
      "train time for 6674 epochs, was 5481.615969657898\n",
      "\n",
      "EPOCH 6676  (with max 8000), loss: 0.006454078946262598\n",
      "train time for 6676 epochs, was 5483.251413345337\n",
      "\n",
      "EPOCH 6678  (with max 8000), loss: 0.008921241387724876\n",
      "train time for 6678 epochs, was 5484.884758234024\n",
      "\n",
      "EPOCH 6680  (with max 8000), loss: 0.011301065795123577\n",
      "train time for 6680 epochs, was 5486.5219004154205\n",
      "\n",
      "EPOCH 6682  (with max 8000), loss: 0.012451562099158764\n",
      "train time for 6682 epochs, was 5488.156927585602\n",
      "\n",
      "EPOCH 6684  (with max 8000), loss: 0.021685853600502014\n",
      "train time for 6684 epochs, was 5489.798256635666\n",
      "\n",
      "EPOCH 6686  (with max 8000), loss: 0.010855823755264282\n",
      "train time for 6686 epochs, was 5491.431409358978\n",
      "\n",
      "EPOCH 6688  (with max 8000), loss: 0.008502260781824589\n",
      "train time for 6688 epochs, was 5493.064841270447\n",
      "\n",
      "EPOCH 6690  (with max 8000), loss: 0.1863950490951538\n",
      "train time for 6690 epochs, was 5494.70033788681\n",
      "\n",
      "EPOCH 6692  (with max 8000), loss: 0.017006749287247658\n",
      "train time for 6692 epochs, was 5496.333449840546\n",
      "\n",
      "EPOCH 6694  (with max 8000), loss: 0.02101800963282585\n",
      "train time for 6694 epochs, was 5497.966531991959\n",
      "\n",
      "EPOCH 6696  (with max 8000), loss: 0.016591504216194153\n",
      "train time for 6696 epochs, was 5499.599691390991\n",
      "\n",
      "EPOCH 6698  (with max 8000), loss: 0.01900498755276203\n",
      "train time for 6698 epochs, was 5501.232904911041\n",
      "\n",
      "EPOCH 6700  (with max 8000), loss: 0.009978107176721096\n",
      "train time for 6700 epochs, was 5502.868370771408\n",
      "\n",
      "EPOCH 6702  (with max 8000), loss: 0.012892195954918861\n",
      "train time for 6702 epochs, was 5504.510154247284\n",
      "\n",
      "EPOCH 6704  (with max 8000), loss: 0.005625148303806782\n",
      "train time for 6704 epochs, was 5506.147737979889\n",
      "\n",
      "EPOCH 6706  (with max 8000), loss: 0.009158016182482243\n",
      "train time for 6706 epochs, was 5507.785497903824\n",
      "\n",
      "EPOCH 6708  (with max 8000), loss: 0.01352280005812645\n",
      "train time for 6708 epochs, was 5509.423305034637\n",
      "\n",
      "EPOCH 6710  (with max 8000), loss: 0.01865108124911785\n",
      "train time for 6710 epochs, was 5511.056683778763\n",
      "\n",
      "EPOCH 6712  (with max 8000), loss: 0.017271166667342186\n",
      "train time for 6712 epochs, was 5512.6899383068085\n",
      "\n",
      "EPOCH 6714  (with max 8000), loss: 0.008153151720762253\n",
      "train time for 6714 epochs, was 5514.323252439499\n",
      "\n",
      "EPOCH 6716  (with max 8000), loss: 0.01648031361401081\n",
      "train time for 6716 epochs, was 5515.956613302231\n",
      "\n",
      "EPOCH 6718  (with max 8000), loss: 0.006776921916753054\n",
      "train time for 6718 epochs, was 5517.590186834335\n",
      "\n",
      "EPOCH 6720  (with max 8000), loss: 0.009078416042029858\n",
      "train time for 6720 epochs, was 5519.223451375961\n",
      "\n",
      "EPOCH 6722  (with max 8000), loss: 0.020732438191771507\n",
      "train time for 6722 epochs, was 5520.858881235123\n",
      "\n",
      "EPOCH 6724  (with max 8000), loss: 0.09535159915685654\n",
      "train time for 6724 epochs, was 5522.498472929001\n",
      "\n",
      "EPOCH 6726  (with max 8000), loss: 0.03269048035144806\n",
      "train time for 6726 epochs, was 5524.131741762161\n",
      "\n",
      "EPOCH 6728  (with max 8000), loss: 0.013756782747805119\n",
      "train time for 6728 epochs, was 5525.765026807785\n",
      "\n",
      "EPOCH 6730  (with max 8000), loss: 0.035010870546102524\n",
      "train time for 6730 epochs, was 5527.400441646576\n",
      "\n",
      "EPOCH 6732  (with max 8000), loss: 0.008397187106311321\n",
      "train time for 6732 epochs, was 5529.0338742733\n",
      "\n",
      "EPOCH 6734  (with max 8000), loss: 0.018408384174108505\n",
      "train time for 6734 epochs, was 5530.667298555374\n",
      "\n",
      "EPOCH 6736  (with max 8000), loss: 0.013004845008254051\n",
      "train time for 6736 epochs, was 5532.306858778\n",
      "\n",
      "EPOCH 6738  (with max 8000), loss: 0.01937786303460598\n",
      "train time for 6738 epochs, was 5533.956929445267\n",
      "\n",
      "EPOCH 6740  (with max 8000), loss: 0.008159739896655083\n",
      "train time for 6740 epochs, was 5535.592482089996\n",
      "\n",
      "EPOCH 6742  (with max 8000), loss: 0.013281897641718388\n",
      "train time for 6742 epochs, was 5537.229980945587\n",
      "\n",
      "EPOCH 6744  (with max 8000), loss: 0.011505584232509136\n",
      "train time for 6744 epochs, was 5538.877915620804\n",
      "\n",
      "EPOCH 6746  (with max 8000), loss: 0.008790855295956135\n",
      "train time for 6746 epochs, was 5540.513323068619\n",
      "\n",
      "EPOCH 6748  (with max 8000), loss: 0.009459072723984718\n",
      "train time for 6748 epochs, was 5542.165553808212\n",
      "\n",
      "EPOCH 6750  (with max 8000), loss: 0.0074294754303991795\n",
      "train time for 6750 epochs, was 5543.801113605499\n",
      "\n",
      "EPOCH 6752  (with max 8000), loss: 0.009987219236791134\n",
      "train time for 6752 epochs, was 5545.434569835663\n",
      "\n",
      "EPOCH 6754  (with max 8000), loss: 0.0070183975622057915\n",
      "train time for 6754 epochs, was 5547.068053007126\n",
      "\n",
      "EPOCH 6756  (with max 8000), loss: 0.2591101825237274\n",
      "train time for 6756 epochs, was 5548.701468706131\n",
      "\n",
      "EPOCH 6758  (with max 8000), loss: 0.035335034132003784\n",
      "train time for 6758 epochs, was 5550.3349006175995\n",
      "\n",
      "EPOCH 6760  (with max 8000), loss: 0.01061976794153452\n",
      "train time for 6760 epochs, was 5551.970344305038\n",
      "\n",
      "EPOCH 6762  (with max 8000), loss: 0.010604106821119785\n",
      "train time for 6762 epochs, was 5553.603683233261\n",
      "\n",
      "EPOCH 6764  (with max 8000), loss: 0.011555475182831287\n",
      "train time for 6764 epochs, was 5555.239112615585\n",
      "\n",
      "EPOCH 6766  (with max 8000), loss: 0.01911858655512333\n",
      "train time for 6766 epochs, was 5556.872595787048\n",
      "\n",
      "EPOCH 6768  (with max 8000), loss: 0.0119499946013093\n",
      "train time for 6768 epochs, was 5558.520616531372\n",
      "\n",
      "EPOCH 6770  (with max 8000), loss: 0.009689155034720898\n",
      "train time for 6770 epochs, was 5560.160218715668\n",
      "\n",
      "EPOCH 6772  (with max 8000), loss: 0.00608723284676671\n",
      "train time for 6772 epochs, was 5561.795730829239\n",
      "\n",
      "EPOCH 6774  (with max 8000), loss: 0.014016147702932358\n",
      "train time for 6774 epochs, was 5563.429247140884\n",
      "\n",
      "EPOCH 6776  (with max 8000), loss: 0.008848450146615505\n",
      "train time for 6776 epochs, was 5565.066940069199\n",
      "\n",
      "EPOCH 6778  (with max 8000), loss: 0.00851217657327652\n",
      "train time for 6778 epochs, was 5566.702323436737\n",
      "\n",
      "EPOCH 6780  (with max 8000), loss: 0.12498413771390915\n",
      "train time for 6780 epochs, was 5568.33794760704\n",
      "\n",
      "EPOCH 6782  (with max 8000), loss: 0.02205786108970642\n",
      "train time for 6782 epochs, was 5569.97155046463\n",
      "\n",
      "EPOCH 6784  (with max 8000), loss: 0.00833762064576149\n",
      "train time for 6784 epochs, was 5571.6072516441345\n",
      "\n",
      "EPOCH 6786  (with max 8000), loss: 0.004584403242915869\n",
      "train time for 6786 epochs, was 5573.240770101547\n",
      "\n",
      "EPOCH 6788  (with max 8000), loss: 0.007914343848824501\n",
      "train time for 6788 epochs, was 5574.878162145615\n",
      "\n",
      "EPOCH 6790  (with max 8000), loss: 0.010062954388558865\n",
      "train time for 6790 epochs, was 5576.51561999321\n",
      "\n",
      "EPOCH 6792  (with max 8000), loss: 0.011946935206651688\n",
      "train time for 6792 epochs, was 5578.167816400528\n",
      "\n",
      "EPOCH 6794  (with max 8000), loss: 0.010075472295284271\n",
      "train time for 6794 epochs, was 5579.805294752121\n",
      "\n",
      "EPOCH 6796  (with max 8000), loss: 0.004480008035898209\n",
      "train time for 6796 epochs, was 5581.4386377334595\n",
      "\n",
      "EPOCH 6798  (with max 8000), loss: 0.013668752275407314\n",
      "train time for 6798 epochs, was 5583.076150894165\n",
      "\n",
      "EPOCH 6800  (with max 8000), loss: 0.009744442068040371\n",
      "train time for 6800 epochs, was 5584.709458351135\n",
      "\n",
      "EPOCH 6800 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_6800.pth\n",
      "\n",
      "EPOCH 6802  (with max 8000), loss: 0.01578090526163578\n",
      "train time for 6802 epochs, was 5586.380739212036\n",
      "\n",
      "EPOCH 6804  (with max 8000), loss: 0.003502854611724615\n",
      "train time for 6804 epochs, was 5588.022345304489\n",
      "\n",
      "EPOCH 6806  (with max 8000), loss: 0.013207503594458103\n",
      "train time for 6806 epochs, was 5589.655574321747\n",
      "\n",
      "EPOCH 6808  (with max 8000), loss: 0.02207038924098015\n",
      "train time for 6808 epochs, was 5591.288865804672\n",
      "\n",
      "EPOCH 6810  (with max 8000), loss: 0.1417236030101776\n",
      "train time for 6810 epochs, was 5592.922294616699\n",
      "\n",
      "EPOCH 6812  (with max 8000), loss: 0.06552571803331375\n",
      "train time for 6812 epochs, was 5594.557703971863\n",
      "\n",
      "EPOCH 6814  (with max 8000), loss: 0.020451312884688377\n",
      "train time for 6814 epochs, was 5596.191025495529\n",
      "\n",
      "EPOCH 6816  (with max 8000), loss: 0.01722540706396103\n",
      "train time for 6816 epochs, was 5597.824268341064\n",
      "\n",
      "EPOCH 6818  (with max 8000), loss: 0.01363647822290659\n",
      "train time for 6818 epochs, was 5599.470181465149\n",
      "\n",
      "EPOCH 6820  (with max 8000), loss: 0.009303675964474678\n",
      "train time for 6820 epochs, was 5601.105617523193\n",
      "\n",
      "EPOCH 6822  (with max 8000), loss: 0.01123001892119646\n",
      "train time for 6822 epochs, was 5602.738834619522\n",
      "\n",
      "EPOCH 6824  (with max 8000), loss: 0.010291083715856075\n",
      "train time for 6824 epochs, was 5604.372039318085\n",
      "\n",
      "EPOCH 6826  (with max 8000), loss: 0.028187651187181473\n",
      "train time for 6826 epochs, was 5606.005305051804\n",
      "\n",
      "EPOCH 6828  (with max 8000), loss: 0.007441428489983082\n",
      "train time for 6828 epochs, was 5607.638823509216\n",
      "\n",
      "EPOCH 6830  (with max 8000), loss: 0.008348093368113041\n",
      "train time for 6830 epochs, was 5609.271964550018\n",
      "\n",
      "EPOCH 6832  (with max 8000), loss: 0.007572495844215155\n",
      "train time for 6832 epochs, was 5610.905185699463\n",
      "\n",
      "EPOCH 6834  (with max 8000), loss: 0.016017265617847443\n",
      "train time for 6834 epochs, was 5612.538451194763\n",
      "\n",
      "EPOCH 6836  (with max 8000), loss: 0.010412354953587055\n",
      "train time for 6836 epochs, was 5614.192807674408\n",
      "\n",
      "EPOCH 6838  (with max 8000), loss: 0.007795652840286493\n",
      "train time for 6838 epochs, was 5615.826148271561\n",
      "\n",
      "EPOCH 6840  (with max 8000), loss: 0.00914409477263689\n",
      "train time for 6840 epochs, was 5617.459442138672\n",
      "\n",
      "EPOCH 6842  (with max 8000), loss: 0.010339125990867615\n",
      "train time for 6842 epochs, was 5619.096966266632\n",
      "\n",
      "EPOCH 6844  (with max 8000), loss: 0.007729144301265478\n",
      "train time for 6844 epochs, was 5620.73041677475\n",
      "\n",
      "EPOCH 6846  (with max 8000), loss: 0.010558141395449638\n",
      "train time for 6846 epochs, was 5622.365915775299\n",
      "\n",
      "EPOCH 6848  (with max 8000), loss: 0.005393930245190859\n",
      "train time for 6848 epochs, was 5624.003425836563\n",
      "\n",
      "EPOCH 6850  (with max 8000), loss: 0.010379519313573837\n",
      "train time for 6850 epochs, was 5625.636636018753\n",
      "\n",
      "EPOCH 6852  (with max 8000), loss: 0.009543634951114655\n",
      "train time for 6852 epochs, was 5627.269873380661\n",
      "\n",
      "EPOCH 6854  (with max 8000), loss: 0.005352555774152279\n",
      "train time for 6854 epochs, was 5628.905454874039\n",
      "\n",
      "EPOCH 6856  (with max 8000), loss: 0.009463672526180744\n",
      "train time for 6856 epochs, was 5630.538819313049\n",
      "\n",
      "EPOCH 6858  (with max 8000), loss: 0.027088960632681847\n",
      "train time for 6858 epochs, was 5632.17213010788\n",
      "\n",
      "EPOCH 6860  (with max 8000), loss: 0.012348022311925888\n",
      "train time for 6860 epochs, was 5633.805552721024\n",
      "\n",
      "EPOCH 6862  (with max 8000), loss: 0.04004794731736183\n",
      "train time for 6862 epochs, was 5635.439125776291\n",
      "\n",
      "EPOCH 6864  (with max 8000), loss: 0.02030438557267189\n",
      "train time for 6864 epochs, was 5637.072538137436\n",
      "\n",
      "EPOCH 6866  (with max 8000), loss: 0.02544119767844677\n",
      "train time for 6866 epochs, was 5638.7058634758\n",
      "\n",
      "EPOCH 6868  (with max 8000), loss: 0.014699299819767475\n",
      "train time for 6868 epochs, was 5640.339189291\n",
      "\n",
      "EPOCH 6870  (with max 8000), loss: 0.021019572392106056\n",
      "train time for 6870 epochs, was 5641.9724843502045\n",
      "\n",
      "EPOCH 6872  (with max 8000), loss: 0.009899487718939781\n",
      "train time for 6872 epochs, was 5643.608001947403\n",
      "\n",
      "EPOCH 6874  (with max 8000), loss: 0.008459201082587242\n",
      "train time for 6874 epochs, was 5645.241242408752\n",
      "\n",
      "EPOCH 6876  (with max 8000), loss: 0.024619493633508682\n",
      "train time for 6876 epochs, was 5646.874548435211\n",
      "\n",
      "EPOCH 6878  (with max 8000), loss: 0.013204941526055336\n",
      "train time for 6878 epochs, was 5648.51006269455\n",
      "\n",
      "EPOCH 6880  (with max 8000), loss: 0.009081650525331497\n",
      "train time for 6880 epochs, was 5650.149931192398\n",
      "\n",
      "EPOCH 6882  (with max 8000), loss: 0.012045418843626976\n",
      "train time for 6882 epochs, was 5651.7957928180695\n",
      "\n",
      "EPOCH 6884  (with max 8000), loss: 0.009532930329442024\n",
      "train time for 6884 epochs, was 5653.431060791016\n",
      "\n",
      "EPOCH 6886  (with max 8000), loss: 0.004330479074269533\n",
      "train time for 6886 epochs, was 5655.064350128174\n",
      "\n",
      "EPOCH 6888  (with max 8000), loss: 0.7525030374526978\n",
      "train time for 6888 epochs, was 5656.69984459877\n",
      "\n",
      "EPOCH 6890  (with max 8000), loss: 0.03411812335252762\n",
      "train time for 6890 epochs, was 5658.333289861679\n",
      "\n",
      "EPOCH 6892  (with max 8000), loss: 0.018094712868332863\n",
      "train time for 6892 epochs, was 5659.966581821442\n",
      "\n",
      "EPOCH 6894  (with max 8000), loss: 0.0053711459040641785\n",
      "train time for 6894 epochs, was 5661.6021156311035\n",
      "\n",
      "EPOCH 6896  (with max 8000), loss: 0.008308342657983303\n",
      "train time for 6896 epochs, was 5663.235489845276\n",
      "\n",
      "EPOCH 6898  (with max 8000), loss: 0.01185599621385336\n",
      "train time for 6898 epochs, was 5664.868990898132\n",
      "\n",
      "EPOCH 6900  (with max 8000), loss: 0.01546140294522047\n",
      "train time for 6900 epochs, was 5666.502413749695\n",
      "\n",
      "EPOCH 6902  (with max 8000), loss: 0.008791464380919933\n",
      "train time for 6902 epochs, was 5668.135679244995\n",
      "\n",
      "EPOCH 6904  (with max 8000), loss: 1.3052787780761719\n",
      "train time for 6904 epochs, was 5669.768876791\n",
      "\n",
      "EPOCH 6906  (with max 8000), loss: 0.017544887959957123\n",
      "train time for 6906 epochs, was 5671.402152061462\n",
      "\n",
      "EPOCH 6908  (with max 8000), loss: 0.011362871155142784\n",
      "train time for 6908 epochs, was 5673.035463094711\n",
      "\n",
      "EPOCH 6910  (with max 8000), loss: 0.015721997246146202\n",
      "train time for 6910 epochs, was 5674.668769359589\n",
      "\n",
      "EPOCH 6912  (with max 8000), loss: 0.027575654909014702\n",
      "train time for 6912 epochs, was 5676.301980257034\n",
      "\n",
      "EPOCH 6914  (with max 8000), loss: 0.03661143407225609\n",
      "train time for 6914 epochs, was 5677.9353585243225\n",
      "\n",
      "EPOCH 6916  (with max 8000), loss: 0.01052457932382822\n",
      "train time for 6916 epochs, was 5679.568955659866\n",
      "\n",
      "EPOCH 6918  (with max 8000), loss: 0.020849579945206642\n",
      "train time for 6918 epochs, was 5681.204443454742\n",
      "\n",
      "EPOCH 6920  (with max 8000), loss: 0.045067645609378815\n",
      "train time for 6920 epochs, was 5682.837658166885\n",
      "\n",
      "EPOCH 6922  (with max 8000), loss: 0.009918345138430595\n",
      "train time for 6922 epochs, was 5684.471062660217\n",
      "\n",
      "EPOCH 6924  (with max 8000), loss: 0.014946470968425274\n",
      "train time for 6924 epochs, was 5686.119036912918\n",
      "\n",
      "EPOCH 6926  (with max 8000), loss: 0.01274323370307684\n",
      "train time for 6926 epochs, was 5687.752417087555\n",
      "\n",
      "EPOCH 6928  (with max 8000), loss: 0.016568144783377647\n",
      "train time for 6928 epochs, was 5689.386118650436\n",
      "\n",
      "EPOCH 6930  (with max 8000), loss: 0.012386062182486057\n",
      "train time for 6930 epochs, was 5691.0194725990295\n",
      "\n",
      "EPOCH 6932  (with max 8000), loss: 0.01013532467186451\n",
      "train time for 6932 epochs, was 5692.6529223918915\n",
      "\n",
      "EPOCH 6934  (with max 8000), loss: 0.010129516012966633\n",
      "train time for 6934 epochs, was 5694.286153078079\n",
      "\n",
      "EPOCH 6936  (with max 8000), loss: 0.010898863896727562\n",
      "train time for 6936 epochs, was 5695.919453620911\n",
      "\n",
      "EPOCH 6938  (with max 8000), loss: 0.0033909110352396965\n",
      "train time for 6938 epochs, was 5697.552711248398\n",
      "\n",
      "EPOCH 6940  (with max 8000), loss: 0.011992095038294792\n",
      "train time for 6940 epochs, was 5699.185968160629\n",
      "\n",
      "EPOCH 6942  (with max 8000), loss: 0.026659559458494186\n",
      "train time for 6942 epochs, was 5700.819558143616\n",
      "\n",
      "EPOCH 6944  (with max 8000), loss: 0.008177999407052994\n",
      "train time for 6944 epochs, was 5702.480067253113\n",
      "\n",
      "EPOCH 6946  (with max 8000), loss: 0.0053551653400063515\n",
      "train time for 6946 epochs, was 5704.117397546768\n",
      "\n",
      "EPOCH 6948  (with max 8000), loss: 0.07441568374633789\n",
      "train time for 6948 epochs, was 5705.750588655472\n",
      "\n",
      "EPOCH 6950  (with max 8000), loss: 0.019047236070036888\n",
      "train time for 6950 epochs, was 5707.3923172950745\n",
      "\n",
      "EPOCH 6952  (with max 8000), loss: 0.01252775453031063\n",
      "train time for 6952 epochs, was 5709.025497436523\n",
      "\n",
      "EPOCH 6954  (with max 8000), loss: 0.01349334605038166\n",
      "train time for 6954 epochs, was 5710.6587433815\n",
      "\n",
      "EPOCH 6956  (with max 8000), loss: 0.010960224084556103\n",
      "train time for 6956 epochs, was 5712.291939496994\n",
      "\n",
      "EPOCH 6958  (with max 8000), loss: 0.020053910091519356\n",
      "train time for 6958 epochs, was 5713.92734503746\n",
      "\n",
      "EPOCH 6960  (with max 8000), loss: 0.023777030408382416\n",
      "train time for 6960 epochs, was 5715.5651087760925\n",
      "\n",
      "EPOCH 6962  (with max 8000), loss: 0.003439293010160327\n",
      "train time for 6962 epochs, was 5717.202737569809\n",
      "\n",
      "EPOCH 6964  (with max 8000), loss: 0.010187121108174324\n",
      "train time for 6964 epochs, was 5718.836151838303\n",
      "\n",
      "EPOCH 6966  (with max 8000), loss: 0.00649783993139863\n",
      "train time for 6966 epochs, was 5720.475869655609\n",
      "\n",
      "EPOCH 6968  (with max 8000), loss: 0.008722720667719841\n",
      "train time for 6968 epochs, was 5722.130307674408\n",
      "\n",
      "EPOCH 6970  (with max 8000), loss: 0.0068534789606928825\n",
      "train time for 6970 epochs, was 5723.763657569885\n",
      "\n",
      "EPOCH 6972  (with max 8000), loss: 0.006004934664815664\n",
      "train time for 6972 epochs, was 5725.3970811367035\n",
      "\n",
      "EPOCH 6974  (with max 8000), loss: 0.00739260483533144\n",
      "train time for 6974 epochs, was 5727.030477523804\n",
      "\n",
      "EPOCH 6976  (with max 8000), loss: 0.008084645494818687\n",
      "train time for 6976 epochs, was 5728.66614151001\n",
      "\n",
      "EPOCH 6978  (with max 8000), loss: 0.006403924897313118\n",
      "train time for 6978 epochs, was 5730.299435138702\n",
      "\n",
      "EPOCH 6980  (with max 8000), loss: 0.0048347110860049725\n",
      "train time for 6980 epochs, was 5731.932626485825\n",
      "\n",
      "EPOCH 6982  (with max 8000), loss: 0.0044606588780879974\n",
      "train time for 6982 epochs, was 5733.5658712387085\n",
      "\n",
      "EPOCH 6984  (with max 8000), loss: 0.013360216282308102\n",
      "train time for 6984 epochs, was 5735.199185371399\n",
      "\n",
      "EPOCH 6986  (with max 8000), loss: 0.004694255534559488\n",
      "train time for 6986 epochs, was 5736.839114665985\n",
      "\n",
      "EPOCH 6988  (with max 8000), loss: 0.015640150755643845\n",
      "train time for 6988 epochs, was 5738.472591638565\n",
      "\n",
      "EPOCH 6990  (with max 8000), loss: 0.0025823491159826517\n",
      "train time for 6990 epochs, was 5740.107873916626\n",
      "\n",
      "EPOCH 6992  (with max 8000), loss: 0.015846095979213715\n",
      "train time for 6992 epochs, was 5741.741221904755\n",
      "\n",
      "EPOCH 6994  (with max 8000), loss: 0.012650948949158192\n",
      "train time for 6994 epochs, was 5743.37694144249\n",
      "\n",
      "EPOCH 6996  (with max 8000), loss: 0.009092943742871284\n",
      "train time for 6996 epochs, was 5745.012498617172\n",
      "\n",
      "EPOCH 6998  (with max 8000), loss: 0.01131418813019991\n",
      "train time for 6998 epochs, was 5746.64585852623\n",
      "\n",
      "EPOCH 7000  (with max 8000), loss: 0.019893892109394073\n",
      "train time for 7000 epochs, was 5748.281346082687\n",
      "\n",
      "EPOCH 7000 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_7000.pth\n",
      "\n",
      "EPOCH 7002  (with max 8000), loss: 0.009944050572812557\n",
      "train time for 7002 epochs, was 5749.950540065765\n",
      "\n",
      "EPOCH 7004  (with max 8000), loss: 0.026212885975837708\n",
      "train time for 7004 epochs, was 5751.583973646164\n",
      "\n",
      "EPOCH 7006  (with max 8000), loss: 0.008059216663241386\n",
      "train time for 7006 epochs, was 5753.217502117157\n",
      "\n",
      "EPOCH 7008  (with max 8000), loss: 0.011903979815542698\n",
      "train time for 7008 epochs, was 5754.853055477142\n",
      "\n",
      "EPOCH 7010  (with max 8000), loss: 0.021793227642774582\n",
      "train time for 7010 epochs, was 5756.486455917358\n",
      "\n",
      "EPOCH 7012  (with max 8000), loss: 0.010052441619336605\n",
      "train time for 7012 epochs, was 5758.120065450668\n",
      "\n",
      "EPOCH 7014  (with max 8000), loss: 0.011871857568621635\n",
      "train time for 7014 epochs, was 5759.7741894721985\n",
      "\n",
      "EPOCH 7016  (with max 8000), loss: 0.015427757054567337\n",
      "train time for 7016 epochs, was 5761.407464504242\n",
      "\n",
      "EPOCH 7018  (with max 8000), loss: 0.0104031041264534\n",
      "train time for 7018 epochs, was 5763.044868707657\n",
      "\n",
      "EPOCH 7020  (with max 8000), loss: 0.2443651407957077\n",
      "train time for 7020 epochs, was 5764.6782257556915\n",
      "\n",
      "EPOCH 7022  (with max 8000), loss: 0.027583040297031403\n",
      "train time for 7022 epochs, was 5766.311568021774\n",
      "\n",
      "EPOCH 7024  (with max 8000), loss: 0.019122686237096786\n",
      "train time for 7024 epochs, was 5767.944757223129\n",
      "\n",
      "EPOCH 7026  (with max 8000), loss: 0.03963499143719673\n",
      "train time for 7026 epochs, was 5769.578040361404\n",
      "\n",
      "EPOCH 7028  (with max 8000), loss: 0.010248261503875256\n",
      "train time for 7028 epochs, was 5771.2114045619965\n",
      "\n",
      "EPOCH 7030  (with max 8000), loss: 0.010838538408279419\n",
      "train time for 7030 epochs, was 5772.844787597656\n",
      "\n",
      "EPOCH 7032  (with max 8000), loss: 0.01157267577946186\n",
      "train time for 7032 epochs, was 5774.478195428848\n",
      "\n",
      "EPOCH 7034  (with max 8000), loss: 0.009604237042367458\n",
      "train time for 7034 epochs, was 5776.113504648209\n",
      "\n",
      "EPOCH 7036  (with max 8000), loss: 0.0074337925761938095\n",
      "train time for 7036 epochs, was 5777.746819257736\n",
      "\n",
      "EPOCH 7038  (with max 8000), loss: 0.009933868423104286\n",
      "train time for 7038 epochs, was 5779.380157470703\n",
      "\n",
      "EPOCH 7040  (with max 8000), loss: 0.010504203848540783\n",
      "train time for 7040 epochs, was 5781.0156309604645\n",
      "\n",
      "EPOCH 7042  (with max 8000), loss: 0.008704718202352524\n",
      "train time for 7042 epochs, was 5782.651126384735\n",
      "\n",
      "EPOCH 7044  (with max 8000), loss: 0.01036892831325531\n",
      "train time for 7044 epochs, was 5784.284450292587\n",
      "\n",
      "EPOCH 7046  (with max 8000), loss: 0.012750688008964062\n",
      "train time for 7046 epochs, was 5785.919946908951\n",
      "\n",
      "EPOCH 7048  (with max 8000), loss: 0.011984052136540413\n",
      "train time for 7048 epochs, was 5787.5552434921265\n",
      "\n",
      "EPOCH 7050  (with max 8000), loss: 0.006144504062831402\n",
      "train time for 7050 epochs, was 5789.188450574875\n",
      "\n",
      "EPOCH 7052  (with max 8000), loss: 0.005235197953879833\n",
      "train time for 7052 epochs, was 5790.8216853141785\n",
      "\n",
      "EPOCH 7054  (with max 8000), loss: 0.005917382892221212\n",
      "train time for 7054 epochs, was 5792.454886436462\n",
      "\n",
      "EPOCH 7056  (with max 8000), loss: 0.00935372430831194\n",
      "train time for 7056 epochs, was 5794.088233709335\n",
      "\n",
      "EPOCH 7058  (with max 8000), loss: 0.01188892312347889\n",
      "train time for 7058 epochs, was 5795.748663425446\n",
      "\n",
      "EPOCH 7060  (with max 8000), loss: 0.0037394592072814703\n",
      "train time for 7060 epochs, was 5797.38631772995\n",
      "\n",
      "EPOCH 7062  (with max 8000), loss: 0.02585768513381481\n",
      "train time for 7062 epochs, was 5799.019751548767\n",
      "\n",
      "EPOCH 7064  (with max 8000), loss: 0.02145475521683693\n",
      "train time for 7064 epochs, was 5800.653244018555\n",
      "\n",
      "EPOCH 7066  (with max 8000), loss: 0.010982532054185867\n",
      "train time for 7066 epochs, was 5802.2864763736725\n",
      "\n",
      "EPOCH 7068  (with max 8000), loss: 0.008348783478140831\n",
      "train time for 7068 epochs, was 5803.919804811478\n",
      "\n",
      "EPOCH 7070  (with max 8000), loss: 0.008693491108715534\n",
      "train time for 7070 epochs, was 5805.5531277656555\n",
      "\n",
      "EPOCH 7072  (with max 8000), loss: 0.0065202657133340836\n",
      "train time for 7072 epochs, was 5807.186477184296\n",
      "\n",
      "EPOCH 7074  (with max 8000), loss: 0.006875987164676189\n",
      "train time for 7074 epochs, was 5808.8220274448395\n",
      "\n",
      "EPOCH 7076  (with max 8000), loss: 0.009585878811776638\n",
      "train time for 7076 epochs, was 5810.455617427826\n",
      "\n",
      "EPOCH 7078  (with max 8000), loss: 0.006109863519668579\n",
      "train time for 7078 epochs, was 5812.089037179947\n",
      "\n",
      "EPOCH 7080  (with max 8000), loss: 0.006704251281917095\n",
      "train time for 7080 epochs, was 5813.722254753113\n",
      "\n",
      "EPOCH 7082  (with max 8000), loss: 0.005539231467992067\n",
      "train time for 7082 epochs, was 5815.355686903\n",
      "\n",
      "EPOCH 7084  (with max 8000), loss: 0.0023857716005295515\n",
      "train time for 7084 epochs, was 5817.001483440399\n",
      "\n",
      "EPOCH 7086  (with max 8000), loss: 0.012997934594750404\n",
      "train time for 7086 epochs, was 5818.645267724991\n",
      "\n",
      "EPOCH 7088  (with max 8000), loss: 0.011897481046617031\n",
      "train time for 7088 epochs, was 5820.2785058021545\n",
      "\n",
      "EPOCH 7090  (with max 8000), loss: 0.017146410420536995\n",
      "train time for 7090 epochs, was 5821.913845062256\n",
      "\n",
      "EPOCH 7092  (with max 8000), loss: 0.1588176041841507\n",
      "train time for 7092 epochs, was 5823.547142505646\n",
      "\n",
      "EPOCH 7094  (with max 8000), loss: 0.03545578941702843\n",
      "train time for 7094 epochs, was 5825.180516719818\n",
      "\n",
      "EPOCH 7096  (with max 8000), loss: 0.010044514201581478\n",
      "train time for 7096 epochs, was 5826.815940856934\n",
      "\n",
      "EPOCH 7098  (with max 8000), loss: 0.010890747420489788\n",
      "train time for 7098 epochs, was 5828.449237585068\n",
      "\n",
      "EPOCH 7100  (with max 8000), loss: 0.008863548748195171\n",
      "train time for 7100 epochs, was 5830.0824682712555\n",
      "\n",
      "EPOCH 7102  (with max 8000), loss: 0.009778870269656181\n",
      "train time for 7102 epochs, was 5831.7385840415955\n",
      "\n",
      "EPOCH 7104  (with max 8000), loss: 0.007861660793423653\n",
      "train time for 7104 epochs, was 5833.375941038132\n",
      "\n",
      "EPOCH 7106  (with max 8000), loss: 0.01157049648463726\n",
      "train time for 7106 epochs, was 5835.019502878189\n",
      "\n",
      "EPOCH 7108  (with max 8000), loss: 0.00689785135909915\n",
      "train time for 7108 epochs, was 5836.6528236866\n",
      "\n",
      "EPOCH 7110  (with max 8000), loss: 0.00536801852285862\n",
      "train time for 7110 epochs, was 5838.285943031311\n",
      "\n",
      "EPOCH 7112  (with max 8000), loss: 0.020842047408223152\n",
      "train time for 7112 epochs, was 5839.919248819351\n",
      "\n",
      "EPOCH 7114  (with max 8000), loss: 0.00626314477995038\n",
      "train time for 7114 epochs, was 5841.552574396133\n",
      "\n",
      "EPOCH 7116  (with max 8000), loss: 0.008304535411298275\n",
      "train time for 7116 epochs, was 5843.186032772064\n",
      "\n",
      "EPOCH 7118  (with max 8000), loss: 0.0034687500447034836\n",
      "train time for 7118 epochs, was 5844.844493150711\n",
      "\n",
      "EPOCH 7120  (with max 8000), loss: 0.009601901285350323\n",
      "train time for 7120 epochs, was 5846.479828596115\n",
      "\n",
      "EPOCH 7122  (with max 8000), loss: 0.008490812964737415\n",
      "train time for 7122 epochs, was 5848.113212347031\n",
      "\n",
      "EPOCH 7124  (with max 8000), loss: 0.31632721424102783\n",
      "train time for 7124 epochs, was 5849.748674631119\n",
      "\n",
      "EPOCH 7126  (with max 8000), loss: 0.022255947813391685\n",
      "train time for 7126 epochs, was 5851.38197684288\n",
      "\n",
      "EPOCH 7128  (with max 8000), loss: 0.029001232236623764\n",
      "train time for 7128 epochs, was 5853.015215873718\n",
      "\n",
      "EPOCH 7130  (with max 8000), loss: 0.00966434832662344\n",
      "train time for 7130 epochs, was 5854.648481369019\n",
      "\n",
      "EPOCH 7132  (with max 8000), loss: 0.011465813033282757\n",
      "train time for 7132 epochs, was 5856.281714677811\n",
      "\n",
      "EPOCH 7134  (with max 8000), loss: 0.020616918802261353\n",
      "train time for 7134 epochs, was 5857.915316581726\n",
      "\n",
      "EPOCH 7136  (with max 8000), loss: 0.006932854186743498\n",
      "train time for 7136 epochs, was 5859.548649311066\n",
      "\n",
      "EPOCH 7138  (with max 8000), loss: 0.007290802896022797\n",
      "train time for 7138 epochs, was 5861.182042360306\n",
      "\n",
      "EPOCH 7140  (with max 8000), loss: 0.007572847884148359\n",
      "train time for 7140 epochs, was 5862.815303325653\n",
      "\n",
      "EPOCH 7142  (with max 8000), loss: 0.004247041419148445\n",
      "train time for 7142 epochs, was 5864.450814962387\n",
      "\n",
      "EPOCH 7144  (with max 8000), loss: 0.0022776660043746233\n",
      "train time for 7144 epochs, was 5866.092762470245\n",
      "\n",
      "EPOCH 7146  (with max 8000), loss: 0.022210532799363136\n",
      "train time for 7146 epochs, was 5867.7406001091\n",
      "\n",
      "EPOCH 7148  (with max 8000), loss: 0.008847021497786045\n",
      "train time for 7148 epochs, was 5869.374054670334\n",
      "\n",
      "EPOCH 7150  (with max 8000), loss: 0.006413700990378857\n",
      "train time for 7150 epochs, was 5871.009449720383\n",
      "\n",
      "EPOCH 7152  (with max 8000), loss: 0.006995367351919413\n",
      "train time for 7152 epochs, was 5872.645069599152\n",
      "\n",
      "EPOCH 7154  (with max 8000), loss: 0.003899156581610441\n",
      "train time for 7154 epochs, was 5874.278486967087\n",
      "\n",
      "EPOCH 7156  (with max 8000), loss: 0.003345046192407608\n",
      "train time for 7156 epochs, was 5875.911979913712\n",
      "\n",
      "EPOCH 7158  (with max 8000), loss: 0.0025944956578314304\n",
      "train time for 7158 epochs, was 5877.5474054813385\n",
      "\n",
      "EPOCH 7160  (with max 8000), loss: 0.0196370966732502\n",
      "train time for 7160 epochs, was 5879.185138702393\n",
      "\n",
      "EPOCH 7162  (with max 8000), loss: 0.015574376098811626\n",
      "train time for 7162 epochs, was 5880.820667505264\n",
      "\n",
      "EPOCH 7164  (with max 8000), loss: 0.008584055118262768\n",
      "train time for 7164 epochs, was 5882.4561886787415\n",
      "\n",
      "EPOCH 7166  (with max 8000), loss: 0.01422581821680069\n",
      "train time for 7166 epochs, was 5884.0916175842285\n",
      "\n",
      "EPOCH 7168  (with max 8000), loss: 0.05605641379952431\n",
      "train time for 7168 epochs, was 5885.7250101566315\n",
      "\n",
      "EPOCH 7170  (with max 8000), loss: 0.007818016223609447\n",
      "train time for 7170 epochs, was 5887.360591888428\n",
      "\n",
      "EPOCH 7172  (with max 8000), loss: 0.021351616829633713\n",
      "train time for 7172 epochs, was 5888.994169950485\n",
      "\n",
      "EPOCH 7174  (with max 8000), loss: 0.013424165546894073\n",
      "train time for 7174 epochs, was 5890.638246059418\n",
      "\n",
      "EPOCH 7176  (with max 8000), loss: 0.008149251341819763\n",
      "train time for 7176 epochs, was 5892.273849725723\n",
      "\n",
      "EPOCH 7178  (with max 8000), loss: 0.21818959712982178\n",
      "train time for 7178 epochs, was 5893.90722823143\n",
      "\n",
      "EPOCH 7180  (with max 8000), loss: 0.01809908077120781\n",
      "train time for 7180 epochs, was 5895.5405151844025\n",
      "\n",
      "EPOCH 7182  (with max 8000), loss: 0.011858376674354076\n",
      "train time for 7182 epochs, was 5897.180139541626\n",
      "\n",
      "EPOCH 7184  (with max 8000), loss: 0.005808364134281874\n",
      "train time for 7184 epochs, was 5898.813482761383\n",
      "\n",
      "EPOCH 7186  (with max 8000), loss: 0.01641884259879589\n",
      "train time for 7186 epochs, was 5900.455316543579\n",
      "\n",
      "EPOCH 7188  (with max 8000), loss: 0.034981608390808105\n",
      "train time for 7188 epochs, was 5902.088844537735\n",
      "\n",
      "EPOCH 7190  (with max 8000), loss: 0.011471293866634369\n",
      "train time for 7190 epochs, was 5903.747582197189\n",
      "\n",
      "EPOCH 7192  (with max 8000), loss: 0.005826225504279137\n",
      "train time for 7192 epochs, was 5905.381147623062\n",
      "\n",
      "EPOCH 7194  (with max 8000), loss: 0.011047055013477802\n",
      "train time for 7194 epochs, was 5907.014655590057\n",
      "\n",
      "EPOCH 7196  (with max 8000), loss: 0.00899682566523552\n",
      "train time for 7196 epochs, was 5908.648470401764\n",
      "\n",
      "EPOCH 7198  (with max 8000), loss: 0.005928040482103825\n",
      "train time for 7198 epochs, was 5910.282034158707\n",
      "\n",
      "EPOCH 7200  (with max 8000), loss: 0.0032366393133997917\n",
      "train time for 7200 epochs, was 5911.915616989136\n",
      "\n",
      "EPOCH 7200 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_7200.pth\n",
      "\n",
      "EPOCH 7202  (with max 8000), loss: 0.004822748713195324\n",
      "train time for 7202 epochs, was 5913.582811832428\n",
      "\n",
      "EPOCH 7204  (with max 8000), loss: 0.003432712983340025\n",
      "train time for 7204 epochs, was 5915.216652393341\n",
      "\n",
      "EPOCH 7206  (with max 8000), loss: 0.00796602014452219\n",
      "train time for 7206 epochs, was 5916.850219488144\n",
      "\n",
      "EPOCH 7208  (with max 8000), loss: 0.0017189821228384972\n",
      "train time for 7208 epochs, was 5918.490070104599\n",
      "\n",
      "EPOCH 7210  (with max 8000), loss: 0.012164250947535038\n",
      "train time for 7210 epochs, was 5920.125731229782\n",
      "\n",
      "EPOCH 7212  (with max 8000), loss: 0.010266642086207867\n",
      "train time for 7212 epochs, was 5921.763422966003\n",
      "\n",
      "EPOCH 7214  (with max 8000), loss: 0.025369690731167793\n",
      "train time for 7214 epochs, was 5923.397217512131\n",
      "\n",
      "EPOCH 7216  (with max 8000), loss: 0.011157921515405178\n",
      "train time for 7216 epochs, was 5925.035068273544\n",
      "\n",
      "EPOCH 7218  (with max 8000), loss: 0.0027920163702219725\n",
      "train time for 7218 epochs, was 5926.681341409683\n",
      "\n",
      "EPOCH 7220  (with max 8000), loss: 0.03239523619413376\n",
      "train time for 7220 epochs, was 5928.315041303635\n",
      "\n",
      "EPOCH 7222  (with max 8000), loss: 0.00476965494453907\n",
      "train time for 7222 epochs, was 5929.951095819473\n",
      "\n",
      "EPOCH 7224  (with max 8000), loss: 0.004958731587976217\n",
      "train time for 7224 epochs, was 5931.584861755371\n",
      "\n",
      "EPOCH 7226  (with max 8000), loss: 0.00644769798964262\n",
      "train time for 7226 epochs, was 5933.220538377762\n",
      "\n",
      "EPOCH 7228  (with max 8000), loss: 0.00649628508836031\n",
      "train time for 7228 epochs, was 5934.860456943512\n",
      "\n",
      "EPOCH 7230  (with max 8000), loss: 0.05257716774940491\n",
      "train time for 7230 epochs, was 5936.496329307556\n",
      "\n",
      "EPOCH 7232  (with max 8000), loss: 0.004124937579035759\n",
      "train time for 7232 epochs, was 5938.129956007004\n",
      "\n",
      "EPOCH 7234  (with max 8000), loss: 0.019523706287145615\n",
      "train time for 7234 epochs, was 5939.7638919353485\n",
      "\n",
      "EPOCH 7236  (with max 8000), loss: 0.009046733379364014\n",
      "train time for 7236 epochs, was 5941.422761440277\n",
      "\n",
      "EPOCH 7238  (with max 8000), loss: 0.005894865375012159\n",
      "train time for 7238 epochs, was 5943.058507680893\n",
      "\n",
      "EPOCH 7240  (with max 8000), loss: 0.004146082326769829\n",
      "train time for 7240 epochs, was 5944.692324638367\n",
      "\n",
      "EPOCH 7242  (with max 8000), loss: 0.038989607244729996\n",
      "train time for 7242 epochs, was 5946.32624912262\n",
      "\n",
      "EPOCH 7244  (with max 8000), loss: 0.004805942997336388\n",
      "train time for 7244 epochs, was 5947.962020158768\n",
      "\n",
      "EPOCH 7246  (with max 8000), loss: 0.007348716724663973\n",
      "train time for 7246 epochs, was 5949.595789194107\n",
      "\n",
      "EPOCH 7248  (with max 8000), loss: 0.007322149351239204\n",
      "train time for 7248 epochs, was 5951.229469537735\n",
      "\n",
      "EPOCH 7250  (with max 8000), loss: 0.009198937565088272\n",
      "train time for 7250 epochs, was 5952.86710357666\n",
      "\n",
      "EPOCH 7252  (with max 8000), loss: 0.006903609726577997\n",
      "train time for 7252 epochs, was 5954.50280380249\n",
      "\n",
      "EPOCH 7254  (with max 8000), loss: 0.003996283747255802\n",
      "train time for 7254 epochs, was 5956.138350486755\n",
      "\n",
      "EPOCH 7256  (with max 8000), loss: 0.008246205747127533\n",
      "train time for 7256 epochs, was 5957.771940946579\n",
      "\n",
      "EPOCH 7258  (with max 8000), loss: 0.008970128372311592\n",
      "train time for 7258 epochs, was 5959.407692193985\n",
      "\n",
      "EPOCH 7260  (with max 8000), loss: 0.005900692194700241\n",
      "train time for 7260 epochs, was 5961.041288614273\n",
      "\n",
      "EPOCH 7262  (with max 8000), loss: 0.007904011756181717\n",
      "train time for 7262 epochs, was 5962.674909114838\n",
      "\n",
      "EPOCH 7264  (with max 8000), loss: 0.006080958992242813\n",
      "train time for 7264 epochs, was 5964.308598518372\n",
      "\n",
      "EPOCH 7266  (with max 8000), loss: 0.004357144236564636\n",
      "train time for 7266 epochs, was 5965.942296743393\n",
      "\n",
      "EPOCH 7268  (with max 8000), loss: 0.003163152141496539\n",
      "train time for 7268 epochs, was 5967.575808763504\n",
      "\n",
      "EPOCH 7270  (with max 8000), loss: 0.009568163193762302\n",
      "train time for 7270 epochs, was 5969.209451913834\n",
      "\n",
      "EPOCH 7272  (with max 8000), loss: 0.0144606688991189\n",
      "train time for 7272 epochs, was 5970.8430507183075\n",
      "\n",
      "EPOCH 7274  (with max 8000), loss: 0.0208867397159338\n",
      "train time for 7274 epochs, was 5972.480850696564\n",
      "\n",
      "EPOCH 7276  (with max 8000), loss: 0.01245119422674179\n",
      "train time for 7276 epochs, was 5974.1142773628235\n",
      "\n",
      "EPOCH 7278  (with max 8000), loss: 0.01308237761259079\n",
      "train time for 7278 epochs, was 5975.747764110565\n",
      "\n",
      "EPOCH 7280  (with max 8000), loss: 0.011990271508693695\n",
      "train time for 7280 epochs, was 5977.387595653534\n",
      "\n",
      "EPOCH 7282  (with max 8000), loss: 0.004287028685212135\n",
      "train time for 7282 epochs, was 5979.048220396042\n",
      "\n",
      "EPOCH 7284  (with max 8000), loss: 0.011939301155507565\n",
      "train time for 7284 epochs, was 5980.681980371475\n",
      "\n",
      "EPOCH 7286  (with max 8000), loss: 0.006402275059372187\n",
      "train time for 7286 epochs, was 5982.315520524979\n",
      "\n",
      "EPOCH 7288  (with max 8000), loss: 0.007752867415547371\n",
      "train time for 7288 epochs, was 5983.949112176895\n",
      "\n",
      "EPOCH 7290  (with max 8000), loss: 0.006121257320046425\n",
      "train time for 7290 epochs, was 5985.587000131607\n",
      "\n",
      "EPOCH 7292  (with max 8000), loss: 0.005053515546023846\n",
      "train time for 7292 epochs, was 5987.222881555557\n",
      "\n",
      "EPOCH 7294  (with max 8000), loss: 0.09797992557287216\n",
      "train time for 7294 epochs, was 5988.856461524963\n",
      "\n",
      "EPOCH 7296  (with max 8000), loss: 0.11703652143478394\n",
      "train time for 7296 epochs, was 5990.500744342804\n",
      "\n",
      "EPOCH 7298  (with max 8000), loss: 0.027397876605391502\n",
      "train time for 7298 epochs, was 5992.136533498764\n",
      "\n",
      "EPOCH 7300  (with max 8000), loss: 0.021276284009218216\n",
      "train time for 7300 epochs, was 5993.778652429581\n",
      "\n",
      "EPOCH 7302  (with max 8000), loss: 0.008065588772296906\n",
      "train time for 7302 epochs, was 5995.414528846741\n",
      "\n",
      "EPOCH 7304  (with max 8000), loss: 0.013237960636615753\n",
      "train time for 7304 epochs, was 5997.054637432098\n",
      "\n",
      "EPOCH 7306  (with max 8000), loss: 0.006264477036893368\n",
      "train time for 7306 epochs, was 5998.690211057663\n",
      "\n",
      "EPOCH 7308  (with max 8000), loss: 0.0026271508540958166\n",
      "train time for 7308 epochs, was 6000.329840183258\n",
      "\n",
      "EPOCH 7310  (with max 8000), loss: 0.011764425784349442\n",
      "train time for 7310 epochs, was 6001.969615221024\n",
      "\n",
      "EPOCH 7312  (with max 8000), loss: 0.003154135774821043\n",
      "train time for 7312 epochs, was 6003.603126049042\n",
      "\n",
      "EPOCH 7314  (with max 8000), loss: 0.002675466937944293\n",
      "train time for 7314 epochs, was 6005.23673915863\n",
      "\n",
      "EPOCH 7316  (with max 8000), loss: 0.00678538903594017\n",
      "train time for 7316 epochs, was 6006.8703854084015\n",
      "\n",
      "EPOCH 7318  (with max 8000), loss: 0.0069243344478309155\n",
      "train time for 7318 epochs, was 6008.504036188126\n",
      "\n",
      "EPOCH 7320  (with max 8000), loss: 0.015321066603064537\n",
      "train time for 7320 epochs, was 6010.137455463409\n",
      "\n",
      "EPOCH 7322  (with max 8000), loss: 0.00516874436289072\n",
      "train time for 7322 epochs, was 6011.770937204361\n",
      "\n",
      "EPOCH 7324  (with max 8000), loss: 0.008788525126874447\n",
      "train time for 7324 epochs, was 6013.40665769577\n",
      "\n",
      "EPOCH 7326  (with max 8000), loss: 0.004605487454682589\n",
      "train time for 7326 epochs, was 6015.075824737549\n",
      "\n",
      "EPOCH 7328  (with max 8000), loss: 0.009036394767463207\n",
      "train time for 7328 epochs, was 6016.709738969803\n",
      "\n",
      "EPOCH 7330  (with max 8000), loss: 0.010528641752898693\n",
      "train time for 7330 epochs, was 6018.345454931259\n",
      "\n",
      "EPOCH 7332  (with max 8000), loss: 0.0026216628029942513\n",
      "train time for 7332 epochs, was 6019.981297492981\n",
      "\n",
      "EPOCH 7334  (with max 8000), loss: 0.04816088080406189\n",
      "train time for 7334 epochs, was 6021.621124744415\n",
      "\n",
      "EPOCH 7336  (with max 8000), loss: 0.023692654445767403\n",
      "train time for 7336 epochs, was 6023.261107206345\n",
      "\n",
      "EPOCH 7338  (with max 8000), loss: 0.00802768487483263\n",
      "train time for 7338 epochs, was 6024.896827697754\n",
      "\n",
      "EPOCH 7340  (with max 8000), loss: 0.010185671970248222\n",
      "train time for 7340 epochs, was 6026.530514717102\n",
      "\n",
      "EPOCH 7342  (with max 8000), loss: 0.010929388925433159\n",
      "train time for 7342 epochs, was 6028.164352178574\n",
      "\n",
      "EPOCH 7344  (with max 8000), loss: 0.004751927684992552\n",
      "train time for 7344 epochs, was 6029.800251483917\n",
      "\n",
      "EPOCH 7346  (with max 8000), loss: 0.005609838292002678\n",
      "train time for 7346 epochs, was 6031.43385386467\n",
      "\n",
      "EPOCH 7348  (with max 8000), loss: 0.004690147005021572\n",
      "train time for 7348 epochs, was 6033.069631814957\n",
      "\n",
      "EPOCH 7350  (with max 8000), loss: 0.0005890012253075838\n",
      "train time for 7350 epochs, was 6034.703280448914\n",
      "\n",
      "EPOCH 7352  (with max 8000), loss: 0.003082618582993746\n",
      "train time for 7352 epochs, was 6036.336755514145\n",
      "\n",
      "EPOCH 7354  (with max 8000), loss: 0.012164279818534851\n",
      "train time for 7354 epochs, was 6037.970327615738\n",
      "\n",
      "EPOCH 7356  (with max 8000), loss: 0.015627196058630943\n",
      "train time for 7356 epochs, was 6039.603897809982\n",
      "\n",
      "EPOCH 7358  (with max 8000), loss: 0.023732027038931847\n",
      "train time for 7358 epochs, was 6041.237415313721\n",
      "\n",
      "EPOCH 7360  (with max 8000), loss: 0.005803466308861971\n",
      "train time for 7360 epochs, was 6042.875175952911\n",
      "\n",
      "EPOCH 7362  (with max 8000), loss: 0.006678333971649408\n",
      "train time for 7362 epochs, was 6044.511072397232\n",
      "\n",
      "EPOCH 7364  (with max 8000), loss: 0.02007650025188923\n",
      "train time for 7364 epochs, was 6046.146837472916\n",
      "\n",
      "EPOCH 7366  (with max 8000), loss: 0.0045886230655014515\n",
      "train time for 7366 epochs, was 6047.782521486282\n",
      "\n",
      "EPOCH 7368  (with max 8000), loss: 0.005210006609559059\n",
      "train time for 7368 epochs, was 6049.41846871376\n",
      "\n",
      "EPOCH 7370  (with max 8000), loss: 0.00584094924852252\n",
      "train time for 7370 epochs, was 6051.070958852768\n",
      "\n",
      "EPOCH 7372  (with max 8000), loss: 0.009702743031084538\n",
      "train time for 7372 epochs, was 6052.706629514694\n",
      "\n",
      "EPOCH 7374  (with max 8000), loss: 0.010944019071757793\n",
      "train time for 7374 epochs, was 6054.340259313583\n",
      "\n",
      "EPOCH 7376  (with max 8000), loss: 0.007199516519904137\n",
      "train time for 7376 epochs, was 6055.973797559738\n",
      "\n",
      "EPOCH 7378  (with max 8000), loss: 0.034009892493486404\n",
      "train time for 7378 epochs, was 6057.609488487244\n",
      "\n",
      "EPOCH 7380  (with max 8000), loss: 0.014913205057382584\n",
      "train time for 7380 epochs, was 6059.2431898117065\n",
      "\n",
      "EPOCH 7382  (with max 8000), loss: 0.009653315879404545\n",
      "train time for 7382 epochs, was 6060.876845598221\n",
      "\n",
      "EPOCH 7384  (with max 8000), loss: 0.0020661710295826197\n",
      "train time for 7384 epochs, was 6062.510555505753\n",
      "\n",
      "EPOCH 7386  (with max 8000), loss: 0.0031136462930589914\n",
      "train time for 7386 epochs, was 6064.14408159256\n",
      "\n",
      "EPOCH 7388  (with max 8000), loss: 0.004216975066810846\n",
      "train time for 7388 epochs, was 6065.777696609497\n",
      "\n",
      "EPOCH 7390  (with max 8000), loss: 0.005778077989816666\n",
      "train time for 7390 epochs, was 6067.411259651184\n",
      "\n",
      "EPOCH 7392  (with max 8000), loss: 0.006122319493442774\n",
      "train time for 7392 epochs, was 6069.044830322266\n",
      "\n",
      "EPOCH 7394  (with max 8000), loss: 0.00912443920969963\n",
      "train time for 7394 epochs, was 6070.678368091583\n",
      "\n",
      "EPOCH 7396  (with max 8000), loss: 0.004465644713491201\n",
      "train time for 7396 epochs, was 6072.311968326569\n",
      "\n",
      "EPOCH 7398  (with max 8000), loss: 0.010405929759144783\n",
      "train time for 7398 epochs, was 6073.949858427048\n",
      "\n",
      "EPOCH 7400  (with max 8000), loss: 0.005375873297452927\n",
      "train time for 7400 epochs, was 6075.585649967194\n",
      "\n",
      "EPOCH 7400 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_7400.pth\n",
      "\n",
      "EPOCH 7402  (with max 8000), loss: 0.031702056527137756\n",
      "train time for 7402 epochs, was 6077.255024433136\n",
      "\n",
      "EPOCH 7404  (with max 8000), loss: 0.012135330587625504\n",
      "train time for 7404 epochs, was 6078.888781309128\n",
      "\n",
      "EPOCH 7406  (with max 8000), loss: 0.004250542726367712\n",
      "train time for 7406 epochs, was 6080.539249897003\n",
      "\n",
      "EPOCH 7408  (with max 8000), loss: 0.0051605477929115295\n",
      "train time for 7408 epochs, was 6082.1770079135895\n",
      "\n",
      "EPOCH 7410  (with max 8000), loss: 0.009623613208532333\n",
      "train time for 7410 epochs, was 6083.8106553554535\n",
      "\n",
      "EPOCH 7412  (with max 8000), loss: 0.0060792844742536545\n",
      "train time for 7412 epochs, was 6085.4462995529175\n",
      "\n",
      "EPOCH 7414  (with max 8000), loss: 0.006603180896490812\n",
      "train time for 7414 epochs, was 6087.096752882004\n",
      "\n",
      "EPOCH 7416  (with max 8000), loss: 0.0026531654875725508\n",
      "train time for 7416 epochs, was 6088.7366189956665\n",
      "\n",
      "EPOCH 7418  (with max 8000), loss: 0.006561407819390297\n",
      "train time for 7418 epochs, was 6090.372271537781\n",
      "\n",
      "EPOCH 7420  (with max 8000), loss: 0.007227345369756222\n",
      "train time for 7420 epochs, was 6092.005837440491\n",
      "\n",
      "EPOCH 7422  (with max 8000), loss: 0.028922729194164276\n",
      "train time for 7422 epochs, was 6093.639440536499\n",
      "\n",
      "EPOCH 7424  (with max 8000), loss: 0.004644051194190979\n",
      "train time for 7424 epochs, was 6095.273220777512\n",
      "\n",
      "EPOCH 7426  (with max 8000), loss: 0.007569595705717802\n",
      "train time for 7426 epochs, was 6096.906908035278\n",
      "\n",
      "EPOCH 7428  (with max 8000), loss: 0.03797066584229469\n",
      "train time for 7428 epochs, was 6098.540504932404\n",
      "\n",
      "EPOCH 7430  (with max 8000), loss: 0.008263921365141869\n",
      "train time for 7430 epochs, was 6100.174258470535\n",
      "\n",
      "EPOCH 7432  (with max 8000), loss: 0.13545583188533783\n",
      "train time for 7432 epochs, was 6101.808114767075\n",
      "\n",
      "EPOCH 7434  (with max 8000), loss: 0.040458936244249344\n",
      "train time for 7434 epochs, was 6103.441720247269\n",
      "\n",
      "EPOCH 7436  (with max 8000), loss: 0.012836846522986889\n",
      "train time for 7436 epochs, was 6105.077493906021\n",
      "\n",
      "EPOCH 7438  (with max 8000), loss: 0.009365016594529152\n",
      "train time for 7438 epochs, was 6106.711164236069\n",
      "\n",
      "EPOCH 7440  (with max 8000), loss: 0.004593327641487122\n",
      "train time for 7440 epochs, was 6108.3449692726135\n",
      "\n",
      "EPOCH 7442  (with max 8000), loss: 0.004750633612275124\n",
      "train time for 7442 epochs, was 6109.978808879852\n",
      "\n",
      "EPOCH 7444  (with max 8000), loss: 0.0019011287949979305\n",
      "train time for 7444 epochs, was 6111.612393140793\n",
      "\n",
      "EPOCH 7446  (with max 8000), loss: 0.004622402135282755\n",
      "train time for 7446 epochs, was 6113.2482380867\n",
      "\n",
      "EPOCH 7448  (with max 8000), loss: 0.007758589461445808\n",
      "train time for 7448 epochs, was 6114.881998062134\n",
      "\n",
      "EPOCH 7450  (with max 8000), loss: 0.0025893193669617176\n",
      "train time for 7450 epochs, was 6116.515899658203\n",
      "\n",
      "EPOCH 7452  (with max 8000), loss: 0.005712264683097601\n",
      "train time for 7452 epochs, was 6118.149460554123\n",
      "\n",
      "EPOCH 7454  (with max 8000), loss: 0.010440106503665447\n",
      "train time for 7454 epochs, was 6119.797756433487\n",
      "\n",
      "EPOCH 7456  (with max 8000), loss: 0.007044171914458275\n",
      "train time for 7456 epochs, was 6121.43151140213\n",
      "\n",
      "EPOCH 7458  (with max 8000), loss: 0.01732546277344227\n",
      "train time for 7458 epochs, was 6123.0695514678955\n",
      "\n",
      "EPOCH 7460  (with max 8000), loss: 0.006231909617781639\n",
      "train time for 7460 epochs, was 6124.703061103821\n",
      "\n",
      "EPOCH 7462  (with max 8000), loss: 0.008068179711699486\n",
      "train time for 7462 epochs, was 6126.338665008545\n",
      "\n",
      "EPOCH 7464  (with max 8000), loss: 0.011179625988006592\n",
      "train time for 7464 epochs, was 6127.984778165817\n",
      "\n",
      "EPOCH 7466  (with max 8000), loss: 0.007096866611391306\n",
      "train time for 7466 epochs, was 6129.620363950729\n",
      "\n",
      "EPOCH 7468  (with max 8000), loss: 0.0036524906754493713\n",
      "train time for 7468 epochs, was 6131.256096124649\n",
      "\n",
      "EPOCH 7470  (with max 8000), loss: 0.008730029687285423\n",
      "train time for 7470 epochs, was 6132.8898067474365\n",
      "\n",
      "EPOCH 7472  (with max 8000), loss: 0.01397212315350771\n",
      "train time for 7472 epochs, was 6134.523463010788\n",
      "\n",
      "EPOCH 7474  (with max 8000), loss: 0.003959566354751587\n",
      "train time for 7474 epochs, was 6136.157212257385\n",
      "\n",
      "EPOCH 7476  (with max 8000), loss: 0.003813069546595216\n",
      "train time for 7476 epochs, was 6137.790979146957\n",
      "\n",
      "EPOCH 7478  (with max 8000), loss: 0.006093684583902359\n",
      "train time for 7478 epochs, was 6139.4246509075165\n",
      "\n",
      "EPOCH 7480  (with max 8000), loss: 0.0076619298197329044\n",
      "train time for 7480 epochs, was 6141.0624878406525\n",
      "\n",
      "EPOCH 7482  (with max 8000), loss: 0.01857162080705166\n",
      "train time for 7482 epochs, was 6142.696024179459\n",
      "\n",
      "EPOCH 7484  (with max 8000), loss: 0.005507919006049633\n",
      "train time for 7484 epochs, was 6144.331929683685\n",
      "\n",
      "EPOCH 7486  (with max 8000), loss: 0.005492308177053928\n",
      "train time for 7486 epochs, was 6145.965608119965\n",
      "\n",
      "EPOCH 7488  (with max 8000), loss: 0.023052990436553955\n",
      "train time for 7488 epochs, was 6147.5993049144745\n",
      "\n",
      "EPOCH 7490  (with max 8000), loss: 0.009522030130028725\n",
      "train time for 7490 epochs, was 6149.232992887497\n",
      "\n",
      "EPOCH 7492  (with max 8000), loss: 0.009953333996236324\n",
      "train time for 7492 epochs, was 6150.86878156662\n",
      "\n",
      "EPOCH 7494  (with max 8000), loss: 0.013498032465577126\n",
      "train time for 7494 epochs, was 6152.504623889923\n",
      "\n",
      "EPOCH 7496  (with max 8000), loss: 0.008404474705457687\n",
      "train time for 7496 epochs, was 6154.1382558345795\n",
      "\n",
      "EPOCH 7498  (with max 8000), loss: 0.011894353665411472\n",
      "train time for 7498 epochs, was 6155.772042751312\n",
      "\n",
      "EPOCH 7500  (with max 8000), loss: 0.04608689248561859\n",
      "train time for 7500 epochs, was 6157.407918214798\n",
      "\n",
      "EPOCH 7502  (with max 8000), loss: 0.012820086441934109\n",
      "train time for 7502 epochs, was 6159.075100898743\n",
      "\n",
      "EPOCH 7504  (with max 8000), loss: 0.008166697807610035\n",
      "train time for 7504 epochs, was 6160.708839893341\n",
      "\n",
      "EPOCH 7506  (with max 8000), loss: 0.00901272427290678\n",
      "train time for 7506 epochs, was 6162.3425760269165\n",
      "\n",
      "EPOCH 7508  (with max 8000), loss: 0.0074785733595490456\n",
      "train time for 7508 epochs, was 6163.978312015533\n",
      "\n",
      "EPOCH 7510  (with max 8000), loss: 0.009713445790112019\n",
      "train time for 7510 epochs, was 6165.611960172653\n",
      "\n",
      "EPOCH 7512  (with max 8000), loss: 0.007709789089858532\n",
      "train time for 7512 epochs, was 6167.245715856552\n",
      "\n",
      "EPOCH 7514  (with max 8000), loss: 0.0067770760506391525\n",
      "train time for 7514 epochs, was 6168.879323720932\n",
      "\n",
      "EPOCH 7516  (with max 8000), loss: 0.014646735973656178\n",
      "train time for 7516 epochs, was 6170.513119220734\n",
      "\n",
      "EPOCH 7518  (with max 8000), loss: 0.010801311582326889\n",
      "train time for 7518 epochs, was 6172.148860692978\n",
      "\n",
      "EPOCH 7520  (with max 8000), loss: 0.007088389713317156\n",
      "train time for 7520 epochs, was 6173.782615661621\n",
      "\n",
      "EPOCH 7522  (with max 8000), loss: 0.005830669775605202\n",
      "train time for 7522 epochs, was 6175.416446447372\n",
      "\n",
      "EPOCH 7524  (with max 8000), loss: 0.005915680434554815\n",
      "train time for 7524 epochs, was 6177.050217866898\n",
      "\n",
      "EPOCH 7526  (with max 8000), loss: 0.013405445031821728\n",
      "train time for 7526 epochs, was 6178.68603014946\n",
      "\n",
      "EPOCH 7528  (with max 8000), loss: 0.0077573275193572044\n",
      "train time for 7528 epochs, was 6180.326264858246\n",
      "\n",
      "EPOCH 7530  (with max 8000), loss: 0.007468067575246096\n",
      "train time for 7530 epochs, was 6181.962030887604\n",
      "\n",
      "EPOCH 7532  (with max 8000), loss: 0.05982019752264023\n",
      "train time for 7532 epochs, was 6183.595668792725\n",
      "\n",
      "EPOCH 7534  (with max 8000), loss: 0.003629873041063547\n",
      "train time for 7534 epochs, was 6185.22936296463\n",
      "\n",
      "EPOCH 7536  (with max 8000), loss: 0.005498856771737337\n",
      "train time for 7536 epochs, was 6186.863201618195\n",
      "\n",
      "EPOCH 7538  (with max 8000), loss: 0.009973203763365746\n",
      "train time for 7538 epochs, was 6188.4970490932465\n",
      "\n",
      "EPOCH 7540  (with max 8000), loss: 0.006456124596297741\n",
      "train time for 7540 epochs, was 6190.130997180939\n",
      "\n",
      "EPOCH 7542  (with max 8000), loss: 0.006507522892206907\n",
      "train time for 7542 epochs, was 6191.764644861221\n",
      "\n",
      "EPOCH 7544  (with max 8000), loss: 0.012186183594167233\n",
      "train time for 7544 epochs, was 6193.398528575897\n",
      "\n",
      "EPOCH 7546  (with max 8000), loss: 0.04038577899336815\n",
      "train time for 7546 epochs, was 6195.055493354797\n",
      "\n",
      "EPOCH 7548  (with max 8000), loss: 0.18129070103168488\n",
      "train time for 7548 epochs, was 6196.71012711525\n",
      "\n",
      "EPOCH 7550  (with max 8000), loss: 0.0304509736597538\n",
      "train time for 7550 epochs, was 6198.346073627472\n",
      "\n",
      "EPOCH 7552  (with max 8000), loss: 0.01701885089278221\n",
      "train time for 7552 epochs, was 6199.981864452362\n",
      "\n",
      "EPOCH 7554  (with max 8000), loss: 0.02003585174679756\n",
      "train time for 7554 epochs, was 6201.61771941185\n",
      "\n",
      "EPOCH 7556  (with max 8000), loss: 0.006857133004814386\n",
      "train time for 7556 epochs, was 6203.251205205917\n",
      "\n",
      "EPOCH 7558  (with max 8000), loss: 0.011221984401345253\n",
      "train time for 7558 epochs, was 6204.884823322296\n",
      "\n",
      "EPOCH 7560  (with max 8000), loss: 0.00679733045399189\n",
      "train time for 7560 epochs, was 6206.520541906357\n",
      "\n",
      "EPOCH 7562  (with max 8000), loss: 0.007060187868773937\n",
      "train time for 7562 epochs, was 6208.154245376587\n",
      "\n",
      "EPOCH 7564  (with max 8000), loss: 0.009785708971321583\n",
      "train time for 7564 epochs, was 6209.787942647934\n",
      "\n",
      "EPOCH 7566  (with max 8000), loss: 0.007038462907075882\n",
      "train time for 7566 epochs, was 6211.421460866928\n",
      "\n",
      "EPOCH 7568  (with max 8000), loss: 0.006681577768176794\n",
      "train time for 7568 epochs, was 6213.054998159409\n",
      "\n",
      "EPOCH 7570  (with max 8000), loss: 0.010818954557180405\n",
      "train time for 7570 epochs, was 6214.69265127182\n",
      "\n",
      "EPOCH 7572  (with max 8000), loss: 0.001535270013846457\n",
      "train time for 7572 epochs, was 6216.328280448914\n",
      "\n",
      "EPOCH 7574  (with max 8000), loss: 0.0018896001856774092\n",
      "train time for 7574 epochs, was 6217.961829423904\n",
      "\n",
      "EPOCH 7576  (with max 8000), loss: 0.01249611284583807\n",
      "train time for 7576 epochs, was 6219.595474720001\n",
      "\n",
      "EPOCH 7578  (with max 8000), loss: 0.001796037657186389\n",
      "train time for 7578 epochs, was 6221.22895359993\n",
      "\n",
      "EPOCH 7580  (with max 8000), loss: 0.003769122762605548\n",
      "train time for 7580 epochs, was 6222.862548589706\n",
      "\n",
      "EPOCH 7582  (with max 8000), loss: 0.008318006992340088\n",
      "train time for 7582 epochs, was 6224.496142625809\n",
      "\n",
      "EPOCH 7584  (with max 8000), loss: 0.011429134756326675\n",
      "train time for 7584 epochs, was 6226.131915330887\n",
      "\n",
      "EPOCH 7586  (with max 8000), loss: 0.005134591367095709\n",
      "train time for 7586 epochs, was 6227.767496347427\n",
      "\n",
      "EPOCH 7588  (with max 8000), loss: 0.010214938782155514\n",
      "train time for 7588 epochs, was 6229.401245594025\n",
      "\n",
      "EPOCH 7590  (with max 8000), loss: 0.006556135602295399\n",
      "train time for 7590 epochs, was 6231.060009241104\n",
      "\n",
      "EPOCH 7592  (with max 8000), loss: 0.005389333236962557\n",
      "train time for 7592 epochs, was 6232.695703268051\n",
      "\n",
      "EPOCH 7594  (with max 8000), loss: 0.006122435908764601\n",
      "train time for 7594 epochs, was 6234.3292355537415\n",
      "\n",
      "EPOCH 7596  (with max 8000), loss: 0.013947137631475925\n",
      "train time for 7596 epochs, was 6235.964952707291\n",
      "\n",
      "EPOCH 7598  (with max 8000), loss: 0.005030563101172447\n",
      "train time for 7598 epochs, was 6237.607044935226\n",
      "\n",
      "EPOCH 7600  (with max 8000), loss: 0.006234462838619947\n",
      "train time for 7600 epochs, was 6239.24490904808\n",
      "\n",
      "EPOCH 7600 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_7600.pth\n",
      "\n",
      "EPOCH 7602  (with max 8000), loss: 0.003740485291928053\n",
      "train time for 7602 epochs, was 6240.9161767959595\n",
      "\n",
      "EPOCH 7604  (with max 8000), loss: 0.008335431106388569\n",
      "train time for 7604 epochs, was 6242.549760580063\n",
      "\n",
      "EPOCH 7606  (with max 8000), loss: 0.00449273781850934\n",
      "train time for 7606 epochs, was 6244.183312892914\n",
      "\n",
      "EPOCH 7608  (with max 8000), loss: 0.012619247660040855\n",
      "train time for 7608 epochs, was 6245.816987514496\n",
      "\n",
      "EPOCH 7610  (with max 8000), loss: 0.004809902049601078\n",
      "train time for 7610 epochs, was 6247.450623750687\n",
      "\n",
      "EPOCH 7612  (with max 8000), loss: 0.014908908866345882\n",
      "train time for 7612 epochs, was 6249.084169626236\n",
      "\n",
      "EPOCH 7614  (with max 8000), loss: 0.00786371435970068\n",
      "train time for 7614 epochs, was 6250.717925786972\n",
      "\n",
      "EPOCH 7616  (with max 8000), loss: 0.2245761603116989\n",
      "train time for 7616 epochs, was 6252.351801633835\n",
      "\n",
      "EPOCH 7618  (with max 8000), loss: 0.02049616165459156\n",
      "train time for 7618 epochs, was 6253.985524892807\n",
      "\n",
      "EPOCH 7620  (with max 8000), loss: 0.012415803037583828\n",
      "train time for 7620 epochs, was 6255.619210720062\n",
      "\n",
      "EPOCH 7622  (with max 8000), loss: 0.013299129903316498\n",
      "train time for 7622 epochs, was 6257.25288271904\n",
      "\n",
      "EPOCH 7624  (with max 8000), loss: 0.02095799148082733\n",
      "train time for 7624 epochs, was 6258.886607408524\n",
      "\n",
      "EPOCH 7626  (with max 8000), loss: 0.007626156322658062\n",
      "train time for 7626 epochs, was 6260.52016210556\n",
      "\n",
      "EPOCH 7628  (with max 8000), loss: 0.011465553194284439\n",
      "train time for 7628 epochs, was 6262.153707265854\n",
      "\n",
      "EPOCH 7630  (with max 8000), loss: 0.010092582553625107\n",
      "train time for 7630 epochs, was 6263.787336349487\n",
      "\n",
      "EPOCH 7632  (with max 8000), loss: 0.005376127082854509\n",
      "train time for 7632 epochs, was 6265.425176382065\n",
      "\n",
      "EPOCH 7634  (with max 8000), loss: 0.014231240376830101\n",
      "train time for 7634 epochs, was 6267.05908370018\n",
      "\n",
      "EPOCH 7636  (with max 8000), loss: 0.006258729845285416\n",
      "train time for 7636 epochs, was 6268.692732334137\n",
      "\n",
      "EPOCH 7638  (with max 8000), loss: 0.0030919653363525867\n",
      "train time for 7638 epochs, was 6270.326428890228\n",
      "\n",
      "EPOCH 7640  (with max 8000), loss: 0.005481960251927376\n",
      "train time for 7640 epochs, was 6271.960139513016\n",
      "\n",
      "EPOCH 7642  (with max 8000), loss: 0.003375908127054572\n",
      "train time for 7642 epochs, was 6273.612813234329\n",
      "\n",
      "EPOCH 7644  (with max 8000), loss: 0.0036792366299778223\n",
      "train time for 7644 epochs, was 6275.2465562820435\n",
      "\n",
      "EPOCH 7646  (with max 8000), loss: 0.007635777350515127\n",
      "train time for 7646 epochs, was 6276.880327939987\n",
      "\n",
      "EPOCH 7648  (with max 8000), loss: 0.004280596040189266\n",
      "train time for 7648 epochs, was 6278.513997077942\n",
      "\n",
      "EPOCH 7650  (with max 8000), loss: 0.0018518625292927027\n",
      "train time for 7650 epochs, was 6280.147582292557\n",
      "\n",
      "EPOCH 7652  (with max 8000), loss: 0.005413956940174103\n",
      "train time for 7652 epochs, was 6281.781351327896\n",
      "\n",
      "EPOCH 7654  (with max 8000), loss: 0.009932366199791431\n",
      "train time for 7654 epochs, was 6283.4149668216705\n",
      "\n",
      "EPOCH 7656  (with max 8000), loss: 0.00256323697976768\n",
      "train time for 7656 epochs, was 6285.048584938049\n",
      "\n",
      "EPOCH 7658  (with max 8000), loss: 0.00644243648275733\n",
      "train time for 7658 epochs, was 6286.684396028519\n",
      "\n",
      "EPOCH 7660  (with max 8000), loss: 0.011756345629692078\n",
      "train time for 7660 epochs, was 6288.318154335022\n",
      "\n",
      "EPOCH 7662  (with max 8000), loss: 0.006172198336571455\n",
      "train time for 7662 epochs, was 6289.951784610748\n",
      "\n",
      "EPOCH 7664  (with max 8000), loss: 0.016699984669685364\n",
      "train time for 7664 epochs, was 6291.585235834122\n",
      "\n",
      "EPOCH 7666  (with max 8000), loss: 0.006859156768769026\n",
      "train time for 7666 epochs, was 6293.218706130981\n",
      "\n",
      "EPOCH 7668  (with max 8000), loss: 0.06914568692445755\n",
      "train time for 7668 epochs, was 6294.854503393173\n",
      "\n",
      "EPOCH 7670  (with max 8000), loss: 0.022185716778039932\n",
      "train time for 7670 epochs, was 6296.488102674484\n",
      "\n",
      "EPOCH 7672  (with max 8000), loss: 0.008920365944504738\n",
      "train time for 7672 epochs, was 6298.121621370316\n",
      "\n",
      "EPOCH 7674  (with max 8000), loss: 0.014261635951697826\n",
      "train time for 7674 epochs, was 6299.755148887634\n",
      "\n",
      "EPOCH 7676  (with max 8000), loss: 0.008937363512814045\n",
      "train time for 7676 epochs, was 6301.415812969208\n",
      "\n",
      "EPOCH 7678  (with max 8000), loss: 0.006370110437273979\n",
      "train time for 7678 epochs, was 6303.04971408844\n",
      "\n",
      "EPOCH 7680  (with max 8000), loss: 0.0046029905788600445\n",
      "train time for 7680 epochs, was 6304.685554981232\n",
      "\n",
      "EPOCH 7682  (with max 8000), loss: 0.008029709570109844\n",
      "train time for 7682 epochs, was 6306.319204568863\n",
      "\n",
      "EPOCH 7684  (with max 8000), loss: 0.009996472857892513\n",
      "train time for 7684 epochs, was 6307.952818393707\n",
      "\n",
      "EPOCH 7686  (with max 8000), loss: 0.005383811891078949\n",
      "train time for 7686 epochs, was 6309.5885553359985\n",
      "\n",
      "EPOCH 7688  (with max 8000), loss: 0.006400938145816326\n",
      "train time for 7688 epochs, was 6311.222208499908\n",
      "\n",
      "EPOCH 7690  (with max 8000), loss: 0.01203925907611847\n",
      "train time for 7690 epochs, was 6312.855762243271\n",
      "\n",
      "EPOCH 7692  (with max 8000), loss: 0.005797513760626316\n",
      "train time for 7692 epochs, was 6314.489322900772\n",
      "\n",
      "EPOCH 7694  (with max 8000), loss: 0.007197870407253504\n",
      "train time for 7694 epochs, was 6316.135418891907\n",
      "\n",
      "EPOCH 7696  (with max 8000), loss: 0.007950729690492153\n",
      "train time for 7696 epochs, was 6317.775511026382\n",
      "\n",
      "EPOCH 7698  (with max 8000), loss: 0.010933201760053635\n",
      "train time for 7698 epochs, was 6319.40899682045\n",
      "\n",
      "EPOCH 7700  (with max 8000), loss: 0.004836356267333031\n",
      "train time for 7700 epochs, was 6321.042494773865\n",
      "\n",
      "EPOCH 7702  (with max 8000), loss: 0.0031270605977624655\n",
      "train time for 7702 epochs, was 6322.676114082336\n",
      "\n",
      "EPOCH 7704  (with max 8000), loss: 0.007778022438287735\n",
      "train time for 7704 epochs, was 6324.309908866882\n",
      "\n",
      "EPOCH 7706  (with max 8000), loss: 0.006310282740741968\n",
      "train time for 7706 epochs, was 6325.943560123444\n",
      "\n",
      "EPOCH 7708  (with max 8000), loss: 0.009474098682403564\n",
      "train time for 7708 epochs, was 6327.577046871185\n",
      "\n",
      "EPOCH 7710  (with max 8000), loss: 0.012122434563934803\n",
      "train time for 7710 epochs, was 6329.210569858551\n",
      "\n",
      "EPOCH 7712  (with max 8000), loss: 0.006811775267124176\n",
      "train time for 7712 epochs, was 6330.8442578315735\n",
      "\n",
      "EPOCH 7714  (with max 8000), loss: 0.011925388127565384\n",
      "train time for 7714 epochs, was 6332.4779505729675\n",
      "\n",
      "EPOCH 7716  (with max 8000), loss: 0.02655278891324997\n",
      "train time for 7716 epochs, was 6334.111424922943\n",
      "\n",
      "EPOCH 7718  (with max 8000), loss: 0.00901410635560751\n",
      "train time for 7718 epochs, was 6335.747184753418\n",
      "\n",
      "EPOCH 7720  (with max 8000), loss: 0.005344816017895937\n",
      "train time for 7720 epochs, was 6337.407975912094\n",
      "\n",
      "EPOCH 7722  (with max 8000), loss: 0.015581429935991764\n",
      "train time for 7722 epochs, was 6339.041631698608\n",
      "\n",
      "EPOCH 7724  (with max 8000), loss: 0.005766586400568485\n",
      "train time for 7724 epochs, was 6340.675172328949\n",
      "\n",
      "EPOCH 7726  (with max 8000), loss: 0.007487663067877293\n",
      "train time for 7726 epochs, was 6342.308789491653\n",
      "\n",
      "EPOCH 7728  (with max 8000), loss: 0.005711927078664303\n",
      "train time for 7728 epochs, was 6343.942450284958\n",
      "\n",
      "EPOCH 7730  (with max 8000), loss: 0.007424416486173868\n",
      "train time for 7730 epochs, was 6345.576251268387\n",
      "\n",
      "EPOCH 7732  (with max 8000), loss: 0.0108652887865901\n",
      "train time for 7732 epochs, was 6347.211891889572\n",
      "\n",
      "EPOCH 7734  (with max 8000), loss: 0.004175178240984678\n",
      "train time for 7734 epochs, was 6348.847703456879\n",
      "\n",
      "EPOCH 7736  (with max 8000), loss: 0.0008821103256195784\n",
      "train time for 7736 epochs, was 6350.48162651062\n",
      "\n",
      "EPOCH 7738  (with max 8000), loss: 0.008120526559650898\n",
      "train time for 7738 epochs, was 6352.117430925369\n",
      "\n",
      "EPOCH 7740  (with max 8000), loss: 0.006157275754958391\n",
      "train time for 7740 epochs, was 6353.753048658371\n",
      "\n",
      "EPOCH 7742  (with max 8000), loss: 0.005647594574838877\n",
      "train time for 7742 epochs, was 6355.388827800751\n",
      "\n",
      "EPOCH 7744  (with max 8000), loss: 0.017759935930371284\n",
      "train time for 7744 epochs, was 6357.0224714279175\n",
      "\n",
      "EPOCH 7746  (with max 8000), loss: 0.005328195635229349\n",
      "train time for 7746 epochs, was 6358.656042814255\n",
      "\n",
      "EPOCH 7748  (with max 8000), loss: 0.01321772113442421\n",
      "train time for 7748 epochs, was 6360.291973590851\n",
      "\n",
      "EPOCH 7750  (with max 8000), loss: 0.018062662333250046\n",
      "train time for 7750 epochs, was 6361.927792787552\n",
      "\n",
      "EPOCH 7752  (with max 8000), loss: 0.008042728528380394\n",
      "train time for 7752 epochs, was 6363.561478614807\n",
      "\n",
      "EPOCH 7754  (with max 8000), loss: 0.012697461992502213\n",
      "train time for 7754 epochs, was 6365.195088386536\n",
      "\n",
      "EPOCH 7756  (with max 8000), loss: 0.01612670347094536\n",
      "train time for 7756 epochs, was 6366.82892370224\n",
      "\n",
      "EPOCH 7758  (with max 8000), loss: 0.005573756527155638\n",
      "train time for 7758 epochs, was 6368.464569807053\n",
      "\n",
      "EPOCH 7760  (with max 8000), loss: 0.00598370423540473\n",
      "train time for 7760 epochs, was 6370.098051548004\n",
      "\n",
      "EPOCH 7762  (with max 8000), loss: 0.003760269610211253\n",
      "train time for 7762 epochs, was 6371.731376171112\n",
      "\n",
      "EPOCH 7764  (with max 8000), loss: 0.007554987911134958\n",
      "train time for 7764 epochs, was 6373.37740945816\n",
      "\n",
      "EPOCH 7766  (with max 8000), loss: 0.0023407135158777237\n",
      "train time for 7766 epochs, was 6375.0111038684845\n",
      "\n",
      "EPOCH 7768  (with max 8000), loss: 0.0035151629708707333\n",
      "train time for 7768 epochs, was 6376.644647121429\n",
      "\n",
      "EPOCH 7770  (with max 8000), loss: 0.0035370325203984976\n",
      "train time for 7770 epochs, was 6378.27810716629\n",
      "\n",
      "EPOCH 7772  (with max 8000), loss: 0.004869591444730759\n",
      "train time for 7772 epochs, was 6379.911620140076\n",
      "\n",
      "EPOCH 7774  (with max 8000), loss: 0.0046010748483240604\n",
      "train time for 7774 epochs, was 6381.5452563762665\n",
      "\n",
      "EPOCH 7776  (with max 8000), loss: 0.004605423659086227\n",
      "train time for 7776 epochs, was 6383.178853273392\n",
      "\n",
      "EPOCH 7778  (with max 8000), loss: 0.009613669477403164\n",
      "train time for 7778 epochs, was 6384.814648628235\n",
      "\n",
      "EPOCH 7780  (with max 8000), loss: 0.008976626209914684\n",
      "train time for 7780 epochs, was 6386.452362060547\n",
      "\n",
      "EPOCH 7782  (with max 8000), loss: 0.009075013920664787\n",
      "train time for 7782 epochs, was 6388.085965633392\n",
      "\n",
      "EPOCH 7784  (with max 8000), loss: 0.002243530470877886\n",
      "train time for 7784 epochs, was 6389.721579313278\n",
      "\n",
      "EPOCH 7786  (with max 8000), loss: 0.006846072617918253\n",
      "train time for 7786 epochs, was 6391.361555099487\n",
      "\n",
      "EPOCH 7788  (with max 8000), loss: 0.012238158844411373\n",
      "train time for 7788 epochs, was 6392.995134115219\n",
      "\n",
      "EPOCH 7790  (with max 8000), loss: 0.01121087372303009\n",
      "train time for 7790 epochs, was 6394.630735874176\n",
      "\n",
      "EPOCH 7792  (with max 8000), loss: 0.003580565331503749\n",
      "train time for 7792 epochs, was 6396.268618106842\n",
      "\n",
      "EPOCH 7794  (with max 8000), loss: 0.007767441216856241\n",
      "train time for 7794 epochs, was 6397.904475927353\n",
      "\n",
      "EPOCH 7796  (with max 8000), loss: 0.011611588299274445\n",
      "train time for 7796 epochs, was 6399.538297891617\n",
      "\n",
      "EPOCH 7798  (with max 8000), loss: 0.009713918901979923\n",
      "train time for 7798 epochs, was 6401.171914815903\n",
      "\n",
      "EPOCH 7800  (with max 8000), loss: 0.017807694151997566\n",
      "train time for 7800 epochs, was 6402.805631875992\n",
      "\n",
      "EPOCH 7800 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_7800.pth\n",
      "\n",
      "EPOCH 7802  (with max 8000), loss: 0.031069429591298103\n",
      "train time for 7802 epochs, was 6404.472822189331\n",
      "\n",
      "EPOCH 7804  (with max 8000), loss: 0.010295834392309189\n",
      "train time for 7804 epochs, was 6406.106356620789\n",
      "\n",
      "EPOCH 7806  (with max 8000), loss: 0.008644454181194305\n",
      "train time for 7806 epochs, was 6407.742121696472\n",
      "\n",
      "EPOCH 7808  (with max 8000), loss: 0.011508186347782612\n",
      "train time for 7808 epochs, was 6409.377920866013\n",
      "\n",
      "EPOCH 7810  (with max 8000), loss: 0.00827748142182827\n",
      "train time for 7810 epochs, was 6411.011775016785\n",
      "\n",
      "EPOCH 7812  (with max 8000), loss: 0.006207671947777271\n",
      "train time for 7812 epochs, was 6412.645374536514\n",
      "\n",
      "EPOCH 7814  (with max 8000), loss: 0.031114138662815094\n",
      "train time for 7814 epochs, was 6414.279064655304\n",
      "\n",
      "EPOCH 7816  (with max 8000), loss: 0.01398085430264473\n",
      "train time for 7816 epochs, was 6415.912749052048\n",
      "\n",
      "EPOCH 7818  (with max 8000), loss: 0.015816636383533478\n",
      "train time for 7818 epochs, was 6417.546505212784\n",
      "\n",
      "EPOCH 7820  (with max 8000), loss: 0.017578918486833572\n",
      "train time for 7820 epochs, was 6419.180061578751\n",
      "\n",
      "EPOCH 7822  (with max 8000), loss: 0.009287131950259209\n",
      "train time for 7822 epochs, was 6420.813739061356\n",
      "\n",
      "EPOCH 7824  (with max 8000), loss: 0.001983478432521224\n",
      "train time for 7824 epochs, was 6422.447468519211\n",
      "\n",
      "EPOCH 7826  (with max 8000), loss: 0.006320412270724773\n",
      "train time for 7826 epochs, was 6424.081344127655\n",
      "\n",
      "EPOCH 7828  (with max 8000), loss: 0.002084322040900588\n",
      "train time for 7828 epochs, was 6425.7150621414185\n",
      "\n",
      "EPOCH 7830  (with max 8000), loss: 0.006540088448673487\n",
      "train time for 7830 epochs, was 6427.3488800525665\n",
      "\n",
      "EPOCH 7832  (with max 8000), loss: 0.007573283743113279\n",
      "train time for 7832 epochs, was 6428.98456287384\n",
      "\n",
      "EPOCH 7834  (with max 8000), loss: 0.004537051543593407\n",
      "train time for 7834 epochs, was 6430.618095397949\n",
      "\n",
      "EPOCH 7836  (with max 8000), loss: 0.003220614744350314\n",
      "train time for 7836 epochs, was 6432.251822710037\n",
      "\n",
      "EPOCH 7838  (with max 8000), loss: 0.00787343829870224\n",
      "train time for 7838 epochs, was 6433.885440587997\n",
      "\n",
      "EPOCH 7840  (with max 8000), loss: 0.02730901911854744\n",
      "train time for 7840 epochs, was 6435.527626991272\n",
      "\n",
      "EPOCH 7842  (with max 8000), loss: 0.0038590501062572002\n",
      "train time for 7842 epochs, was 6437.161319494247\n",
      "\n",
      "EPOCH 7844  (with max 8000), loss: 0.0016626717988401651\n",
      "train time for 7844 epochs, was 6438.795084476471\n",
      "\n",
      "EPOCH 7846  (with max 8000), loss: 0.004523562733083963\n",
      "train time for 7846 epochs, was 6440.428890705109\n",
      "\n",
      "EPOCH 7848  (with max 8000), loss: 0.004579886328428984\n",
      "train time for 7848 epochs, was 6442.066663742065\n",
      "\n",
      "EPOCH 7850  (with max 8000), loss: 0.0022997516207396984\n",
      "train time for 7850 epochs, was 6443.700226783752\n",
      "\n",
      "EPOCH 7852  (with max 8000), loss: 0.012117372825741768\n",
      "train time for 7852 epochs, was 6445.35902261734\n",
      "\n",
      "EPOCH 7854  (with max 8000), loss: 0.006364063825458288\n",
      "train time for 7854 epochs, was 6446.9950041770935\n",
      "\n",
      "EPOCH 7856  (with max 8000), loss: 0.013486736454069614\n",
      "train time for 7856 epochs, was 6448.6328711509705\n",
      "\n",
      "EPOCH 7858  (with max 8000), loss: 0.012287133373320103\n",
      "train time for 7858 epochs, was 6450.270718336105\n",
      "\n",
      "EPOCH 7860  (with max 8000), loss: 0.011975579895079136\n",
      "train time for 7860 epochs, was 6451.906533241272\n",
      "\n",
      "EPOCH 7862  (with max 8000), loss: 0.0042977966368198395\n",
      "train time for 7862 epochs, was 6453.54022359848\n",
      "\n",
      "EPOCH 7864  (with max 8000), loss: 0.005663365591317415\n",
      "train time for 7864 epochs, was 6455.182249307632\n",
      "\n",
      "EPOCH 7866  (with max 8000), loss: 0.008506929501891136\n",
      "train time for 7866 epochs, was 6456.818030595779\n",
      "\n",
      "EPOCH 7868  (with max 8000), loss: 0.017742857336997986\n",
      "train time for 7868 epochs, was 6458.455894708633\n",
      "\n",
      "EPOCH 7870  (with max 8000), loss: 0.004959836136549711\n",
      "train time for 7870 epochs, was 6460.089909553528\n",
      "\n",
      "EPOCH 7872  (with max 8000), loss: 0.0037567962426692247\n",
      "train time for 7872 epochs, was 6461.723526716232\n",
      "\n",
      "EPOCH 7874  (with max 8000), loss: 0.007134417537599802\n",
      "train time for 7874 epochs, was 6463.35719871521\n",
      "\n",
      "EPOCH 7876  (with max 8000), loss: 0.05808331072330475\n",
      "train time for 7876 epochs, was 6464.990780830383\n",
      "\n",
      "EPOCH 7878  (with max 8000), loss: 0.007727908436208963\n",
      "train time for 7878 epochs, was 6466.624198675156\n",
      "\n",
      "EPOCH 7880  (with max 8000), loss: 0.005399235989898443\n",
      "train time for 7880 epochs, was 6468.262238025665\n",
      "\n",
      "EPOCH 7882  (with max 8000), loss: 0.005498243495821953\n",
      "train time for 7882 epochs, was 6469.896056890488\n",
      "\n",
      "EPOCH 7884  (with max 8000), loss: 0.006074194796383381\n",
      "train time for 7884 epochs, was 6471.529768705368\n",
      "\n",
      "EPOCH 7886  (with max 8000), loss: 0.01193957682698965\n",
      "train time for 7886 epochs, was 6473.165416479111\n",
      "\n",
      "EPOCH 7888  (with max 8000), loss: 0.0021377746015787125\n",
      "train time for 7888 epochs, was 6474.799156904221\n",
      "\n",
      "EPOCH 7890  (with max 8000), loss: 0.004936599172651768\n",
      "train time for 7890 epochs, was 6476.434748411179\n",
      "\n",
      "EPOCH 7892  (with max 8000), loss: 0.005656431429088116\n",
      "train time for 7892 epochs, was 6478.068211078644\n",
      "\n",
      "EPOCH 7894  (with max 8000), loss: 0.0039058078546077013\n",
      "train time for 7894 epochs, was 6479.703773975372\n",
      "\n",
      "EPOCH 7896  (with max 8000), loss: 0.007082217372953892\n",
      "train time for 7896 epochs, was 6481.34169960022\n",
      "\n",
      "EPOCH 7898  (with max 8000), loss: 0.005958016030490398\n",
      "train time for 7898 epochs, was 6482.979630470276\n",
      "\n",
      "EPOCH 7900  (with max 8000), loss: 0.005581314209848642\n",
      "train time for 7900 epochs, was 6484.6152975559235\n",
      "\n",
      "EPOCH 7902  (with max 8000), loss: 0.02155960164964199\n",
      "train time for 7902 epochs, was 6486.248849391937\n",
      "\n",
      "EPOCH 7904  (with max 8000), loss: 0.016545072197914124\n",
      "train time for 7904 epochs, was 6487.8824372291565\n",
      "\n",
      "EPOCH 7906  (with max 8000), loss: 0.01093817688524723\n",
      "train time for 7906 epochs, was 6489.518227815628\n",
      "\n",
      "EPOCH 7908  (with max 8000), loss: 0.013533427380025387\n",
      "train time for 7908 epochs, was 6491.151992082596\n",
      "\n",
      "EPOCH 7910  (with max 8000), loss: 0.0035926816053688526\n",
      "train time for 7910 epochs, was 6492.796049118042\n",
      "\n",
      "EPOCH 7912  (with max 8000), loss: 0.008571929298341274\n",
      "train time for 7912 epochs, was 6494.42967414856\n",
      "\n",
      "EPOCH 7914  (with max 8000), loss: 0.006614240817725658\n",
      "train time for 7914 epochs, was 6496.078134059906\n",
      "\n",
      "EPOCH 7916  (with max 8000), loss: 0.003302175784483552\n",
      "train time for 7916 epochs, was 6497.718148231506\n",
      "\n",
      "EPOCH 7918  (with max 8000), loss: 0.0029162971768528223\n",
      "train time for 7918 epochs, was 6499.385375499725\n",
      "\n",
      "EPOCH 7920  (with max 8000), loss: 0.005850492976605892\n",
      "train time for 7920 epochs, was 6501.0232899188995\n",
      "\n",
      "EPOCH 7922  (with max 8000), loss: 0.00856300164014101\n",
      "train time for 7922 epochs, was 6502.6570084095\n",
      "\n",
      "EPOCH 7924  (with max 8000), loss: 0.008900714106857777\n",
      "train time for 7924 epochs, was 6504.296958684921\n",
      "\n",
      "EPOCH 7926  (with max 8000), loss: 0.004211133345961571\n",
      "train time for 7926 epochs, was 6505.9305584430695\n",
      "\n",
      "EPOCH 7928  (with max 8000), loss: 0.001995667815208435\n",
      "train time for 7928 epochs, was 6507.5661408901215\n",
      "\n",
      "EPOCH 7930  (with max 8000), loss: 0.006450403947383165\n",
      "train time for 7930 epochs, was 6509.199764251709\n",
      "\n",
      "EPOCH 7932  (with max 8000), loss: 0.003722943365573883\n",
      "train time for 7932 epochs, was 6510.835590839386\n",
      "\n",
      "EPOCH 7934  (with max 8000), loss: 0.007245416287332773\n",
      "train time for 7934 epochs, was 6512.469258785248\n",
      "\n",
      "EPOCH 7936  (with max 8000), loss: 0.010376770980656147\n",
      "train time for 7936 epochs, was 6514.104938745499\n",
      "\n",
      "EPOCH 7938  (with max 8000), loss: 0.007995919324457645\n",
      "train time for 7938 epochs, was 6515.738555431366\n",
      "\n",
      "EPOCH 7940  (with max 8000), loss: 0.0010765368351712823\n",
      "train time for 7940 epochs, was 6517.393243312836\n",
      "\n",
      "EPOCH 7942  (with max 8000), loss: 0.0064804330468177795\n",
      "train time for 7942 epochs, was 6519.02690577507\n",
      "\n",
      "EPOCH 7944  (with max 8000), loss: 0.004037007223814726\n",
      "train time for 7944 epochs, was 6520.660424232483\n",
      "\n",
      "EPOCH 7946  (with max 8000), loss: 0.0032269805669784546\n",
      "train time for 7946 epochs, was 6522.294029712677\n",
      "\n",
      "EPOCH 7948  (with max 8000), loss: 0.010982255451381207\n",
      "train time for 7948 epochs, was 6523.927601575851\n",
      "\n",
      "EPOCH 7950  (with max 8000), loss: 0.004862216301262379\n",
      "train time for 7950 epochs, was 6525.561338186264\n",
      "\n",
      "EPOCH 7952  (with max 8000), loss: 0.003472427371889353\n",
      "train time for 7952 epochs, was 6527.194961547852\n",
      "\n",
      "EPOCH 7954  (with max 8000), loss: 0.003498413134366274\n",
      "train time for 7954 epochs, was 6528.832790136337\n",
      "\n",
      "EPOCH 7956  (with max 8000), loss: 0.007177292834967375\n",
      "train time for 7956 epochs, was 6530.466553688049\n",
      "\n",
      "EPOCH 7958  (with max 8000), loss: 0.003003489226102829\n",
      "train time for 7958 epochs, was 6532.104465007782\n",
      "\n",
      "EPOCH 7960  (with max 8000), loss: 0.006456149276345968\n",
      "train time for 7960 epochs, was 6533.740314722061\n",
      "\n",
      "EPOCH 7962  (with max 8000), loss: 0.00706434017047286\n",
      "train time for 7962 epochs, was 6535.376165628433\n",
      "\n",
      "EPOCH 7964  (with max 8000), loss: 0.004271733574569225\n",
      "train time for 7964 epochs, was 6537.014273643494\n",
      "\n",
      "EPOCH 7966  (with max 8000), loss: 0.005820963531732559\n",
      "train time for 7966 epochs, was 6538.648273229599\n",
      "\n",
      "EPOCH 7968  (with max 8000), loss: 0.004471753258258104\n",
      "train time for 7968 epochs, was 6540.282164812088\n",
      "\n",
      "EPOCH 7970  (with max 8000), loss: 0.002675797790288925\n",
      "train time for 7970 epochs, was 6541.91600894928\n",
      "\n",
      "EPOCH 7972  (with max 8000), loss: 0.03271592780947685\n",
      "train time for 7972 epochs, was 6543.551766633987\n",
      "\n",
      "EPOCH 7974  (with max 8000), loss: 0.012888751924037933\n",
      "train time for 7974 epochs, was 6545.1856961250305\n",
      "\n",
      "EPOCH 7976  (with max 8000), loss: 0.008653915487229824\n",
      "train time for 7976 epochs, was 6546.823658704758\n",
      "\n",
      "EPOCH 7978  (with max 8000), loss: 0.005904454737901688\n",
      "train time for 7978 epochs, was 6548.457408666611\n",
      "\n",
      "EPOCH 7980  (with max 8000), loss: 0.014956722967326641\n",
      "train time for 7980 epochs, was 6550.091048717499\n",
      "\n",
      "EPOCH 7982  (with max 8000), loss: 0.006572068203240633\n",
      "train time for 7982 epochs, was 6551.728962659836\n",
      "\n",
      "EPOCH 7984  (with max 8000), loss: 0.005321139004081488\n",
      "train time for 7984 epochs, was 6553.366981744766\n",
      "\n",
      "EPOCH 7986  (with max 8000), loss: 0.006435653194785118\n",
      "train time for 7986 epochs, was 6555.009040355682\n",
      "\n",
      "EPOCH 7988  (with max 8000), loss: 0.0072946990840137005\n",
      "train time for 7988 epochs, was 6556.64266204834\n",
      "\n",
      "EPOCH 7990  (with max 8000), loss: 0.0027263909578323364\n",
      "train time for 7990 epochs, was 6558.276376724243\n",
      "\n",
      "EPOCH 7992  (with max 8000), loss: 0.0018244525417685509\n",
      "train time for 7992 epochs, was 6559.910068273544\n",
      "\n",
      "EPOCH 7994  (with max 8000), loss: 0.0038364226929843426\n",
      "train time for 7994 epochs, was 6561.543943405151\n",
      "\n",
      "EPOCH 7996  (with max 8000), loss: 0.0031027081422507763\n",
      "train time for 7996 epochs, was 6563.177696228027\n",
      "\n",
      "EPOCH 7998  (with max 8000), loss: 0.04248450696468353\n",
      "train time for 7998 epochs, was 6564.811306715012\n",
      "\n",
      "EPOCH 8000  (with max 8000), loss: 0.006856647785753012\n",
      "train time for 8000 epochs, was 6566.445014953613\n",
      "\n",
      "EPOCH 8000 save model to : runs/nsynth_test_256_class/out.e256.l4.h8_chkpt_8000.pth\n",
      "\n",
      "train time for 8000 epochs, was 6566.478028535843\n",
      "loss  =  0.006856647785753012\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train(model, optimizer, dataloader, num_epochs, device, outdir, basefname, start_epoch=0, checkpoint_path=None):\n",
    "    t0 = time.time()\n",
    "    max_epoch = start_epoch + num_epochs\n",
    "    for epoch in range(start_epoch, max_epoch):\n",
    "        torch.cuda.empty_cache()\n",
    "        model.train()\n",
    "        for batch_idx, (input_data, target_data, cond_data) in enumerate(dataloader):\n",
    "            if verboselevel > 5 :\n",
    "                print(f' ---- submitting batch with input_data={input_data.shape}, target_data={target_data.shape}, cond_data={cond_data.shape}')\n",
    "            #print(f\"b{batch_idx} \", end='')\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # Move inputs and targets to the device\n",
    "            input_data, target_data, cond_data = input_data.to(device), target_data.to(device), cond_data.to(device)\n",
    "            \n",
    "            if cond_size==0 :  #Ignore conditioning data\n",
    "                cond_expanded=None\n",
    "            else : \n",
    "                # for dataset exammples, expand the conditioning info across all time steps before passing to models\n",
    "                cond_expanded = cond_data.unsqueeze(1).expand(-1, input_data.size(1), -1)\n",
    "            \n",
    "            #print(f'    after loading a batch,  input_data.shape is {input_data.shape}, and cond_data.shape is {cond_data.shape}')\n",
    "            #print(f'    after loading a batch,  cond_expanded.shape is {cond_expanded.shape}')\n",
    "            #print(f'    after loading a batch,  mask.shape is {mask.shape}')\n",
    "            #print(f' model={model}')\n",
    "            \n",
    "            # torch.Size([batch_size, seq_len, num_tokens, vocab_size])\n",
    "            output = model(input_data, cond_expanded, mask)\n",
    "        \n",
    "            if verboselevel > 5 :\n",
    "                print(f' TTTTTTTT after training, output shape ={output.shape}, torch.Size([batch_size, seq_len, num_tokens, vocab_size])')\n",
    "                print(f' TTTTTTTT Passing to CRITERION with , output.reshape(-1, vocab_size) = {output.reshape(-1, vocab_size).shape} and target_data.reshape(-1) = {target_data.reshape(-1).shape}' )\n",
    "    \n",
    "            ##  this works, but is too verbose >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "            ##      # Original shape: (batch_size, seq_len, num_tokens, vocab_size)\n",
    "            ##      output = output.reshape(batch_size, sequence_length * num_tokens, vocab_size)\n",
    "            ##      # Original shape: (batch_size, seq_len, num_tokens)\n",
    "            ##      targets = targets.reshape(batch_size, sequence_length * num_tokens)\n",
    "            ##      loss = criterion(output.permute(0, 2, 1), targets) \n",
    "            \n",
    "            ##  more succinct <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "            #   Computes the CE for each token separately, and then averages them to get the loss.\n",
    "            #loss = criterion(output.reshape(-1, vocab_size), target_data.reshape(-1)) # collapses all target_data dimensions into a single dimension\n",
    "            loss = criterion(output.reshape(-1, vocab_size), target_data.reshape(-1).long())\n",
    "            ## <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if (epoch+1) % ErrorLogRate == 0:\n",
    "            print(f'EPOCH {epoch+1}  (with max {max_epoch}), ', end='')\n",
    "            print(f'loss: {loss}')\n",
    "            # Log the loss to TensorBoard\n",
    "            writer.add_scalar('Loss/train', loss, epoch)\n",
    "            \n",
    "            if validator_data_dir != None :\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_loss = 0\n",
    "                    for val_inputs, val_targets, cond_data in validator_dataloader:\n",
    "                        val_inputs, val_targets, cond_data = val_inputs.to(device), val_targets.to(device), cond_data.to(device)\n",
    "                        \n",
    "                        if cond_size==0 :  #Ignore conditioning data\n",
    "                            cond_expanded=None\n",
    "                        else: \n",
    "                            # for dataset exammples, expand the conditioning info across all time steps before passing to models\n",
    "                            cond_expanded = cond_data.unsqueeze(1).expand(-1, input_data.size(1), -1)\n",
    "    \n",
    "                        \n",
    "                        val_outputs = model(val_inputs,cond_expanded, mask)\n",
    "                        \n",
    "                        val_loss += criterion(val_outputs.reshape(-1, vocab_size), val_targets.reshape(-1).long()) # collapses all target_data dimensions into a single dimension\n",
    "                        #val_loss += criterion(val_outputs, val_targets).item()\n",
    "    \n",
    "                print(f'Validation Loss: {val_loss / len(validator_dataloader)}')\n",
    "                writer.add_scalar('Loss/validation', val_loss / len(validator_dataloader), epoch)\n",
    "    \n",
    "            t1 = time.time()\n",
    "            train_time = t1-t0\n",
    "            print(f'train time for {epoch-start_epoch+1} epochs, was {train_time}' )\n",
    "            print(f'')\n",
    "                \n",
    "        if (epoch+1) % checkpoint_interval == 0:\n",
    "            lastbasename = outdir+\"/\"+basefname+\"_chkpt_\"+str(epoch+1).zfill(4)\n",
    "            print(f'EPOCH {epoch+1} save model to : {lastbasename}.pth')\n",
    "            print(f'')\n",
    "            save_model(model, optimizer, Ti,  lastbasename +\".pth\")\n",
    "        \n",
    "    \n",
    "    t1 = time.time()\n",
    "    train_time = t1-t0\n",
    "    print(f'train time for {num_epochs} epochs, was {train_time}' )\n",
    "    print(f'loss  =  {loss}' )\n",
    "    \n",
    "## -----------------------------------------------------------------------------------\n",
    "## OK, let's do it!\n",
    "train(model, optimizer, dataloader, num_epochs, device, outdir, basefname, start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16eb43b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
       "        [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
       "        [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., -inf, -inf],\n",
       "        [0., 0., 0.,  ..., 0., 0., -inf],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just check that inference attention mask will look right\n",
    "#Actually, the inference mask can be None since we are using a context window only as long as the maximum look-back in the training mask\n",
    "# thats why taking the mask with :TI is upper-triangular. Longer dims would show a banded mask again.\n",
    "foo=mask[:Ti, :Ti]\n",
    "foo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871a1f25-78a6-479b-8771-2910cf639d67",
   "metadata": {},
   "source": [
    "### <font color='blue'> Use Inference.Decode.ipynb to see and hear your generated audio   \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68274809-4986-4d54-a442-ba7ac8b48ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
