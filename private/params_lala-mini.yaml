experiment: "2025.03.08_mini_params"

#data_dir: "/home/lonce/scratchdata/Lala_data/lala_dac"
#data_frames: "/home/lonce/scratchdata/Lala_data/lala-train.xlsx"
data_dir: "/home/lonce/scratchdata/Lala_data/lala_dac"
data_frames: "/home/lonce/scratchdata/Lala_data/lala_param_train.xlsx"
validator_data_dir: null
validator_data_frames: null


TransformerClass: "RopeCondDACTransformer" 
ftype: 'dac' # dac or mel
vocab_size: 1024
input_type: "int" #typically int for ftype dac, float for ftypemel
num_tokens: 4

#cond_params: 1 #1 (not counting the classes)
model_size: 128 # must be divisible by num_heads

Ti: 43 #86 # 172 #86 mask size for training and training, mask and windowsize for inference 
Tt: 430 # must match the length of the sequences in the batch
batch_size: 4  #**


num_layers: 2 #**
num_heads: 8 #8 # 8 # embed_size must be divisible by num_heads
forward_expansion: 4 #4 #4
dropout_rate: 0.2
learning_rate: 0.0005

num_epochs: 2000 ### 800 

ErrorLogRate: 25 #2 ### 10
checkpoint_interval: 50 ###50 # 25

