experiment: "mini_test_2"

data_dir: "testdata/minisyntex/dac-train"
data_frames: "testdata/minisyntex/dac-train.xlsx"
validator_data_dir: "testdata/minisyntex/dac-val"
validator_data_frames: "testdata/minisyntex/dac-val.xlsx"



TransformerClass: "RopeCondDACTransformer" 

ftype: 'dac' # dac or mel
vocab_size: 1024
input_type: "int" # int (for tokens), or "float" (for decoded tokens or mel spectrograms, etc)
num_tokens: 4

#cond_params: 1 #1 (not counting the classes)
model_size: 64 # must be divisible by num_heads

Ti: 43 # 172 #86 mask size for training and training, mask and windowsize for inference 
Tt: 430 # must match the length of the sequences in the batch
batch_size: 4  #**


num_layers: 2 #**
num_heads: 4 #8 # 8 # embed_size must be divisible by num_heads
forward_expansion: 2 #4 #4
dropout_rate: 0.2
learning_rate: 0.0005
use_adaLN: False #else FiLM

num_epochs: 2 ### 800 

ErrorLogRate: 1 #2 ### 10
checkpoint_interval: 2 ###50 # 25

